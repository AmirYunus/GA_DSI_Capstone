{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KrG1QfTlRhbu"
   },
   "source": [
    "# Import Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from datetime import datetime\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, CSVLogger\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, accuracy_score\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_attr_names = ['WAERS', 'BUKRS', 'KTOSL', 'PRCTR', 'BSCHL', 'HKONT']\n",
    "numeric_attr_names = ['DMBTR', 'WRBTR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "gfz4Y8S6RxMg",
    "outputId": "cf247fc0-4bac-48c6-8328-5e4e2afd5485",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing dataset of 33314 rows and 11 columns loaded\n"
     ]
    }
   ],
   "source": [
    "test_dataset = pd.read_csv('../data/test_set_2.csv')\n",
    "# test_dataset = pd.read_csv('/content/drive/My Drive/Project/test_set_2.csv')\n",
    "# inspect the datasets dimensionalities\n",
    "print(F'Testing dataset of {test_dataset.shape[0]} rows and {test_dataset.shape[1]} columns loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PHdS_YYydoDG"
   },
   "outputs": [],
   "source": [
    "if 'label' in test_dataset:\n",
    "    real_label = test_dataset.pop('label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "KraNCLnaSaIn",
    "outputId": "abcc7761-1c5d-49f4-da79-2fc5988c2800"
   },
   "outputs": [],
   "source": [
    "test_dataset_categ_transformed = pd.get_dummies(test_dataset[categorical_attr_names])\n",
    "test_dataset_categ_transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "IxhBWxkwV4JW",
    "outputId": "0f56539f-5d69-48d7-e72e-e819ff4de6d0"
   },
   "outputs": [],
   "source": [
    "test_numeric_attr = test_dataset[numeric_attr_names] + 1e-7\n",
    "test_numeric_attr = test_numeric_attr.apply(np.log)\n",
    "test_dataset_numeric_attr = (test_numeric_attr - test_numeric_attr.min()) / (test_numeric_attr.max() - test_numeric_attr.min())\n",
    "test_dataset_numeric_attr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/check_columns.csv', 'r', newline='', encoding='utf-8') as readFile:\n",
    "    reader = csv.reader(readFile, dialect='excel')\n",
    "    check_columns = list(reader)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "_1gdD6NNWvqi",
    "outputId": "5dcdb7e4-eca3-4ad7-808a-a0b1b16f8a00"
   },
   "outputs": [],
   "source": [
    "test_subset_transformed = pd.concat([test_dataset_categ_transformed, test_dataset_numeric_attr], axis = 1)\n",
    "for i in check_columns:\n",
    "    if i not in test_subset_transformed:\n",
    "        test_subset_transformed[i] = 0\n",
    "test_subset_transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9ZL3NMauefG0"
   },
   "outputs": [],
   "source": [
    "df_real_test = test_subset_transformed.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XuiQ2nDaigum"
   },
   "outputs": [],
   "source": [
    "# df_real_test_, df_real_val_, df_y_real_test, df_y_real_val = \\\n",
    "# train_test_split(\n",
    "#     df_real_test, \n",
    "#     real_label, \n",
    "#     random_state=42, \n",
    "#     stratify=real_label\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jbLhE66efVwz"
   },
   "outputs": [],
   "source": [
    "ss = MinMaxScaler()\n",
    "df_real_test_ss = ss.fit_transform(df_real_test)\n",
    "# df_real_val_ss = ss.fit_transform(df_real_val_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EZTgt30BHyYo"
   },
   "source": [
    "## Preparing Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Fitting the PCA algorithm with our Data\n",
    "# pca = PCA().fit(df_real_test_ss)\n",
    "# #Plotting the Cumulative Summation of the Explained Variance\n",
    "# plt.figure(figsize=(16,9))\n",
    "# plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "# plt.xlabel('Number of Components')\n",
    "# plt.ylabel('Variance (%)') #for each component\n",
    "# plt.title('Pulsar Dataset Explained Variance')\n",
    "# # plt.xlim(200,250)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3pq9IBE-fBG6"
   },
   "outputs": [],
   "source": [
    "# latent space dimension\n",
    "encoding_dim = 200\n",
    "\n",
    "# input placeholder\n",
    "real_input_data = Input (shape = (df_real_test_ss.shape[1], ) )\n",
    "\n",
    "# encoded input\n",
    "real_encoded = Dense (encoding_dim, activation = 'relu', activity_regularizer = regularizers.l1(10e-5) ) (real_input_data)\n",
    "\n",
    "# decoded input\n",
    "real_decoded = Dense (df_real_test_ss.shape[1], activation = 'sigmoid') (real_encoded)\n",
    "\n",
    "# build autoencoder model\n",
    "real_autoencoder = Model (real_input_data, real_decoded)\n",
    "\n",
    "# build encoder for autoencoder model\n",
    "real_encoder = Model (real_input_data, real_encoded)\n",
    "\n",
    "# build decoder for autoencoder model\n",
    "real_encoded_input = Input (shape = (encoding_dim, ) )\n",
    "real_decoder_layer = real_autoencoder.layers[-1]\n",
    "real_decoder = Model (real_encoded_input, real_decoder_layer (real_encoded_input) )\n",
    "\n",
    "real_autoencoder.compile (optimizer = 'adam', loss = 'binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iPTA7KKsgr1w"
   },
   "outputs": [],
   "source": [
    "real_early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KuOggE_6g0AK"
   },
   "outputs": [],
   "source": [
    "# filepath=\"../models/04_autoencoder_knn/{epoch:04}.hdf5\"\n",
    "# real_filepath=\"/content/drive/My Drive/Project/real_models/{epoch:04}.hdf5\"\n",
    "# real_checkpoint = ModelCheckpoint(real_filepath, monitor='val_loss', verbose=1, save_best_only=False, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3PdxiUFwhPyJ"
   },
   "outputs": [],
   "source": [
    "# csv_logger = CSVLogger(\"../models/04_autoencoder_knn/history.csv\", append=True)\n",
    "# real_csv_logger = CSVLogger(\"/content/drive/My Drive/Project/real_models/history.csv\", append=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "268-fPuYhy5c",
    "outputId": "21bb5aa8-4926-4b84-ef9f-b360d2dcde43"
   },
   "outputs": [],
   "source": [
    "real_autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nHsNayLqHyYr"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "rERWfrWJdf_O",
    "outputId": "0a37ea4d-959d-4dfb-931d-91b93a74c630",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22209 samples, validate on 11105 samples\n",
      "Epoch 1/1000\n",
      " - 5s - loss: 0.2716 - val_loss: 0.1192\n",
      "Epoch 2/1000\n",
      " - 4s - loss: 0.0887 - val_loss: 0.0734\n",
      "Epoch 3/1000\n",
      " - 4s - loss: 0.0679 - val_loss: 0.0628\n",
      "Epoch 4/1000\n",
      " - 4s - loss: 0.0595 - val_loss: 0.0567\n",
      "Epoch 5/1000\n",
      " - 4s - loss: 0.0549 - val_loss: 0.0531\n",
      "Epoch 6/1000\n",
      " - 4s - loss: 0.0518 - val_loss: 0.0504\n",
      "Epoch 7/1000\n",
      " - 4s - loss: 0.0494 - val_loss: 0.0482\n",
      "Epoch 8/1000\n",
      " - 4s - loss: 0.0472 - val_loss: 0.0461\n",
      "Epoch 9/1000\n",
      " - 4s - loss: 0.0453 - val_loss: 0.0443\n",
      "Epoch 10/1000\n",
      " - 5s - loss: 0.0436 - val_loss: 0.0427\n",
      "Epoch 11/1000\n",
      " - 4s - loss: 0.0421 - val_loss: 0.0413\n",
      "Epoch 12/1000\n",
      " - 4s - loss: 0.0408 - val_loss: 0.0401\n",
      "Epoch 13/1000\n",
      " - 4s - loss: 0.0397 - val_loss: 0.0390\n",
      "Epoch 14/1000\n",
      " - 4s - loss: 0.0386 - val_loss: 0.0379\n",
      "Epoch 15/1000\n",
      " - 4s - loss: 0.0376 - val_loss: 0.0370\n",
      "Epoch 16/1000\n",
      " - 4s - loss: 0.0367 - val_loss: 0.0361\n",
      "Epoch 17/1000\n",
      " - 4s - loss: 0.0358 - val_loss: 0.0353\n",
      "Epoch 18/1000\n",
      " - 4s - loss: 0.0350 - val_loss: 0.0345\n",
      "Epoch 19/1000\n",
      " - 4s - loss: 0.0343 - val_loss: 0.0338\n",
      "Epoch 20/1000\n",
      " - 4s - loss: 0.0336 - val_loss: 0.0331\n",
      "Epoch 21/1000\n",
      " - 4s - loss: 0.0329 - val_loss: 0.0325\n",
      "Epoch 22/1000\n",
      " - 4s - loss: 0.0323 - val_loss: 0.0319\n",
      "Epoch 23/1000\n",
      " - 4s - loss: 0.0318 - val_loss: 0.0314\n",
      "Epoch 24/1000\n",
      " - 4s - loss: 0.0312 - val_loss: 0.0308\n",
      "Epoch 25/1000\n",
      " - 4s - loss: 0.0307 - val_loss: 0.0304\n",
      "Epoch 26/1000\n",
      " - 4s - loss: 0.0302 - val_loss: 0.0299\n",
      "Epoch 27/1000\n",
      " - 4s - loss: 0.0298 - val_loss: 0.0295\n",
      "Epoch 28/1000\n",
      " - 4s - loss: 0.0294 - val_loss: 0.0291\n",
      "Epoch 29/1000\n",
      " - 4s - loss: 0.0290 - val_loss: 0.0287\n",
      "Epoch 30/1000\n",
      " - 4s - loss: 0.0286 - val_loss: 0.0283\n",
      "Epoch 31/1000\n",
      " - 4s - loss: 0.0283 - val_loss: 0.0280\n",
      "Epoch 32/1000\n",
      " - 4s - loss: 0.0279 - val_loss: 0.0277\n",
      "Epoch 33/1000\n",
      " - 5s - loss: 0.0276 - val_loss: 0.0274\n",
      "Epoch 34/1000\n",
      " - 5s - loss: 0.0273 - val_loss: 0.0271\n",
      "Epoch 35/1000\n",
      " - 4s - loss: 0.0271 - val_loss: 0.0268\n",
      "Epoch 36/1000\n",
      " - 5s - loss: 0.0268 - val_loss: 0.0266\n",
      "Epoch 37/1000\n",
      " - 5s - loss: 0.0266 - val_loss: 0.0264\n",
      "Epoch 38/1000\n",
      " - 5s - loss: 0.0264 - val_loss: 0.0262\n",
      "Epoch 39/1000\n",
      " - 4s - loss: 0.0262 - val_loss: 0.0260\n",
      "Epoch 40/1000\n",
      " - 4s - loss: 0.0260 - val_loss: 0.0258\n",
      "Epoch 41/1000\n",
      " - 4s - loss: 0.0258 - val_loss: 0.0256\n",
      "Epoch 42/1000\n",
      " - 4s - loss: 0.0256 - val_loss: 0.0254\n",
      "Epoch 43/1000\n",
      " - 4s - loss: 0.0255 - val_loss: 0.0253\n",
      "Epoch 44/1000\n",
      " - 4s - loss: 0.0253 - val_loss: 0.0251\n",
      "Epoch 45/1000\n",
      " - 4s - loss: 0.0252 - val_loss: 0.0250\n",
      "Epoch 46/1000\n",
      " - 4s - loss: 0.0250 - val_loss: 0.0249\n",
      "Epoch 47/1000\n",
      " - 4s - loss: 0.0249 - val_loss: 0.0247\n",
      "Epoch 48/1000\n",
      " - 4s - loss: 0.0248 - val_loss: 0.0246\n",
      "Epoch 49/1000\n",
      " - 4s - loss: 0.0247 - val_loss: 0.0245\n",
      "Epoch 50/1000\n",
      " - 4s - loss: 0.0246 - val_loss: 0.0244\n",
      "Epoch 51/1000\n",
      " - 4s - loss: 0.0244 - val_loss: 0.0243\n",
      "Epoch 52/1000\n",
      " - 4s - loss: 0.0243 - val_loss: 0.0242\n",
      "Epoch 53/1000\n",
      " - 4s - loss: 0.0242 - val_loss: 0.0241\n",
      "Epoch 54/1000\n",
      " - 4s - loss: 0.0242 - val_loss: 0.0240\n",
      "Epoch 55/1000\n",
      " - 4s - loss: 0.0241 - val_loss: 0.0239\n",
      "Epoch 56/1000\n",
      " - 4s - loss: 0.0240 - val_loss: 0.0239\n",
      "Epoch 57/1000\n",
      " - 4s - loss: 0.0239 - val_loss: 0.0238\n",
      "Epoch 58/1000\n",
      " - 4s - loss: 0.0238 - val_loss: 0.0237\n",
      "Epoch 59/1000\n",
      " - 4s - loss: 0.0238 - val_loss: 0.0236\n",
      "Epoch 60/1000\n",
      " - 4s - loss: 0.0237 - val_loss: 0.0236\n",
      "Epoch 61/1000\n",
      " - 4s - loss: 0.0236 - val_loss: 0.0235\n",
      "Epoch 62/1000\n",
      " - 4s - loss: 0.0235 - val_loss: 0.0234\n",
      "Epoch 63/1000\n",
      " - 4s - loss: 0.0235 - val_loss: 0.0234\n",
      "Epoch 64/1000\n",
      " - 4s - loss: 0.0234 - val_loss: 0.0233\n",
      "Epoch 65/1000\n",
      " - 4s - loss: 0.0233 - val_loss: 0.0232\n",
      "Epoch 66/1000\n",
      " - 4s - loss: 0.0233 - val_loss: 0.0232\n",
      "Epoch 67/1000\n",
      " - 5s - loss: 0.0232 - val_loss: 0.0231\n",
      "Epoch 68/1000\n",
      " - 4s - loss: 0.0232 - val_loss: 0.0231\n",
      "Epoch 69/1000\n",
      " - 4s - loss: 0.0231 - val_loss: 0.0230\n",
      "Epoch 70/1000\n",
      " - 4s - loss: 0.0231 - val_loss: 0.0230\n",
      "Epoch 71/1000\n",
      " - 4s - loss: 0.0230 - val_loss: 0.0229\n",
      "Epoch 72/1000\n",
      " - 4s - loss: 0.0230 - val_loss: 0.0229\n",
      "Epoch 73/1000\n",
      " - 4s - loss: 0.0229 - val_loss: 0.0228\n",
      "Epoch 74/1000\n",
      " - 4s - loss: 0.0229 - val_loss: 0.0228\n",
      "Epoch 75/1000\n",
      " - 4s - loss: 0.0228 - val_loss: 0.0227\n",
      "Epoch 76/1000\n",
      " - 4s - loss: 0.0228 - val_loss: 0.0227\n",
      "Epoch 77/1000\n",
      " - 4s - loss: 0.0227 - val_loss: 0.0226\n",
      "Epoch 78/1000\n",
      " - 5s - loss: 0.0227 - val_loss: 0.0226\n",
      "Epoch 79/1000\n",
      " - 4s - loss: 0.0226 - val_loss: 0.0225\n",
      "Epoch 80/1000\n",
      " - 4s - loss: 0.0226 - val_loss: 0.0225\n",
      "Epoch 81/1000\n",
      " - 4s - loss: 0.0226 - val_loss: 0.0225\n",
      "Epoch 82/1000\n",
      " - 4s - loss: 0.0225 - val_loss: 0.0224\n",
      "Epoch 83/1000\n",
      " - 4s - loss: 0.0225 - val_loss: 0.0224\n",
      "Epoch 84/1000\n",
      " - 4s - loss: 0.0224 - val_loss: 0.0223\n",
      "Epoch 85/1000\n",
      " - 4s - loss: 0.0224 - val_loss: 0.0223\n",
      "Epoch 86/1000\n",
      " - 4s - loss: 0.0224 - val_loss: 0.0223\n",
      "Epoch 87/1000\n",
      " - 4s - loss: 0.0223 - val_loss: 0.0222\n",
      "Epoch 88/1000\n",
      " - 4s - loss: 0.0223 - val_loss: 0.0222\n",
      "Epoch 89/1000\n",
      " - 4s - loss: 0.0223 - val_loss: 0.0222\n",
      "Epoch 90/1000\n",
      " - 4s - loss: 0.0222 - val_loss: 0.0221\n",
      "Epoch 91/1000\n",
      " - 4s - loss: 0.0222 - val_loss: 0.0221\n",
      "Epoch 92/1000\n",
      " - 4s - loss: 0.0222 - val_loss: 0.0221\n",
      "Epoch 93/1000\n",
      " - 4s - loss: 0.0221 - val_loss: 0.0220\n",
      "Epoch 94/1000\n",
      " - 4s - loss: 0.0221 - val_loss: 0.0220\n",
      "Epoch 95/1000\n",
      " - 4s - loss: 0.0221 - val_loss: 0.0220\n",
      "Epoch 96/1000\n",
      " - 4s - loss: 0.0220 - val_loss: 0.0219\n",
      "Epoch 97/1000\n",
      " - 4s - loss: 0.0220 - val_loss: 0.0219\n",
      "Epoch 98/1000\n",
      " - 4s - loss: 0.0220 - val_loss: 0.0219\n",
      "Epoch 99/1000\n",
      " - 4s - loss: 0.0219 - val_loss: 0.0219\n",
      "Epoch 100/1000\n",
      " - 4s - loss: 0.0219 - val_loss: 0.0218\n",
      "Epoch 101/1000\n",
      " - 4s - loss: 0.0219 - val_loss: 0.0218\n",
      "Epoch 102/1000\n",
      " - 4s - loss: 0.0219 - val_loss: 0.0218\n",
      "Epoch 103/1000\n",
      " - 4s - loss: 0.0218 - val_loss: 0.0218\n",
      "Epoch 104/1000\n",
      " - 4s - loss: 0.0218 - val_loss: 0.0217\n",
      "Epoch 105/1000\n",
      " - 4s - loss: 0.0218 - val_loss: 0.0217\n",
      "Epoch 106/1000\n",
      " - 4s - loss: 0.0218 - val_loss: 0.0217\n",
      "Epoch 107/1000\n",
      " - 4s - loss: 0.0217 - val_loss: 0.0217\n",
      "Epoch 108/1000\n",
      " - 4s - loss: 0.0217 - val_loss: 0.0216\n",
      "Epoch 109/1000\n",
      " - 4s - loss: 0.0217 - val_loss: 0.0216\n",
      "Epoch 110/1000\n",
      " - 4s - loss: 0.0217 - val_loss: 0.0216\n",
      "Epoch 111/1000\n",
      " - 4s - loss: 0.0216 - val_loss: 0.0216\n",
      "Epoch 112/1000\n",
      " - 4s - loss: 0.0216 - val_loss: 0.0215\n",
      "Epoch 113/1000\n",
      " - 5s - loss: 0.0216 - val_loss: 0.0215\n",
      "Epoch 114/1000\n",
      " - 4s - loss: 0.0216 - val_loss: 0.0215\n",
      "Epoch 115/1000\n",
      " - 4s - loss: 0.0215 - val_loss: 0.0215\n",
      "Epoch 116/1000\n",
      " - 4s - loss: 0.0215 - val_loss: 0.0214\n",
      "Epoch 117/1000\n",
      " - 4s - loss: 0.0215 - val_loss: 0.0214\n",
      "Epoch 118/1000\n",
      " - 4s - loss: 0.0215 - val_loss: 0.0214\n",
      "Epoch 119/1000\n",
      " - 4s - loss: 0.0214 - val_loss: 0.0214\n",
      "Epoch 120/1000\n",
      " - 4s - loss: 0.0214 - val_loss: 0.0213\n",
      "Epoch 121/1000\n",
      " - 4s - loss: 0.0214 - val_loss: 0.0213\n",
      "Epoch 122/1000\n",
      " - 4s - loss: 0.0214 - val_loss: 0.0213\n",
      "Epoch 123/1000\n",
      " - 4s - loss: 0.0214 - val_loss: 0.0213\n",
      "Epoch 124/1000\n",
      " - 4s - loss: 0.0213 - val_loss: 0.0213\n",
      "Epoch 125/1000\n",
      " - 4s - loss: 0.0213 - val_loss: 0.0212\n",
      "Epoch 126/1000\n",
      " - 4s - loss: 0.0213 - val_loss: 0.0212\n",
      "Epoch 127/1000\n",
      " - 4s - loss: 0.0213 - val_loss: 0.0212\n",
      "Epoch 128/1000\n",
      " - 4s - loss: 0.0212 - val_loss: 0.0212\n",
      "Epoch 129/1000\n",
      " - 4s - loss: 0.0212 - val_loss: 0.0212\n",
      "Epoch 130/1000\n",
      " - 4s - loss: 0.0212 - val_loss: 0.0211\n",
      "Epoch 131/1000\n",
      " - 4s - loss: 0.0212 - val_loss: 0.0211\n",
      "Epoch 132/1000\n",
      " - 4s - loss: 0.0212 - val_loss: 0.0211\n",
      "Epoch 133/1000\n",
      " - 4s - loss: 0.0211 - val_loss: 0.0211\n",
      "Epoch 134/1000\n",
      " - 4s - loss: 0.0211 - val_loss: 0.0211\n",
      "Epoch 135/1000\n",
      " - 4s - loss: 0.0211 - val_loss: 0.0210\n",
      "Epoch 136/1000\n",
      " - 4s - loss: 0.0211 - val_loss: 0.0210\n",
      "Epoch 137/1000\n",
      " - 4s - loss: 0.0211 - val_loss: 0.0210\n",
      "Epoch 138/1000\n",
      " - 5s - loss: 0.0211 - val_loss: 0.0210\n",
      "Epoch 139/1000\n",
      " - 4s - loss: 0.0210 - val_loss: 0.0210\n",
      "Epoch 140/1000\n",
      " - 4s - loss: 0.0210 - val_loss: 0.0210\n",
      "Epoch 141/1000\n",
      " - 4s - loss: 0.0210 - val_loss: 0.0209\n",
      "Epoch 142/1000\n",
      " - 4s - loss: 0.0210 - val_loss: 0.0209\n",
      "Epoch 143/1000\n",
      " - 4s - loss: 0.0210 - val_loss: 0.0209\n",
      "Epoch 144/1000\n",
      " - 4s - loss: 0.0209 - val_loss: 0.0209\n",
      "Epoch 145/1000\n",
      " - 4s - loss: 0.0209 - val_loss: 0.0209\n",
      "Epoch 146/1000\n",
      " - 4s - loss: 0.0209 - val_loss: 0.0208\n",
      "Epoch 147/1000\n",
      " - 4s - loss: 0.0209 - val_loss: 0.0208\n",
      "Epoch 148/1000\n",
      " - 4s - loss: 0.0209 - val_loss: 0.0208\n",
      "Epoch 149/1000\n",
      " - 4s - loss: 0.0209 - val_loss: 0.0208\n",
      "Epoch 150/1000\n",
      " - 4s - loss: 0.0208 - val_loss: 0.0208\n",
      "Epoch 151/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 4s - loss: 0.0208 - val_loss: 0.0208\n",
      "Epoch 152/1000\n",
      " - 4s - loss: 0.0208 - val_loss: 0.0207\n",
      "Epoch 153/1000\n",
      " - 4s - loss: 0.0208 - val_loss: 0.0207\n",
      "Epoch 154/1000\n",
      " - 4s - loss: 0.0208 - val_loss: 0.0207\n",
      "Epoch 155/1000\n",
      " - 4s - loss: 0.0208 - val_loss: 0.0207\n",
      "Epoch 156/1000\n",
      " - 4s - loss: 0.0207 - val_loss: 0.0207\n",
      "Epoch 157/1000\n",
      " - 4s - loss: 0.0207 - val_loss: 0.0207\n",
      "Epoch 158/1000\n",
      " - 4s - loss: 0.0207 - val_loss: 0.0207\n",
      "Epoch 159/1000\n",
      " - 4s - loss: 0.0207 - val_loss: 0.0206\n",
      "Epoch 160/1000\n",
      " - 4s - loss: 0.0207 - val_loss: 0.0206\n",
      "Epoch 161/1000\n",
      " - 4s - loss: 0.0207 - val_loss: 0.0206\n",
      "Epoch 162/1000\n",
      " - 4s - loss: 0.0206 - val_loss: 0.0206\n",
      "Epoch 163/1000\n",
      " - 4s - loss: 0.0206 - val_loss: 0.0206\n",
      "Epoch 164/1000\n",
      " - 4s - loss: 0.0206 - val_loss: 0.0206\n",
      "Epoch 165/1000\n",
      " - 4s - loss: 0.0206 - val_loss: 0.0205\n",
      "Epoch 166/1000\n",
      " - 4s - loss: 0.0206 - val_loss: 0.0205\n",
      "Epoch 167/1000\n",
      " - 5s - loss: 0.0206 - val_loss: 0.0205\n",
      "Epoch 168/1000\n",
      " - 4s - loss: 0.0206 - val_loss: 0.0205\n",
      "Epoch 169/1000\n",
      " - 4s - loss: 0.0205 - val_loss: 0.0205\n",
      "Epoch 170/1000\n",
      " - 4s - loss: 0.0205 - val_loss: 0.0205\n",
      "Epoch 171/1000\n",
      " - 4s - loss: 0.0205 - val_loss: 0.0205\n",
      "Epoch 172/1000\n",
      " - 4s - loss: 0.0205 - val_loss: 0.0204\n",
      "Epoch 173/1000\n",
      " - 4s - loss: 0.0205 - val_loss: 0.0204\n",
      "Epoch 174/1000\n",
      " - 4s - loss: 0.0205 - val_loss: 0.0204\n",
      "Epoch 175/1000\n",
      " - 4s - loss: 0.0204 - val_loss: 0.0204\n",
      "Epoch 176/1000\n",
      " - 4s - loss: 0.0204 - val_loss: 0.0204\n",
      "Epoch 177/1000\n",
      " - 4s - loss: 0.0204 - val_loss: 0.0204\n",
      "Epoch 178/1000\n",
      " - 4s - loss: 0.0204 - val_loss: 0.0204\n",
      "Epoch 179/1000\n",
      " - 4s - loss: 0.0204 - val_loss: 0.0203\n",
      "Epoch 180/1000\n",
      " - 4s - loss: 0.0204 - val_loss: 0.0203\n",
      "Epoch 181/1000\n",
      " - 4s - loss: 0.0204 - val_loss: 0.0203\n",
      "Epoch 182/1000\n",
      " - 4s - loss: 0.0203 - val_loss: 0.0203\n",
      "Epoch 183/1000\n",
      " - 4s - loss: 0.0203 - val_loss: 0.0203\n",
      "Epoch 184/1000\n",
      " - 4s - loss: 0.0203 - val_loss: 0.0203\n",
      "Epoch 185/1000\n",
      " - 4s - loss: 0.0203 - val_loss: 0.0203\n",
      "Epoch 186/1000\n",
      " - 4s - loss: 0.0203 - val_loss: 0.0202\n",
      "Epoch 187/1000\n",
      " - 4s - loss: 0.0203 - val_loss: 0.0202\n",
      "Epoch 188/1000\n",
      " - 5s - loss: 0.0203 - val_loss: 0.0202\n",
      "Epoch 189/1000\n",
      " - 4s - loss: 0.0202 - val_loss: 0.0202\n",
      "Epoch 190/1000\n",
      " - 4s - loss: 0.0202 - val_loss: 0.0202\n",
      "Epoch 191/1000\n",
      " - 4s - loss: 0.0202 - val_loss: 0.0202\n",
      "Epoch 192/1000\n",
      " - 4s - loss: 0.0202 - val_loss: 0.0202\n",
      "Epoch 193/1000\n",
      " - 4s - loss: 0.0202 - val_loss: 0.0202\n",
      "Epoch 194/1000\n",
      " - 4s - loss: 0.0202 - val_loss: 0.0201\n",
      "Epoch 195/1000\n",
      " - 4s - loss: 0.0202 - val_loss: 0.0201\n",
      "Epoch 196/1000\n",
      " - 4s - loss: 0.0201 - val_loss: 0.0201\n",
      "Epoch 197/1000\n",
      " - 4s - loss: 0.0201 - val_loss: 0.0201\n",
      "Epoch 198/1000\n",
      " - 4s - loss: 0.0201 - val_loss: 0.0201\n",
      "Epoch 199/1000\n",
      " - 4s - loss: 0.0201 - val_loss: 0.0201\n",
      "Epoch 200/1000\n",
      " - 4s - loss: 0.0201 - val_loss: 0.0201\n",
      "Epoch 201/1000\n",
      " - 4s - loss: 0.0201 - val_loss: 0.0200\n",
      "Epoch 202/1000\n",
      " - 4s - loss: 0.0201 - val_loss: 0.0200\n",
      "Epoch 203/1000\n",
      " - 4s - loss: 0.0201 - val_loss: 0.0200\n",
      "Epoch 204/1000\n",
      " - 4s - loss: 0.0200 - val_loss: 0.0200\n",
      "Epoch 205/1000\n",
      " - 4s - loss: 0.0200 - val_loss: 0.0200\n",
      "Epoch 206/1000\n",
      " - 4s - loss: 0.0200 - val_loss: 0.0200\n",
      "Epoch 207/1000\n",
      " - 4s - loss: 0.0200 - val_loss: 0.0200\n",
      "Epoch 208/1000\n",
      " - 4s - loss: 0.0200 - val_loss: 0.0200\n",
      "Epoch 209/1000\n",
      " - 4s - loss: 0.0200 - val_loss: 0.0199\n",
      "Epoch 210/1000\n",
      " - 4s - loss: 0.0200 - val_loss: 0.0199\n",
      "Epoch 211/1000\n",
      " - 4s - loss: 0.0199 - val_loss: 0.0199\n",
      "Epoch 212/1000\n",
      " - 4s - loss: 0.0199 - val_loss: 0.0199\n",
      "Epoch 213/1000\n",
      " - 4s - loss: 0.0199 - val_loss: 0.0199\n",
      "Epoch 214/1000\n",
      " - 4s - loss: 0.0199 - val_loss: 0.0199\n",
      "Epoch 215/1000\n",
      " - 4s - loss: 0.0199 - val_loss: 0.0199\n",
      "Epoch 216/1000\n",
      " - 4s - loss: 0.0199 - val_loss: 0.0199\n",
      "Epoch 217/1000\n",
      " - 4s - loss: 0.0199 - val_loss: 0.0198\n",
      "Epoch 218/1000\n",
      " - 4s - loss: 0.0198 - val_loss: 0.0198\n",
      "Epoch 219/1000\n",
      " - 4s - loss: 0.0198 - val_loss: 0.0198\n",
      "Epoch 220/1000\n",
      " - 4s - loss: 0.0198 - val_loss: 0.0198\n",
      "Epoch 221/1000\n",
      " - 4s - loss: 0.0198 - val_loss: 0.0198\n",
      "Epoch 222/1000\n",
      " - 4s - loss: 0.0198 - val_loss: 0.0198\n",
      "Epoch 223/1000\n",
      " - 4s - loss: 0.0198 - val_loss: 0.0198\n",
      "Epoch 224/1000\n",
      " - 4s - loss: 0.0198 - val_loss: 0.0197\n",
      "Epoch 225/1000\n",
      " - 4s - loss: 0.0198 - val_loss: 0.0197\n",
      "Epoch 226/1000\n",
      " - 4s - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 227/1000\n",
      " - 4s - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 228/1000\n",
      " - 6s - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 229/1000\n",
      " - 4s - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 230/1000\n",
      " - 4s - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 231/1000\n",
      " - 4s - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 232/1000\n",
      " - 5s - loss: 0.0197 - val_loss: 0.0196\n",
      "Epoch 233/1000\n",
      " - 5s - loss: 0.0196 - val_loss: 0.0196\n",
      "Epoch 234/1000\n",
      " - 4s - loss: 0.0196 - val_loss: 0.0196\n",
      "Epoch 235/1000\n",
      " - 4s - loss: 0.0196 - val_loss: 0.0196\n",
      "Epoch 236/1000\n",
      " - 4s - loss: 0.0196 - val_loss: 0.0196\n",
      "Epoch 237/1000\n",
      " - 4s - loss: 0.0196 - val_loss: 0.0196\n",
      "Epoch 238/1000\n",
      " - 4s - loss: 0.0196 - val_loss: 0.0196\n",
      "Epoch 239/1000\n",
      " - 4s - loss: 0.0196 - val_loss: 0.0195\n",
      "Epoch 240/1000\n",
      " - 4s - loss: 0.0196 - val_loss: 0.0195\n",
      "Epoch 241/1000\n",
      " - 4s - loss: 0.0195 - val_loss: 0.0195\n",
      "Epoch 242/1000\n",
      " - 4s - loss: 0.0195 - val_loss: 0.0195\n",
      "Epoch 243/1000\n",
      " - 4s - loss: 0.0195 - val_loss: 0.0195\n",
      "Epoch 244/1000\n",
      " - 4s - loss: 0.0195 - val_loss: 0.0195\n",
      "Epoch 245/1000\n",
      " - 4s - loss: 0.0195 - val_loss: 0.0195\n",
      "Epoch 246/1000\n",
      " - 4s - loss: 0.0195 - val_loss: 0.0195\n",
      "Epoch 247/1000\n",
      " - 4s - loss: 0.0195 - val_loss: 0.0194\n",
      "Epoch 248/1000\n",
      " - 4s - loss: 0.0195 - val_loss: 0.0194\n",
      "Epoch 249/1000\n",
      " - 4s - loss: 0.0194 - val_loss: 0.0194\n",
      "Epoch 250/1000\n",
      " - 4s - loss: 0.0194 - val_loss: 0.0194\n",
      "Epoch 251/1000\n",
      " - 4s - loss: 0.0194 - val_loss: 0.0194\n",
      "Epoch 252/1000\n",
      " - 4s - loss: 0.0194 - val_loss: 0.0194\n",
      "Epoch 253/1000\n",
      " - 4s - loss: 0.0194 - val_loss: 0.0194\n",
      "Epoch 254/1000\n",
      " - 4s - loss: 0.0194 - val_loss: 0.0194\n",
      "Epoch 255/1000\n",
      " - 4s - loss: 0.0194 - val_loss: 0.0193\n",
      "Epoch 256/1000\n",
      " - 4s - loss: 0.0194 - val_loss: 0.0193\n",
      "Epoch 257/1000\n",
      " - 4s - loss: 0.0193 - val_loss: 0.0193\n",
      "Epoch 258/1000\n",
      " - 4s - loss: 0.0193 - val_loss: 0.0193\n",
      "Epoch 259/1000\n",
      " - 4s - loss: 0.0193 - val_loss: 0.0193\n",
      "Epoch 260/1000\n",
      " - 4s - loss: 0.0193 - val_loss: 0.0193\n",
      "Epoch 261/1000\n",
      " - 4s - loss: 0.0193 - val_loss: 0.0193\n",
      "Epoch 262/1000\n",
      " - 4s - loss: 0.0193 - val_loss: 0.0193\n",
      "Epoch 263/1000\n",
      " - 4s - loss: 0.0193 - val_loss: 0.0193\n",
      "Epoch 264/1000\n",
      " - 4s - loss: 0.0193 - val_loss: 0.0193\n",
      "Epoch 265/1000\n",
      " - 4s - loss: 0.0193 - val_loss: 0.0193\n",
      "Epoch 266/1000\n",
      " - 4s - loss: 0.0193 - val_loss: 0.0192\n",
      "Epoch 267/1000\n",
      " - 4s - loss: 0.0192 - val_loss: 0.0192\n",
      "Epoch 268/1000\n",
      " - 4s - loss: 0.0192 - val_loss: 0.0192\n",
      "Epoch 269/1000\n",
      " - 4s - loss: 0.0192 - val_loss: 0.0192\n",
      "Epoch 270/1000\n",
      " - 4s - loss: 0.0192 - val_loss: 0.0192\n",
      "Epoch 271/1000\n",
      " - 4s - loss: 0.0192 - val_loss: 0.0192\n",
      "Epoch 272/1000\n",
      " - 4s - loss: 0.0192 - val_loss: 0.0192\n",
      "Epoch 273/1000\n",
      " - 4s - loss: 0.0192 - val_loss: 0.0192\n",
      "Epoch 274/1000\n",
      " - 4s - loss: 0.0192 - val_loss: 0.0192\n",
      "Epoch 275/1000\n",
      " - 4s - loss: 0.0192 - val_loss: 0.0191\n",
      "Epoch 276/1000\n",
      " - 5s - loss: 0.0191 - val_loss: 0.0191\n",
      "Epoch 277/1000\n",
      " - 4s - loss: 0.0191 - val_loss: 0.0191\n",
      "Epoch 278/1000\n",
      " - 5s - loss: 0.0191 - val_loss: 0.0191\n",
      "Epoch 279/1000\n",
      " - 5s - loss: 0.0191 - val_loss: 0.0191\n",
      "Epoch 280/1000\n",
      " - 4s - loss: 0.0191 - val_loss: 0.0191\n",
      "Epoch 281/1000\n",
      " - 5s - loss: 0.0191 - val_loss: 0.0191\n",
      "Epoch 282/1000\n",
      " - 4s - loss: 0.0191 - val_loss: 0.0191\n",
      "Epoch 283/1000\n",
      " - 4s - loss: 0.0191 - val_loss: 0.0191\n",
      "Epoch 284/1000\n",
      " - 4s - loss: 0.0191 - val_loss: 0.0191\n",
      "Epoch 285/1000\n",
      " - 4s - loss: 0.0191 - val_loss: 0.0190\n",
      "Epoch 286/1000\n",
      " - 4s - loss: 0.0191 - val_loss: 0.0190\n",
      "Epoch 287/1000\n",
      " - 4s - loss: 0.0190 - val_loss: 0.0190\n",
      "Epoch 288/1000\n",
      " - 4s - loss: 0.0190 - val_loss: 0.0191\n",
      "Epoch 289/1000\n",
      " - 4s - loss: 0.0190 - val_loss: 0.0190\n",
      "Epoch 290/1000\n",
      " - 4s - loss: 0.0190 - val_loss: 0.0190\n",
      "Epoch 291/1000\n",
      " - 4s - loss: 0.0190 - val_loss: 0.0190\n",
      "Epoch 292/1000\n",
      " - 5s - loss: 0.0190 - val_loss: 0.0190\n",
      "Epoch 293/1000\n",
      " - 4s - loss: 0.0190 - val_loss: 0.0190\n",
      "Epoch 294/1000\n",
      " - 4s - loss: 0.0190 - val_loss: 0.0190\n",
      "Epoch 295/1000\n",
      " - 5s - loss: 0.0190 - val_loss: 0.0190\n",
      "Epoch 296/1000\n",
      " - 4s - loss: 0.0190 - val_loss: 0.0190\n",
      "Epoch 297/1000\n",
      " - 4s - loss: 0.0190 - val_loss: 0.0189\n",
      "Epoch 298/1000\n",
      " - 4s - loss: 0.0190 - val_loss: 0.0189\n",
      "Epoch 299/1000\n",
      " - 5s - loss: 0.0189 - val_loss: 0.0189\n",
      "Epoch 300/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 5s - loss: 0.0189 - val_loss: 0.0189\n",
      "Epoch 301/1000\n",
      " - 4s - loss: 0.0189 - val_loss: 0.0189\n",
      "Epoch 302/1000\n",
      " - 4s - loss: 0.0189 - val_loss: 0.0189\n",
      "Epoch 303/1000\n",
      " - 4s - loss: 0.0189 - val_loss: 0.0189\n",
      "Epoch 304/1000\n",
      " - 4s - loss: 0.0189 - val_loss: 0.0189\n",
      "Epoch 305/1000\n",
      " - 4s - loss: 0.0189 - val_loss: 0.0189\n",
      "Epoch 306/1000\n",
      " - 4s - loss: 0.0189 - val_loss: 0.0189\n",
      "Epoch 307/1000\n",
      " - 4s - loss: 0.0189 - val_loss: 0.0189\n",
      "Epoch 308/1000\n",
      " - 4s - loss: 0.0189 - val_loss: 0.0189\n",
      "Epoch 309/1000\n",
      " - 4s - loss: 0.0189 - val_loss: 0.0188\n",
      "Epoch 310/1000\n",
      " - 4s - loss: 0.0188 - val_loss: 0.0188\n",
      "Epoch 311/1000\n",
      " - 4s - loss: 0.0188 - val_loss: 0.0188\n",
      "Epoch 312/1000\n",
      " - 4s - loss: 0.0188 - val_loss: 0.0188\n",
      "Epoch 313/1000\n",
      " - 4s - loss: 0.0188 - val_loss: 0.0188\n",
      "Epoch 314/1000\n",
      " - 5s - loss: 0.0188 - val_loss: 0.0188\n",
      "Epoch 315/1000\n",
      " - 4s - loss: 0.0188 - val_loss: 0.0188\n",
      "Epoch 316/1000\n",
      " - 4s - loss: 0.0188 - val_loss: 0.0188\n",
      "Epoch 317/1000\n",
      " - 4s - loss: 0.0188 - val_loss: 0.0188\n",
      "Epoch 318/1000\n",
      " - 4s - loss: 0.0188 - val_loss: 0.0188\n",
      "Epoch 319/1000\n",
      " - 4s - loss: 0.0188 - val_loss: 0.0188\n",
      "Epoch 320/1000\n",
      " - 4s - loss: 0.0188 - val_loss: 0.0188\n",
      "Epoch 321/1000\n",
      " - 4s - loss: 0.0188 - val_loss: 0.0188\n",
      "Epoch 322/1000\n",
      " - 5s - loss: 0.0188 - val_loss: 0.0187\n",
      "Epoch 323/1000\n",
      " - 4s - loss: 0.0188 - val_loss: 0.0188\n",
      "Epoch 324/1000\n",
      " - 4s - loss: 0.0188 - val_loss: 0.0187\n",
      "Epoch 325/1000\n",
      " - 4s - loss: 0.0187 - val_loss: 0.0187\n",
      "Epoch 326/1000\n",
      " - 5s - loss: 0.0187 - val_loss: 0.0187\n",
      "Epoch 327/1000\n",
      " - 5s - loss: 0.0187 - val_loss: 0.0187\n",
      "Epoch 328/1000\n",
      " - 5s - loss: 0.0187 - val_loss: 0.0187\n",
      "Epoch 329/1000\n",
      " - 5s - loss: 0.0187 - val_loss: 0.0187\n",
      "Epoch 330/1000\n",
      " - 4s - loss: 0.0187 - val_loss: 0.0187\n",
      "Epoch 331/1000\n",
      " - 4s - loss: 0.0187 - val_loss: 0.0187\n",
      "Epoch 332/1000\n",
      " - 4s - loss: 0.0187 - val_loss: 0.0187\n",
      "Epoch 333/1000\n",
      " - 4s - loss: 0.0187 - val_loss: 0.0187\n",
      "Epoch 334/1000\n",
      " - 5s - loss: 0.0187 - val_loss: 0.0187\n",
      "Epoch 335/1000\n",
      " - 5s - loss: 0.0187 - val_loss: 0.0187\n",
      "Epoch 336/1000\n",
      " - 5s - loss: 0.0187 - val_loss: 0.0186\n",
      "Epoch 337/1000\n",
      " - 4s - loss: 0.0187 - val_loss: 0.0187\n",
      "Epoch 338/1000\n",
      " - 4s - loss: 0.0187 - val_loss: 0.0186\n",
      "Epoch 339/1000\n",
      " - 4s - loss: 0.0186 - val_loss: 0.0186\n",
      "Epoch 340/1000\n",
      " - 4s - loss: 0.0186 - val_loss: 0.0186\n",
      "Epoch 341/1000\n",
      " - 4s - loss: 0.0186 - val_loss: 0.0186\n",
      "Epoch 342/1000\n",
      " - 4s - loss: 0.0186 - val_loss: 0.0186\n",
      "Epoch 343/1000\n",
      " - 4s - loss: 0.0186 - val_loss: 0.0186\n",
      "Epoch 344/1000\n",
      " - 4s - loss: 0.0186 - val_loss: 0.0186\n",
      "Epoch 345/1000\n",
      " - 4s - loss: 0.0186 - val_loss: 0.0186\n",
      "Epoch 346/1000\n",
      " - 5s - loss: 0.0186 - val_loss: 0.0186\n",
      "Epoch 347/1000\n",
      " - 4s - loss: 0.0186 - val_loss: 0.0186\n",
      "Epoch 348/1000\n",
      " - 4s - loss: 0.0186 - val_loss: 0.0186\n",
      "Epoch 349/1000\n",
      " - 4s - loss: 0.0186 - val_loss: 0.0186\n",
      "Epoch 350/1000\n",
      " - 4s - loss: 0.0186 - val_loss: 0.0186\n",
      "Epoch 351/1000\n",
      " - 4s - loss: 0.0186 - val_loss: 0.0186\n",
      "Epoch 352/1000\n",
      " - 4s - loss: 0.0186 - val_loss: 0.0185\n",
      "Epoch 353/1000\n",
      " - 4s - loss: 0.0186 - val_loss: 0.0185\n",
      "Epoch 354/1000\n",
      " - 4s - loss: 0.0185 - val_loss: 0.0185\n",
      "Epoch 355/1000\n",
      " - 4s - loss: 0.0185 - val_loss: 0.0185\n",
      "Epoch 356/1000\n",
      " - 5s - loss: 0.0185 - val_loss: 0.0185\n",
      "Epoch 357/1000\n",
      " - 4s - loss: 0.0185 - val_loss: 0.0185\n",
      "Epoch 358/1000\n",
      " - 5s - loss: 0.0185 - val_loss: 0.0185\n",
      "Epoch 359/1000\n",
      " - 5s - loss: 0.0185 - val_loss: 0.0185\n",
      "Epoch 360/1000\n",
      " - 4s - loss: 0.0185 - val_loss: 0.0185\n",
      "Epoch 361/1000\n",
      " - 4s - loss: 0.0185 - val_loss: 0.0185\n",
      "Epoch 362/1000\n",
      " - 5s - loss: 0.0185 - val_loss: 0.0185\n",
      "Epoch 363/1000\n",
      " - 5s - loss: 0.0185 - val_loss: 0.0185\n",
      "Epoch 364/1000\n",
      " - 5s - loss: 0.0185 - val_loss: 0.0185\n",
      "Epoch 365/1000\n",
      " - 5s - loss: 0.0185 - val_loss: 0.0185\n",
      "Epoch 366/1000\n",
      " - 4s - loss: 0.0185 - val_loss: 0.0185\n",
      "Epoch 367/1000\n",
      " - 4s - loss: 0.0185 - val_loss: 0.0185\n",
      "Epoch 368/1000\n",
      " - 4s - loss: 0.0185 - val_loss: 0.0184\n",
      "Epoch 369/1000\n",
      " - 4s - loss: 0.0185 - val_loss: 0.0185\n",
      "Epoch 370/1000\n",
      " - 4s - loss: 0.0184 - val_loss: 0.0184\n",
      "Epoch 371/1000\n",
      " - 4s - loss: 0.0184 - val_loss: 0.0184\n",
      "Epoch 372/1000\n",
      " - 4s - loss: 0.0184 - val_loss: 0.0184\n",
      "Epoch 373/1000\n",
      " - 4s - loss: 0.0184 - val_loss: 0.0184\n",
      "Epoch 374/1000\n",
      " - 4s - loss: 0.0184 - val_loss: 0.0184\n",
      "Epoch 375/1000\n",
      " - 4s - loss: 0.0184 - val_loss: 0.0184\n",
      "Epoch 376/1000\n",
      " - 4s - loss: 0.0184 - val_loss: 0.0185\n",
      "Epoch 377/1000\n",
      " - 4s - loss: 0.0184 - val_loss: 0.0184\n",
      "Epoch 378/1000\n",
      " - 4s - loss: 0.0184 - val_loss: 0.0184\n",
      "Epoch 379/1000\n",
      " - 4s - loss: 0.0184 - val_loss: 0.0184\n",
      "Epoch 380/1000\n",
      " - 4s - loss: 0.0184 - val_loss: 0.0184\n",
      "Epoch 381/1000\n",
      " - 4s - loss: 0.0184 - val_loss: 0.0184\n",
      "Epoch 382/1000\n",
      " - 5s - loss: 0.0184 - val_loss: 0.0184\n",
      "Epoch 383/1000\n",
      " - 4s - loss: 0.0184 - val_loss: 0.0184\n",
      "Epoch 384/1000\n",
      " - 4s - loss: 0.0184 - val_loss: 0.0184\n",
      "Epoch 385/1000\n",
      " - 4s - loss: 0.0184 - val_loss: 0.0184\n",
      "Epoch 386/1000\n",
      " - 4s - loss: 0.0184 - val_loss: 0.0184\n",
      "Epoch 387/1000\n",
      " - 4s - loss: 0.0184 - val_loss: 0.0183\n",
      "Epoch 388/1000\n",
      " - 4s - loss: 0.0183 - val_loss: 0.0184\n",
      "Epoch 389/1000\n",
      " - 4s - loss: 0.0183 - val_loss: 0.0183\n",
      "Epoch 390/1000\n",
      " - 4s - loss: 0.0183 - val_loss: 0.0183\n",
      "Epoch 391/1000\n",
      " - 4s - loss: 0.0183 - val_loss: 0.0183\n",
      "Epoch 392/1000\n",
      " - 4s - loss: 0.0183 - val_loss: 0.0183\n",
      "Epoch 393/1000\n",
      " - 5s - loss: 0.0183 - val_loss: 0.0183\n",
      "Epoch 394/1000\n",
      " - 5s - loss: 0.0183 - val_loss: 0.0183\n",
      "Epoch 395/1000\n",
      " - 6s - loss: 0.0183 - val_loss: 0.0183\n",
      "Epoch 396/1000\n",
      " - 4s - loss: 0.0183 - val_loss: 0.0183\n",
      "Epoch 397/1000\n",
      " - 6s - loss: 0.0183 - val_loss: 0.0183\n",
      "Epoch 398/1000\n",
      " - 5s - loss: 0.0183 - val_loss: 0.0183\n",
      "Epoch 399/1000\n",
      " - 4s - loss: 0.0183 - val_loss: 0.0183\n",
      "Epoch 400/1000\n",
      " - 5s - loss: 0.0183 - val_loss: 0.0183\n",
      "Epoch 401/1000\n",
      " - 4s - loss: 0.0183 - val_loss: 0.0183\n",
      "Epoch 402/1000\n",
      " - 4s - loss: 0.0183 - val_loss: 0.0183\n",
      "Epoch 403/1000\n",
      " - 5s - loss: 0.0183 - val_loss: 0.0183\n",
      "Epoch 404/1000\n",
      " - 4s - loss: 0.0183 - val_loss: 0.0183\n",
      "Epoch 405/1000\n",
      " - 4s - loss: 0.0183 - val_loss: 0.0183\n",
      "Epoch 406/1000\n",
      " - 6s - loss: 0.0183 - val_loss: 0.0183\n",
      "Epoch 407/1000\n",
      " - 5s - loss: 0.0183 - val_loss: 0.0182\n",
      "Epoch 408/1000\n",
      " - 4s - loss: 0.0182 - val_loss: 0.0182\n",
      "Epoch 409/1000\n",
      " - 4s - loss: 0.0182 - val_loss: 0.0183\n",
      "Epoch 410/1000\n",
      " - 4s - loss: 0.0182 - val_loss: 0.0182\n",
      "Epoch 411/1000\n",
      " - 4s - loss: 0.0182 - val_loss: 0.0182\n",
      "Epoch 412/1000\n",
      " - 4s - loss: 0.0182 - val_loss: 0.0182\n",
      "Epoch 413/1000\n",
      " - 4s - loss: 0.0182 - val_loss: 0.0182\n",
      "Epoch 414/1000\n",
      " - 4s - loss: 0.0182 - val_loss: 0.0182\n",
      "Epoch 415/1000\n",
      " - 4s - loss: 0.0182 - val_loss: 0.0182\n",
      "Epoch 416/1000\n",
      " - 4s - loss: 0.0182 - val_loss: 0.0182\n",
      "Epoch 417/1000\n",
      " - 4s - loss: 0.0182 - val_loss: 0.0182\n",
      "Epoch 418/1000\n",
      " - 4s - loss: 0.0182 - val_loss: 0.0182\n",
      "Epoch 419/1000\n",
      " - 4s - loss: 0.0182 - val_loss: 0.0182\n",
      "Epoch 420/1000\n",
      " - 4s - loss: 0.0182 - val_loss: 0.0182\n",
      "Epoch 421/1000\n",
      " - 4s - loss: 0.0182 - val_loss: 0.0182\n",
      "Epoch 422/1000\n",
      " - 4s - loss: 0.0182 - val_loss: 0.0182\n",
      "Epoch 423/1000\n",
      " - 4s - loss: 0.0182 - val_loss: 0.0182\n",
      "Epoch 424/1000\n",
      " - 5s - loss: 0.0182 - val_loss: 0.0182\n",
      "Epoch 425/1000\n",
      " - 4s - loss: 0.0182 - val_loss: 0.0181\n",
      "Epoch 426/1000\n",
      " - 4s - loss: 0.0182 - val_loss: 0.0182\n",
      "Epoch 427/1000\n",
      " - 5s - loss: 0.0182 - val_loss: 0.0182\n",
      "Epoch 428/1000\n",
      " - 4s - loss: 0.0182 - val_loss: 0.0181\n",
      "Epoch 429/1000\n",
      " - 4s - loss: 0.0181 - val_loss: 0.0181\n",
      "Epoch 430/1000\n",
      " - 4s - loss: 0.0181 - val_loss: 0.0181\n",
      "Epoch 431/1000\n",
      " - 4s - loss: 0.0181 - val_loss: 0.0181\n",
      "Epoch 432/1000\n",
      " - 4s - loss: 0.0181 - val_loss: 0.0181\n",
      "Epoch 433/1000\n",
      " - 4s - loss: 0.0181 - val_loss: 0.0181\n",
      "Epoch 434/1000\n",
      " - 4s - loss: 0.0181 - val_loss: 0.0181\n",
      "Epoch 435/1000\n",
      " - 4s - loss: 0.0181 - val_loss: 0.0181\n",
      "Epoch 436/1000\n",
      " - 4s - loss: 0.0181 - val_loss: 0.0181\n",
      "Epoch 437/1000\n",
      " - 4s - loss: 0.0181 - val_loss: 0.0181\n",
      "Epoch 438/1000\n",
      " - 4s - loss: 0.0181 - val_loss: 0.0181\n",
      "Epoch 439/1000\n",
      " - 4s - loss: 0.0181 - val_loss: 0.0181\n",
      "Epoch 440/1000\n",
      " - 4s - loss: 0.0181 - val_loss: 0.0181\n",
      "Epoch 441/1000\n",
      " - 4s - loss: 0.0181 - val_loss: 0.0181\n",
      "Epoch 442/1000\n",
      " - 4s - loss: 0.0181 - val_loss: 0.0181\n",
      "Epoch 443/1000\n",
      " - 5s - loss: 0.0181 - val_loss: 0.0181\n",
      "Epoch 444/1000\n",
      " - 4s - loss: 0.0181 - val_loss: 0.0181\n",
      "Epoch 445/1000\n",
      " - 4s - loss: 0.0181 - val_loss: 0.0181\n",
      "Epoch 446/1000\n",
      " - 4s - loss: 0.0181 - val_loss: 0.0181\n",
      "Epoch 447/1000\n",
      " - 4s - loss: 0.0181 - val_loss: 0.0181\n",
      "Epoch 448/1000\n",
      " - 4s - loss: 0.0181 - val_loss: 0.0181\n",
      "Epoch 449/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 4s - loss: 0.0180 - val_loss: 0.0180\n",
      "Epoch 450/1000\n",
      " - 4s - loss: 0.0180 - val_loss: 0.0180\n",
      "Epoch 451/1000\n",
      " - 4s - loss: 0.0180 - val_loss: 0.0181\n",
      "Epoch 452/1000\n",
      " - 4s - loss: 0.0180 - val_loss: 0.0180\n",
      "Epoch 453/1000\n",
      " - 4s - loss: 0.0180 - val_loss: 0.0181\n",
      "Epoch 454/1000\n",
      " - 4s - loss: 0.0180 - val_loss: 0.0180\n",
      "Epoch 455/1000\n",
      " - 4s - loss: 0.0180 - val_loss: 0.0180\n",
      "Epoch 456/1000\n",
      " - 4s - loss: 0.0180 - val_loss: 0.0180\n",
      "Epoch 457/1000\n",
      " - 4s - loss: 0.0180 - val_loss: 0.0180\n",
      "Epoch 458/1000\n",
      " - 4s - loss: 0.0180 - val_loss: 0.0180\n",
      "Epoch 459/1000\n",
      " - 4s - loss: 0.0180 - val_loss: 0.0180\n",
      "Epoch 460/1000\n",
      " - 4s - loss: 0.0180 - val_loss: 0.0180\n",
      "Epoch 461/1000\n",
      " - 4s - loss: 0.0180 - val_loss: 0.0180\n",
      "Epoch 462/1000\n",
      " - 4s - loss: 0.0180 - val_loss: 0.0180\n",
      "Epoch 463/1000\n",
      " - 4s - loss: 0.0180 - val_loss: 0.0180\n",
      "Epoch 464/1000\n",
      " - 4s - loss: 0.0180 - val_loss: 0.0180\n",
      "Epoch 465/1000\n",
      " - 4s - loss: 0.0180 - val_loss: 0.0180\n",
      "Epoch 466/1000\n",
      " - 4s - loss: 0.0180 - val_loss: 0.0180\n",
      "Epoch 467/1000\n",
      " - 4s - loss: 0.0180 - val_loss: 0.0180\n",
      "Epoch 468/1000\n",
      " - 4s - loss: 0.0180 - val_loss: 0.0180\n",
      "Epoch 469/1000\n",
      " - 4s - loss: 0.0180 - val_loss: 0.0180\n",
      "Epoch 470/1000\n",
      " - 5s - loss: 0.0180 - val_loss: 0.0180\n",
      "Epoch 471/1000\n",
      " - 5s - loss: 0.0180 - val_loss: 0.0180\n",
      "Epoch 472/1000\n",
      " - 4s - loss: 0.0180 - val_loss: 0.0180\n",
      "Epoch 473/1000\n",
      " - 4s - loss: 0.0180 - val_loss: 0.0179\n",
      "Epoch 474/1000\n",
      " - 4s - loss: 0.0179 - val_loss: 0.0179\n",
      "Epoch 475/1000\n",
      " - 4s - loss: 0.0179 - val_loss: 0.0180\n",
      "Epoch 476/1000\n",
      " - 4s - loss: 0.0179 - val_loss: 0.0179\n",
      "Epoch 477/1000\n",
      " - 4s - loss: 0.0179 - val_loss: 0.0180\n",
      "Epoch 478/1000\n",
      " - 4s - loss: 0.0180 - val_loss: 0.0179\n",
      "Epoch 479/1000\n",
      " - 4s - loss: 0.0179 - val_loss: 0.0179\n",
      "Epoch 480/1000\n",
      " - 4s - loss: 0.0179 - val_loss: 0.0179\n",
      "Epoch 481/1000\n",
      " - 4s - loss: 0.0179 - val_loss: 0.0179\n",
      "Epoch 482/1000\n",
      " - 4s - loss: 0.0179 - val_loss: 0.0180\n",
      "Epoch 483/1000\n",
      " - 4s - loss: 0.0179 - val_loss: 0.0179\n",
      "Epoch 484/1000\n",
      " - 4s - loss: 0.0179 - val_loss: 0.0179\n",
      "Epoch 485/1000\n",
      " - 4s - loss: 0.0179 - val_loss: 0.0179\n",
      "Epoch 486/1000\n",
      " - 4s - loss: 0.0179 - val_loss: 0.0179\n",
      "Epoch 487/1000\n",
      " - 4s - loss: 0.0179 - val_loss: 0.0179\n",
      "Epoch 488/1000\n",
      " - 4s - loss: 0.0179 - val_loss: 0.0179\n",
      "Epoch 489/1000\n",
      " - 4s - loss: 0.0179 - val_loss: 0.0179\n",
      "Epoch 490/1000\n",
      " - 5s - loss: 0.0179 - val_loss: 0.0179\n",
      "Epoch 491/1000\n",
      " - 5s - loss: 0.0179 - val_loss: 0.0179\n",
      "Epoch 492/1000\n",
      " - 4s - loss: 0.0179 - val_loss: 0.0179\n",
      "Epoch 493/1000\n",
      " - 4s - loss: 0.0179 - val_loss: 0.0179\n",
      "Epoch 494/1000\n",
      " - 4s - loss: 0.0179 - val_loss: 0.0179\n",
      "Epoch 495/1000\n",
      " - 4s - loss: 0.0179 - val_loss: 0.0179\n",
      "Epoch 496/1000\n",
      " - 4s - loss: 0.0179 - val_loss: 0.0179\n",
      "Epoch 497/1000\n",
      " - 4s - loss: 0.0179 - val_loss: 0.0179\n",
      "Epoch 498/1000\n",
      " - 4s - loss: 0.0179 - val_loss: 0.0179\n",
      "Epoch 499/1000\n",
      " - 4s - loss: 0.0179 - val_loss: 0.0179\n",
      "Epoch 500/1000\n",
      " - 4s - loss: 0.0179 - val_loss: 0.0179\n",
      "Epoch 501/1000\n",
      " - 4s - loss: 0.0178 - val_loss: 0.0179\n",
      "Epoch 502/1000\n",
      " - 4s - loss: 0.0178 - val_loss: 0.0179\n",
      "Epoch 503/1000\n",
      " - 4s - loss: 0.0178 - val_loss: 0.0179\n",
      "Epoch 504/1000\n",
      " - 4s - loss: 0.0179 - val_loss: 0.0179\n",
      "Epoch 505/1000\n",
      " - 5s - loss: 0.0178 - val_loss: 0.0178\n",
      "Epoch 506/1000\n",
      " - 5s - loss: 0.0178 - val_loss: 0.0178\n",
      "Epoch 507/1000\n",
      " - 5s - loss: 0.0178 - val_loss: 0.0178\n",
      "Epoch 508/1000\n",
      " - 5s - loss: 0.0178 - val_loss: 0.0178\n",
      "Epoch 509/1000\n",
      " - 4s - loss: 0.0178 - val_loss: 0.0178\n",
      "Epoch 510/1000\n",
      " - 4s - loss: 0.0178 - val_loss: 0.0178\n",
      "Epoch 511/1000\n",
      " - 4s - loss: 0.0178 - val_loss: 0.0178\n",
      "Epoch 512/1000\n",
      " - 4s - loss: 0.0178 - val_loss: 0.0178\n",
      "Epoch 513/1000\n",
      " - 4s - loss: 0.0178 - val_loss: 0.0178\n",
      "Epoch 514/1000\n",
      " - 4s - loss: 0.0178 - val_loss: 0.0178\n",
      "Epoch 515/1000\n",
      " - 4s - loss: 0.0178 - val_loss: 0.0178\n",
      "Epoch 516/1000\n",
      " - 4s - loss: 0.0178 - val_loss: 0.0178\n",
      "Epoch 517/1000\n",
      " - 4s - loss: 0.0178 - val_loss: 0.0178\n",
      "Epoch 518/1000\n",
      " - 4s - loss: 0.0178 - val_loss: 0.0178\n",
      "Epoch 519/1000\n",
      " - 4s - loss: 0.0178 - val_loss: 0.0178\n",
      "Epoch 520/1000\n",
      " - 4s - loss: 0.0178 - val_loss: 0.0178\n",
      "Epoch 521/1000\n",
      " - 4s - loss: 0.0178 - val_loss: 0.0178\n",
      "Epoch 522/1000\n",
      " - 4s - loss: 0.0178 - val_loss: 0.0178\n",
      "Epoch 523/1000\n",
      " - 4s - loss: 0.0178 - val_loss: 0.0178\n",
      "Epoch 524/1000\n",
      " - 4s - loss: 0.0178 - val_loss: 0.0178\n",
      "Epoch 525/1000\n",
      " - 4s - loss: 0.0178 - val_loss: 0.0178\n",
      "Epoch 526/1000\n",
      " - 4s - loss: 0.0178 - val_loss: 0.0178\n",
      "Epoch 527/1000\n",
      " - 4s - loss: 0.0178 - val_loss: 0.0178\n",
      "Epoch 528/1000\n",
      " - 4s - loss: 0.0178 - val_loss: 0.0178\n",
      "Epoch 529/1000\n",
      " - 4s - loss: 0.0178 - val_loss: 0.0178\n",
      "Epoch 530/1000\n",
      " - 4s - loss: 0.0178 - val_loss: 0.0178\n",
      "Epoch 531/1000\n",
      " - 4s - loss: 0.0177 - val_loss: 0.0178\n",
      "Epoch 532/1000\n",
      " - 5s - loss: 0.0177 - val_loss: 0.0178\n",
      "Epoch 533/1000\n",
      " - 4s - loss: 0.0177 - val_loss: 0.0177\n",
      "Epoch 534/1000\n",
      " - 4s - loss: 0.0177 - val_loss: 0.0177\n",
      "Epoch 535/1000\n",
      " - 4s - loss: 0.0177 - val_loss: 0.0178\n",
      "Epoch 536/1000\n",
      " - 5s - loss: 0.0177 - val_loss: 0.0177\n",
      "Epoch 537/1000\n",
      " - 5s - loss: 0.0177 - val_loss: 0.0178\n",
      "Epoch 538/1000\n",
      " - 5s - loss: 0.0177 - val_loss: 0.0177\n",
      "Epoch 539/1000\n",
      " - 5s - loss: 0.0177 - val_loss: 0.0177\n",
      "Epoch 540/1000\n",
      " - 5s - loss: 0.0177 - val_loss: 0.0178\n",
      "Epoch 541/1000\n",
      " - 4s - loss: 0.0177 - val_loss: 0.0178\n",
      "Epoch 542/1000\n",
      " - 5s - loss: 0.0177 - val_loss: 0.0177\n",
      "Epoch 543/1000\n",
      " - 4s - loss: 0.0177 - val_loss: 0.0177\n",
      "Epoch 544/1000\n",
      " - 4s - loss: 0.0177 - val_loss: 0.0177\n",
      "Epoch 545/1000\n",
      " - 5s - loss: 0.0177 - val_loss: 0.0177\n",
      "Epoch 546/1000\n",
      " - 4s - loss: 0.0177 - val_loss: 0.0177\n",
      "Epoch 547/1000\n",
      " - 4s - loss: 0.0177 - val_loss: 0.0177\n",
      "Epoch 548/1000\n",
      " - 4s - loss: 0.0177 - val_loss: 0.0177\n",
      "Epoch 549/1000\n",
      " - 5s - loss: 0.0177 - val_loss: 0.0177\n",
      "Epoch 550/1000\n",
      " - 5s - loss: 0.0177 - val_loss: 0.0177\n",
      "Epoch 551/1000\n",
      " - 5s - loss: 0.0177 - val_loss: 0.0177\n",
      "Epoch 552/1000\n",
      " - 4s - loss: 0.0177 - val_loss: 0.0177\n",
      "Epoch 553/1000\n",
      " - 5s - loss: 0.0177 - val_loss: 0.0177\n",
      "Epoch 554/1000\n",
      " - 4s - loss: 0.0177 - val_loss: 0.0177\n",
      "Epoch 555/1000\n",
      " - 4s - loss: 0.0177 - val_loss: 0.0177\n",
      "Epoch 556/1000\n",
      " - 4s - loss: 0.0177 - val_loss: 0.0177\n",
      "Epoch 557/1000\n",
      " - 4s - loss: 0.0177 - val_loss: 0.0177\n",
      "Epoch 558/1000\n",
      " - 4s - loss: 0.0177 - val_loss: 0.0177\n",
      "Epoch 559/1000\n",
      " - 4s - loss: 0.0177 - val_loss: 0.0177\n",
      "Epoch 560/1000\n",
      " - 4s - loss: 0.0177 - val_loss: 0.0177\n",
      "Epoch 561/1000\n",
      " - 4s - loss: 0.0177 - val_loss: 0.0177\n",
      "Epoch 562/1000\n",
      " - 4s - loss: 0.0177 - val_loss: 0.0177\n",
      "Epoch 563/1000\n",
      " - 4s - loss: 0.0177 - val_loss: 0.0177\n",
      "Epoch 564/1000\n",
      " - 4s - loss: 0.0177 - val_loss: 0.0177\n",
      "Epoch 565/1000\n",
      " - 4s - loss: 0.0177 - val_loss: 0.0177\n",
      "Epoch 566/1000\n",
      " - 4s - loss: 0.0177 - val_loss: 0.0177\n",
      "Epoch 567/1000\n",
      " - 4s - loss: 0.0176 - val_loss: 0.0176\n",
      "Epoch 568/1000\n",
      " - 4s - loss: 0.0176 - val_loss: 0.0176\n",
      "Epoch 569/1000\n",
      " - 4s - loss: 0.0176 - val_loss: 0.0177\n",
      "Epoch 570/1000\n",
      " - 4s - loss: 0.0176 - val_loss: 0.0176\n",
      "Epoch 571/1000\n",
      " - 4s - loss: 0.0176 - val_loss: 0.0176\n",
      "Epoch 572/1000\n",
      " - 4s - loss: 0.0176 - val_loss: 0.0177\n",
      "Epoch 573/1000\n",
      " - 4s - loss: 0.0176 - val_loss: 0.0176\n",
      "Epoch 574/1000\n",
      " - 4s - loss: 0.0176 - val_loss: 0.0176\n",
      "Epoch 575/1000\n",
      " - 4s - loss: 0.0176 - val_loss: 0.0176\n",
      "Epoch 576/1000\n",
      " - 4s - loss: 0.0176 - val_loss: 0.0176\n",
      "Epoch 577/1000\n",
      " - 4s - loss: 0.0176 - val_loss: 0.0176\n",
      "Epoch 578/1000\n",
      " - 4s - loss: 0.0176 - val_loss: 0.0176\n",
      "Epoch 579/1000\n",
      " - 5s - loss: 0.0176 - val_loss: 0.0176\n",
      "Epoch 580/1000\n",
      " - 5s - loss: 0.0176 - val_loss: 0.0176\n",
      "Epoch 581/1000\n",
      " - 5s - loss: 0.0176 - val_loss: 0.0176\n",
      "Epoch 582/1000\n",
      " - 5s - loss: 0.0176 - val_loss: 0.0176\n",
      "Epoch 583/1000\n",
      " - 4s - loss: 0.0176 - val_loss: 0.0176\n",
      "Epoch 584/1000\n",
      " - 4s - loss: 0.0176 - val_loss: 0.0176\n",
      "Epoch 585/1000\n",
      " - 4s - loss: 0.0176 - val_loss: 0.0176\n",
      "Epoch 586/1000\n",
      " - 4s - loss: 0.0176 - val_loss: 0.0176\n",
      "Epoch 587/1000\n",
      " - 4s - loss: 0.0176 - val_loss: 0.0176\n",
      "Epoch 588/1000\n",
      " - 4s - loss: 0.0176 - val_loss: 0.0176\n",
      "Epoch 589/1000\n",
      " - 4s - loss: 0.0176 - val_loss: 0.0177\n",
      "Epoch 590/1000\n",
      " - 4s - loss: 0.0176 - val_loss: 0.0176\n",
      "Epoch 591/1000\n",
      " - 4s - loss: 0.0176 - val_loss: 0.0176\n",
      "Epoch 592/1000\n",
      " - 4s - loss: 0.0176 - val_loss: 0.0176\n",
      "Epoch 593/1000\n",
      " - 5s - loss: 0.0176 - val_loss: 0.0176\n",
      "Epoch 594/1000\n",
      " - 5s - loss: 0.0176 - val_loss: 0.0176\n",
      "Epoch 595/1000\n",
      " - 5s - loss: 0.0176 - val_loss: 0.0176\n",
      "Epoch 596/1000\n",
      " - 5s - loss: 0.0176 - val_loss: 0.0176\n",
      "Epoch 597/1000\n",
      " - 5s - loss: 0.0176 - val_loss: 0.0176\n",
      "Epoch 598/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 5s - loss: 0.0176 - val_loss: 0.0176\n",
      "Epoch 599/1000\n",
      " - 5s - loss: 0.0176 - val_loss: 0.0176\n",
      "Epoch 600/1000\n",
      " - 5s - loss: 0.0176 - val_loss: 0.0176\n",
      "Epoch 601/1000\n",
      " - 5s - loss: 0.0176 - val_loss: 0.0176\n",
      "Epoch 602/1000\n",
      " - 5s - loss: 0.0176 - val_loss: 0.0176\n",
      "Epoch 603/1000\n",
      " - 6s - loss: 0.0176 - val_loss: 0.0176\n",
      "Epoch 604/1000\n",
      " - 5s - loss: 0.0176 - val_loss: 0.0176\n",
      "Epoch 605/1000\n",
      " - 5s - loss: 0.0175 - val_loss: 0.0176\n",
      "Epoch 606/1000\n",
      " - 5s - loss: 0.0175 - val_loss: 0.0176\n",
      "Epoch 607/1000\n",
      " - 5s - loss: 0.0175 - val_loss: 0.0175\n",
      "Epoch 608/1000\n",
      " - 5s - loss: 0.0175 - val_loss: 0.0176\n",
      "Epoch 609/1000\n",
      " - 5s - loss: 0.0175 - val_loss: 0.0175\n",
      "Epoch 610/1000\n",
      " - 5s - loss: 0.0175 - val_loss: 0.0175\n",
      "Epoch 611/1000\n",
      " - 5s - loss: 0.0175 - val_loss: 0.0175\n",
      "Epoch 612/1000\n",
      " - 5s - loss: 0.0175 - val_loss: 0.0176\n",
      "Epoch 613/1000\n",
      " - 5s - loss: 0.0175 - val_loss: 0.0176\n",
      "Epoch 614/1000\n",
      " - 5s - loss: 0.0175 - val_loss: 0.0176\n",
      "Epoch 615/1000\n",
      " - 5s - loss: 0.0175 - val_loss: 0.0175\n",
      "Epoch 616/1000\n",
      " - 5s - loss: 0.0175 - val_loss: 0.0176\n",
      "Epoch 00616: early stopping\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "batch_size = 64\n",
    "real_autoencoder_history = real_autoencoder.fit(\n",
    "    df_real_test_ss, \n",
    "    df_real_test_ss, \n",
    "    epochs = epochs,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True,\n",
    "    verbose = 2,\n",
    "    # validation_data = (df_real_val_ss, df_real_val_ss),\n",
    "    validation_split = (1 / 3),\n",
    "    callbacks = [\n",
    "                 real_early_stopping, \n",
    "#                  real_checkpoint, \n",
    "#                  real_csv_logger\n",
    "                 ]\n",
    ").history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5OnSM1niHyYs"
   },
   "source": [
    "## Load Trained Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l3QoqoPRlxPv"
   },
   "outputs": [],
   "source": [
    "# real_autoencoder_history = pd.read_csv(\"../models/04_autoencoder_knn/history.csv\")\n",
    "# # real_autoencoder_history = pd.read_csv(\"/content/drive/My Drive/Project/real_models/history.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "6MRkR9RUmWxF",
    "outputId": "911803c3-d27c-4b81-c8ff-7956298f7df3"
   },
   "outputs": [],
   "source": [
    "# real_autoencoder.load_weights(f\"../models/04_autoencoder_knn/0070.hdf5\")\n",
    "# # real_autoencoder.load_weights(f\"/content/drive/My Drive/Project/real_models/0070.hdf5\")\n",
    "# # real_autoencoder.compile (optimizer = 'adam', loss = 'binary_crossentropy')\n",
    "# # real_autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ov1xqzICGAFP"
   },
   "source": [
    "## Visualise Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T08:33:46.809219Z",
     "start_time": "2019-11-14T08:33:45.853822Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "7Vbe6RS9GAFP",
    "outputId": "97e556ba-4f7d-46d1-edb4-60f8600cdca9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(*args, **kw)>"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize = (16,9), dpi = 72)\n",
    "ax.plot(real_autoencoder_history['loss'], 'b', label='Train', linewidth = 2)\n",
    "ax.plot(real_autoencoder_history['val_loss'], 'r', label = 'Validation', linewidth = 2)\n",
    "ax.set_title('Model Loss', fontsize = 20)\n",
    "ax.set_ylabel('Loss (MSE)')\n",
    "ax.set_xlabel('Epoch')\n",
    "# ax.set_xlim(5,20)\n",
    "# ax.set_ylim(0.02,0.03)\n",
    "ax.legend(loc='best')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T08:46:45.244473Z",
     "start_time": "2019-11-14T08:46:11.073265Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "DDLjG4HkGAFQ"
   },
   "outputs": [],
   "source": [
    "encoded_data = real_encoder.predict(df_real_test_ss)\n",
    "X_pred_train = real_decoder.predict(encoded_data)\n",
    "X_pred_train = pd.DataFrame(X_pred_train, columns = df_real_test.columns)\n",
    "X_pred_train.index = df_real_test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T08:47:00.431842Z",
     "start_time": "2019-11-14T08:46:45.246843Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "_Jv3DtnLGAFS"
   },
   "outputs": [],
   "source": [
    "autoencoder_scored = pd.DataFrame(index = df_real_test.index)\n",
    "# Xtrain = X_train.reshape(X_train.shape[0], X_train.shape[2])\n",
    "autoencoder_scored['loss_mse'] = np.mean(np.abs(X_pred_train-df_real_test_ss), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T08:54:29.114715Z",
     "start_time": "2019-11-14T08:54:27.918241Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "qkkf0FEMGAFU",
    "outputId": "e547b02c-b892-4cad-ef24-d0d30f86ec20"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2423d1b18d0>"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16,9), dpi=72)\n",
    "plt.title('Loss Distribution', fontsize=20)\n",
    "sns.distplot(autoencoder_scored['loss_mse'], bins=20, kde=True, color='blue')\n",
    "# plt.xlim([0.0,0.02])\n",
    "# plt.xticks(np.arange(0,0.05,0.005));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nc6WbufrGAFY"
   },
   "source": [
    "## Predict Anomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivity = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03397589400588021"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder_scored['loss_mse'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T08:55:51.165904Z",
     "start_time": "2019-11-14T08:55:51.161762Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "Igmyi2AzGAFZ"
   },
   "outputs": [],
   "source": [
    "threshold = (1 - sensitivity) * autoencoder_scored['loss_mse'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T08:56:12.742492Z",
     "start_time": "2019-11-14T08:56:01.506665Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "Vs9Sy2zlGAFe"
   },
   "outputs": [],
   "source": [
    "encoded_data = real_encoder.predict(df_real_test_ss)\n",
    "X_pred = real_decoder.predict(encoded_data)\n",
    "X_pred = pd.DataFrame(X_pred, columns = df_real_test.columns)\n",
    "X_pred.index = df_real_test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T08:56:14.080626Z",
     "start_time": "2019-11-14T08:56:12.745406Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "ClIpOOWTGAFf",
    "outputId": "90e2e8c0-1cf3-4d38-8c22-de173f822965"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss_mse</th>\n",
       "      <th>threshold</th>\n",
       "      <th>pred_anomaly</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.005595</td>\n",
       "      <td>0.016988</td>\n",
       "      <td>False</td>\n",
       "      <td>regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.006861</td>\n",
       "      <td>0.016988</td>\n",
       "      <td>False</td>\n",
       "      <td>regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.006287</td>\n",
       "      <td>0.016988</td>\n",
       "      <td>False</td>\n",
       "      <td>regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.008376</td>\n",
       "      <td>0.016988</td>\n",
       "      <td>False</td>\n",
       "      <td>regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.008222</td>\n",
       "      <td>0.016988</td>\n",
       "      <td>False</td>\n",
       "      <td>regular</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loss_mse  threshold  pred_anomaly    label\n",
       "0  0.005595   0.016988         False  regular\n",
       "1  0.006861   0.016988         False  regular\n",
       "2  0.006287   0.016988         False  regular\n",
       "3  0.008376   0.016988         False  regular\n",
       "4  0.008222   0.016988         False  regular"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder_scored = pd.DataFrame(index = df_real_test.index)\n",
    "autoencoder_scored['loss_mse'] = np.mean(np.abs(X_pred-df_real_test_ss), axis=1)\n",
    "autoencoder_scored['threshold'] = threshold\n",
    "autoencoder_scored['pred_anomaly'] = autoencoder_scored['loss_mse'] >= autoencoder_scored['threshold']\n",
    "autoencoder_scored['label'] = real_label\n",
    "autoencoder_scored.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T08:56:14.113934Z",
     "start_time": "2019-11-14T08:56:14.083484Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "NQYqL2sAGAFg",
    "outputId": "53bb0861-0ac8-4b51-df27-5f42c25b9d4c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss_mse</th>\n",
       "      <th>threshold</th>\n",
       "      <th>pred_anomaly</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10563</th>\n",
       "      <td>0.026999</td>\n",
       "      <td>0.016988</td>\n",
       "      <td>True</td>\n",
       "      <td>global</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13129</th>\n",
       "      <td>0.027003</td>\n",
       "      <td>0.016988</td>\n",
       "      <td>True</td>\n",
       "      <td>global</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13279</th>\n",
       "      <td>0.026941</td>\n",
       "      <td>0.016988</td>\n",
       "      <td>True</td>\n",
       "      <td>global</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14093</th>\n",
       "      <td>0.026887</td>\n",
       "      <td>0.016988</td>\n",
       "      <td>True</td>\n",
       "      <td>global</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25057</th>\n",
       "      <td>0.033976</td>\n",
       "      <td>0.016988</td>\n",
       "      <td>True</td>\n",
       "      <td>local</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32408</th>\n",
       "      <td>0.031642</td>\n",
       "      <td>0.016988</td>\n",
       "      <td>True</td>\n",
       "      <td>local</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss_mse  threshold  pred_anomaly   label\n",
       "10563  0.026999   0.016988          True  global\n",
       "13129  0.027003   0.016988          True  global\n",
       "13279  0.026941   0.016988          True  global\n",
       "14093  0.026887   0.016988          True  global\n",
       "25057  0.033976   0.016988          True   local\n",
       "32408  0.031642   0.016988          True   local"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder_scored[(autoencoder_scored.pred_anomaly == True) & (autoencoder_scored.label != \"regular\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T08:56:14.238696Z",
     "start_time": "2019-11-14T08:56:14.116100Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "ure4mgi9GAFi",
    "outputId": "7dc1d140-d9d9-46db-fa97-32eea41ea1d2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: label, dtype: int64)"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder_scored[(autoencoder_scored.pred_anomaly == True) & (autoencoder_scored.label == \"regular\")].label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T08:56:26.871833Z",
     "start_time": "2019-11-14T08:56:26.849430Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "YwCPTDuoGAFu",
    "outputId": "6aaf52d4-5aec-4086-f805-d50467e149ba"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss_mse</th>\n",
       "      <th>threshold</th>\n",
       "      <th>pred_anomaly</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [loss_mse, threshold, pred_anomaly, label]\n",
       "Index: []"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder_scored[(autoencoder_scored.pred_anomaly == False) & (autoencoder_scored.label != \"regular\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T08:56:31.929416Z",
     "start_time": "2019-11-14T08:56:31.898783Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "vA2MD0-7GAFw",
    "outputId": "914da2af-de35-436f-bc0c-fcf07409dddd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "regular    33308\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder_scored[(autoencoder_scored.pred_anomaly == False) & (autoencoder_scored.label == \"regular\")].label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AKyDYdStGAF2"
   },
   "source": [
    "|                      | Actual<br>Anomaly | Actual<br>Regular |\n",
    "|----------------------|-------------------|-------------------|\n",
    "| Predicted<br>Anomaly | 18                | 0                 |\n",
    "| Predicted<br>Regular | 7                 | 133,228           |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JA12PwaM_qBl"
   },
   "source": [
    "### Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XO2n9EapSX8v"
   },
   "outputs": [],
   "source": [
    "encoded_data = real_encoder.predict(df_real_test_ss)\n",
    "decoded_data = real_decoder.predict(encoded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vyQgCZ_e5luv"
   },
   "outputs": [],
   "source": [
    "label_int = real_label.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W8m1cbDT5nIQ"
   },
   "outputs": [],
   "source": [
    "for i in range(len(label_int)):\n",
    "    if label_int[i] == \"regular\":\n",
    "        label_int[i] = 0\n",
    "    elif label_int[i] == \"global\":\n",
    "        label_int[i] = 1\n",
    "    elif label_int[i] == \"local\":\n",
    "        label_int[i] = 1\n",
    "    else:\n",
    "        print(\"error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CpyjJQfj5oZy"
   },
   "outputs": [],
   "source": [
    "df_train_ae, df_test_ae, df_y_train_ae, df_y_test_ae = \\\n",
    "train_test_split(\n",
    "    encoded_data, \n",
    "    label_int, \n",
    "    random_state=42, \n",
    "    stratify=label_int\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "YQMt_x_M5rge",
    "outputId": "9781847f-42b0-47a2-9796-8780cd4f4359"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape (24985, 2)\n",
      "Testing data shape (8329, 2)\n"
     ]
    }
   ],
   "source": [
    "print(f'Training data shape {df_train_ae.shape}')\n",
    "print(f'Testing data shape {df_test_ae.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "54nkatK0_qBs"
   },
   "source": [
    "### Autoencoder with kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "HWJeCbap5tlw",
    "outputId": "2ca83a81-9243-41da-f7b8-ed38ede99760"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ae_knn = KNeighborsClassifier()\n",
    "ae_knn.fit(df_train_ae, df_y_train_ae.astype('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x_MAXJSLf48P"
   },
   "outputs": [],
   "source": [
    "# import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DceWTFEhgMgi"
   },
   "outputs": [],
   "source": [
    "# pickle.dump(ae_knn, open('/content/drive/My Drive/Project/trained models/ae_knn.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GrIx3jJDhjtu"
   },
   "outputs": [],
   "source": [
    "# ae_knn = pickle.load(open('/content/drive/My Drive/Project/trained models/ae_knn.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fnVjmWOg5vfr"
   },
   "outputs": [],
   "source": [
    "pred_ae_knn = ae_knn.predict(encoded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "xRi8Ps9L5xOc",
    "outputId": "d1454a65-00fc-4cb5-8f80-14993116b2e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP - True Negative 33308\n",
      "FP - False Positive 0\n",
      "FN - False Negative 6\n",
      "TP - True Positive 0\n",
      "Accuracy Rate: 0.9998198955394129\n",
      "Misclassification Rate: 0.00018010446058714055\n"
     ]
    }
   ],
   "source": [
    "cmat = confusion_matrix(label_int.astype(int), pred_ae_knn)\n",
    "print(f'TP - True Negative {cmat[0,0]}')\n",
    "print(f'FP - False Positive {cmat[0,1]}')\n",
    "print(f'FN - False Negative {cmat[1,0]}')\n",
    "print(f'TP - True Positive {cmat[1,1]}')\n",
    "print(f'Accuracy Rate: {np.divide(np.sum([cmat[0,0],cmat[1,1]]),np.sum(cmat))}')\n",
    "print(f'Misclassification Rate: {np.divide(np.sum([cmat[0,1],cmat[1,0]]),np.sum(cmat))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "K2fQio0Z5y6-",
    "outputId": "bec42fc7-8320-4118-9409-bd74e82bd09d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.99982   1.00000   0.99991     33308\n",
      "           1    0.00000   0.00000   0.00000         6\n",
      "\n",
      "    accuracy                        0.99982     33314\n",
      "   macro avg    0.49991   0.50000   0.49995     33314\n",
      "weighted avg    0.99964   0.99982   0.99973     33314\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(label_int.astype(int), pred_ae_knn, digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ASqt5u2-_qB1"
   },
   "outputs": [],
   "source": [
    "acc_ae_knn = accuracy_score(label_int.astype(int), pred_ae_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fw99esSa_qB2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "f1_ae_knn = f1_score(label_int.astype(int), pred_ae_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_6jH96ZE_qB4"
   },
   "source": [
    "### Autoencoder with Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "VLxBXI_SNCuv",
    "outputId": "2781896b-d06e-4b72-e57a-096003a805bd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ae_svc = SVC(gamma=\"scale\")\n",
    "ae_svc.fit(df_train_ae, df_y_train_ae.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lEQCupRciUzf"
   },
   "outputs": [],
   "source": [
    "# pickle.dump(ae_svc, open('/content/drive/My Drive/Project/trained models/ae_svc.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V0cSF2xpiUzk"
   },
   "outputs": [],
   "source": [
    "# ae_svc = pickle.load(open('/content/drive/My Drive/Project/trained models/ae_svc.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u2MdvOKgNEMT"
   },
   "outputs": [],
   "source": [
    "pred_ae_svc = ae_svc.predict(encoded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "5WbtfHjXNFsu",
    "outputId": "c479108f-710f-437d-c868-c7781d36ec28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP - True Negative 33308\n",
      "FP - False Positive 0\n",
      "FN - False Negative 6\n",
      "TP - True Positive 0\n",
      "Accuracy Rate: 0.9998198955394129\n",
      "Misclassification Rate: 0.00018010446058714055\n"
     ]
    }
   ],
   "source": [
    "cmat = confusion_matrix(label_int.astype(int), pred_ae_svc)\n",
    "print(f'TP - True Negative {cmat[0,0]}')\n",
    "print(f'FP - False Positive {cmat[0,1]}')\n",
    "print(f'FN - False Negative {cmat[1,0]}')\n",
    "print(f'TP - True Positive {cmat[1,1]}')\n",
    "print(f'Accuracy Rate: {np.divide(np.sum([cmat[0,0],cmat[1,1]]),np.sum(cmat))}')\n",
    "print(f'Misclassification Rate: {np.divide(np.sum([cmat[0,1],cmat[1,0]]),np.sum(cmat))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "_KqLxCoqNHTl",
    "outputId": "fa9e967d-ee0a-40f0-9e0e-0c6b5b21b559"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.99982   1.00000   0.99991     33308\n",
      "           1    0.00000   0.00000   0.00000         6\n",
      "\n",
      "    accuracy                        0.99982     33314\n",
      "   macro avg    0.49991   0.50000   0.49995     33314\n",
      "weighted avg    0.99964   0.99982   0.99973     33314\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(label_int.astype(int), pred_ae_svc, digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4khPGWuh_qB_"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "f1_ae_svc = f1_score(label_int.astype(int), pred_ae_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cJp158Ci_qCA"
   },
   "outputs": [],
   "source": [
    "acc_ae_svc = accuracy_score(label_int.astype(int), pred_ae_svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fhve6_MN_qCB"
   },
   "source": [
    "### Autoencoder with Local Outlier Factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PFE1wzBXPUAz"
   },
   "outputs": [],
   "source": [
    "ae_lof = LocalOutlierFactor(n_neighbors=30, contamination=0.0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mbvgkW5OjM3p"
   },
   "outputs": [],
   "source": [
    "# pickle.dump(ae_lof, open('/content/drive/My Drive/Project/trained models/ae_lof.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O1BN2OA1jM3t"
   },
   "outputs": [],
   "source": [
    "# ae_lof = pickle.load(open('/content/drive/My Drive/Project/trained models/ae_lof.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7Ukv-9W9PVbh"
   },
   "outputs": [],
   "source": [
    "pred_ae_lof = ae_lof.fit_predict(encoded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uvnqZ3wKPWq2"
   },
   "outputs": [],
   "source": [
    "pred_ae_lof = pd.Series(pred_ae_lof).replace([-1,1],[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "QOhK6QfsPYJ5",
    "outputId": "d115aead-e727-48fb-f259-9ea0bb2f698e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP - True Negative 33301\n",
      "FP - False Positive 7\n",
      "FN - False Negative 6\n",
      "TP - True Positive 0\n",
      "Accuracy Rate: 0.9996097736687278\n",
      "Misclassification Rate: 0.00039022633127213784\n"
     ]
    }
   ],
   "source": [
    "cmat = confusion_matrix(label_int.astype(int), pred_ae_lof)\n",
    "print(f'TP - True Negative {cmat[0,0]}')\n",
    "print(f'FP - False Positive {cmat[0,1]}')\n",
    "print(f'FN - False Negative {cmat[1,0]}')\n",
    "print(f'TP - True Positive {cmat[1,1]}')\n",
    "print(f'Accuracy Rate: {np.divide(np.sum([cmat[0,0],cmat[1,1]]),np.sum(cmat))}')\n",
    "print(f'Misclassification Rate: {np.divide(np.sum([cmat[0,1],cmat[1,0]]),np.sum(cmat))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "u3aXByXZPZt4",
    "outputId": "0e5edbdb-8397-4e0e-c8f5-7ffb1b4f4974"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.99982   0.99979   0.99980     33308\n",
      "           1    0.00000   0.00000   0.00000         6\n",
      "\n",
      "    accuracy                        0.99961     33314\n",
      "   macro avg    0.49991   0.49989   0.49990     33314\n",
      "weighted avg    0.99964   0.99961   0.99962     33314\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(label_int.astype(int), pred_ae_lof, digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "stdifJf3_qCG"
   },
   "outputs": [],
   "source": [
    "f1_ae_lof = f1_score(label_int.astype(int), pred_ae_lof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZaCb6F6t_qCH"
   },
   "outputs": [],
   "source": [
    "acc_ae_lof = accuracy_score(label_int.astype(int), pred_ae_lof)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "99t-w0mb_qCH"
   },
   "source": [
    "### Autoencoder with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "VXOPa8j33gf5",
    "outputId": "33f07334-6cad-4520-beec-fd8c3ff1b608"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ae_lr = LogisticRegression()\n",
    "ae_lr.fit(df_train_ae, df_y_train_ae.astype('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aQyXJ3KHnSze"
   },
   "outputs": [],
   "source": [
    "# pickle.dump(ae_lr, open('/content/drive/My Drive/Project/trained models/ae_lr.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YDVf2XnnnSzj"
   },
   "outputs": [],
   "source": [
    "# ae_lr = pickle.load(open('/content/drive/My Drive/Project/trained models/ae_lr.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "IZO1gthQ3jOK",
    "outputId": "e9b412f2-b0e8-45ba-db06-008ddd1ef9cd"
   },
   "outputs": [],
   "source": [
    "pred_ae_lr = ae_lr.predict(encoded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "UNNbvU3h3lLV",
    "outputId": "985401ff-bcee-44e4-f629-440485514126"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP - True Negative 33308\n",
      "FP - False Positive 0\n",
      "FN - False Negative 6\n",
      "TP - True Positive 0\n",
      "Accuracy Rate: 0.9998198955394129\n",
      "Misclassification Rate: 0.00018010446058714055\n"
     ]
    }
   ],
   "source": [
    "cmat = confusion_matrix(label_int.astype(int), pred_ae_lr)\n",
    "print(f'TP - True Negative {cmat[0,0]}')\n",
    "print(f'FP - False Positive {cmat[0,1]}')\n",
    "print(f'FN - False Negative {cmat[1,0]}')\n",
    "print(f'TP - True Positive {cmat[1,1]}')\n",
    "print(f'Accuracy Rate: {np.divide(np.sum([cmat[0,0],cmat[1,1]]),np.sum(cmat))}')\n",
    "print(f'Misclassification Rate: {np.divide(np.sum([cmat[0,1],cmat[1,0]]),np.sum(cmat))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "C7OA0fg03mcX",
    "outputId": "5ac32694-d27c-42e1-d8df-ab524cdbc6ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.99982   1.00000   0.99991     33308\n",
      "           1    0.00000   0.00000   0.00000         6\n",
      "\n",
      "    accuracy                        0.99982     33314\n",
      "   macro avg    0.49991   0.50000   0.49995     33314\n",
      "weighted avg    0.99964   0.99982   0.99973     33314\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(label_int.astype(int), pred_ae_lr, digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WEL9JW1y_qCM"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "f1_ae_lr = f1_score(label_int.astype(int), pred_ae_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZOG03nZl_qCN"
   },
   "outputs": [],
   "source": [
    "acc_ae_lr = accuracy_score(label_int.astype(int), pred_ae_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "07YUp1hS_qCO"
   },
   "source": [
    "### Autoencoder with kMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IJp_b3Fa_qCP"
   },
   "outputs": [],
   "source": [
    "ae_kmeans = KMeans(n_clusters=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zwIf7L1Cnpaz"
   },
   "outputs": [],
   "source": [
    "pickle.dump(ae_kmeans, open('/content/drive/My Drive/Project/trained models/ae_kmeans.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3xIyG7_vnpa5"
   },
   "outputs": [],
   "source": [
    "ae_kmeans = pickle.load(open('/content/drive/My Drive/Project/trained models/ae_kmeans.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ht8wDI91_qCQ"
   },
   "outputs": [],
   "source": [
    "ae_kmeans.fit(df_test_ae)\n",
    "pred_ae_kmeans = ae_kmeans.predict(df_test_ae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "yLpQ-txb_qCS",
    "outputId": "84df30de-dcd9-4e78-cc59-9f64fe12d19d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP - True Negative 42442\n",
      "FP - False Positive 90786\n",
      "FN - False Negative 6\n",
      "TP - True Positive 19\n",
      "Accuracy Rate: 0.3186494863155051\n",
      "Misclassification Rate: 0.681350513684495\n"
     ]
    }
   ],
   "source": [
    "cmat = confusion_matrix(df_y_test_ae.astype(int), pred_ae_kmeans)\n",
    "print(f'TP - True Negative {cmat[0,0]}')\n",
    "print(f'FP - False Positive {cmat[0,1]}')\n",
    "print(f'FN - False Negative {cmat[1,0]}')\n",
    "print(f'TP - True Positive {cmat[1,1]}')\n",
    "print(f'Accuracy Rate: {np.divide(np.sum([cmat[0,0],cmat[1,1]]),np.sum(cmat))}')\n",
    "print(f'Misclassification Rate: {np.divide(np.sum([cmat[0,1],cmat[1,0]]),np.sum(cmat))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "lBBhxUKc_qCT",
    "outputId": "c2a5960f-91b4-4857-a859-2ecb3a40859b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.99986   0.31857   0.48318    133228\n",
      "           1    0.00021   0.76000   0.00042        25\n",
      "\n",
      "    accuracy                        0.31865    133253\n",
      "   macro avg    0.50003   0.53928   0.24180    133253\n",
      "weighted avg    0.99967   0.31865   0.48309    133253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df_y_test_ae.astype(int), pred_ae_kmeans, digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MezCdMaa_qCT"
   },
   "outputs": [],
   "source": [
    "f1_ae_kmeans = f1_score(df_y_test_ae.astype(int), pred_ae_kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v18O2XuJ_qCU"
   },
   "outputs": [],
   "source": [
    "acc_ae_kmeans = accuracy_score(df_y_test_ae.astype(int), pred_ae_kmeans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6IqLUftp_qCV"
   },
   "source": [
    "### Autoencoder with Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xKzjq2aD_qCV"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "qoPzJL0E_qCW",
    "outputId": "936367bc-8057-4e64-9019-5346d078f52d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 176,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Decision Tree classifer object\n",
    "ae_dt = DecisionTreeClassifier()\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "ae_dt.fit(df_train_ae,df_y_train_ae.astype('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WtvUdef-n7ST"
   },
   "outputs": [],
   "source": [
    "pickle.dump(ae_dt, open('/content/drive/My Drive/Project/trained models/ae_dt.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rL3TUjDin7SW"
   },
   "outputs": [],
   "source": [
    "ae_dt = pickle.load(open('/content/drive/My Drive/Project/trained models/ae_dt.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ktk7oapL_qCY"
   },
   "outputs": [],
   "source": [
    "#Predict the response for test dataset\n",
    "pred_ae_dt = ae_dt.predict(df_test_ae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "0xPPVmpL_qCZ",
    "outputId": "e09a447b-1286-4980-ef3b-24431a98fa47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP - True Negative 133225\n",
      "FP - False Positive 3\n",
      "FN - False Negative 6\n",
      "TP - True Positive 19\n",
      "Accuracy Rate: 0.9999324593067324\n",
      "Misclassification Rate: 6.754069326769379e-05\n"
     ]
    }
   ],
   "source": [
    "cmat = confusion_matrix(df_y_test_ae.astype(int), pred_ae_dt)\n",
    "print(f'TP - True Negative {cmat[0,0]}')\n",
    "print(f'FP - False Positive {cmat[0,1]}')\n",
    "print(f'FN - False Negative {cmat[1,0]}')\n",
    "print(f'TP - True Positive {cmat[1,1]}')\n",
    "print(f'Accuracy Rate: {np.divide(np.sum([cmat[0,0],cmat[1,1]]),np.sum(cmat))}')\n",
    "print(f'Misclassification Rate: {np.divide(np.sum([cmat[0,1],cmat[1,0]]),np.sum(cmat))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "4GqyEhmC_qCZ",
    "outputId": "765f893f-247a-4a19-ec48-c7a18882d80b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.99995   0.99998   0.99997    133228\n",
      "           1    0.86364   0.76000   0.80851        25\n",
      "\n",
      "    accuracy                        0.99993    133253\n",
      "   macro avg    0.93180   0.87999   0.90424    133253\n",
      "weighted avg    0.99993   0.99993   0.99993    133253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df_y_test_ae.astype(int), pred_ae_dt, digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vTqyzKxV_qCa"
   },
   "outputs": [],
   "source": [
    "f1_ae_dt = f1_score(df_y_test_ae.astype(int), pred_ae_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zeDlpHF9_qCb"
   },
   "outputs": [],
   "source": [
    "acc_ae_dt = accuracy_score(df_y_test_ae.astype(int), pred_ae_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M54ElZko_qCc"
   },
   "source": [
    "### Autoencoder with Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7LI9OWob_qCc"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JMn5XuzX_qCd"
   },
   "outputs": [],
   "source": [
    "ae_rf = RandomForestClassifier(random_state = 42)\n",
    "ae_rf.fit(df_train_ae, df_y_train_ae.astype('int'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RA4Yvo5Yplhk"
   },
   "outputs": [],
   "source": [
    "pickle.dump(ae_rf, open('/content/drive/My Drive/Project/trained models/ae_rf.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YZJP0fP4plhn"
   },
   "outputs": [],
   "source": [
    "ae_rf = pickle.load(open('/content/drive/My Drive/Project/trained models/ae_rf.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AIjxCu4q_qCe"
   },
   "outputs": [],
   "source": [
    "pred_ae_rf = ae_rf.predict(df_test_ae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "WZSQckWQ_qCg",
    "outputId": "189eefd0-216e-42af-d163-dad4d8ef0189"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP - True Negative 133227\n",
      "FP - False Positive 1\n",
      "FN - False Negative 6\n",
      "TP - True Positive 19\n",
      "Accuracy Rate: 0.9999474683496807\n",
      "Misclassification Rate: 5.253165031931739e-05\n"
     ]
    }
   ],
   "source": [
    "cmat = confusion_matrix(df_y_test_ae.astype(int), pred_ae_rf)\n",
    "print(f'TP - True Negative {cmat[0,0]}')\n",
    "print(f'FP - False Positive {cmat[0,1]}')\n",
    "print(f'FN - False Negative {cmat[1,0]}')\n",
    "print(f'TP - True Positive {cmat[1,1]}')\n",
    "print(f'Accuracy Rate: {np.divide(np.sum([cmat[0,0],cmat[1,1]]),np.sum(cmat))}')\n",
    "print(f'Misclassification Rate: {np.divide(np.sum([cmat[0,1],cmat[1,0]]),np.sum(cmat))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "TKWR2cJF_qCi",
    "outputId": "f2290895-288c-4f49-a019-92e65f33d16c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.99995   0.99999   0.99997    133228\n",
      "           1    0.95000   0.76000   0.84444        25\n",
      "\n",
      "    accuracy                        0.99995    133253\n",
      "   macro avg    0.97498   0.88000   0.92221    133253\n",
      "weighted avg    0.99995   0.99995   0.99994    133253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df_y_test_ae.astype(int), pred_ae_rf, digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yRimAjQE_qCi"
   },
   "outputs": [],
   "source": [
    "f1_ae_rf = f1_score(df_y_test_ae.astype(int), pred_ae_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZDclk4Vs_qCj"
   },
   "outputs": [],
   "source": [
    "acc_ae_rf = accuracy_score(df_y_test_ae.astype(int), pred_ae_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nMkt9_Tn_qCk"
   },
   "source": [
    "### Autoencoder with Extra Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PkBJUMbR_qCk"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0ndT11xa_qCl"
   },
   "outputs": [],
   "source": [
    "ae_et = ExtraTreesClassifier(random_state = 42)\n",
    "ae_et.fit(df_train_ae, df_y_train_ae.astype('int'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tv19Ac6Hp4bW"
   },
   "outputs": [],
   "source": [
    "pickle.dump(ae_et, open('/content/drive/My Drive/Project/trained models/ae_et.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WoWrXotwp4bb"
   },
   "outputs": [],
   "source": [
    "ae_et = pickle.load(open('/content/drive/My Drive/Project/trained models/ae_et.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cRQ2Vf2L_qCn"
   },
   "outputs": [],
   "source": [
    "pred_ae_et = ae_et.predict(df_test_ae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "Sbyc1HDh_qCp",
    "outputId": "c50d8ca7-6b6a-4097-9f49-ba0f85fd51bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP - True Negative 133226\n",
      "FP - False Positive 2\n",
      "FN - False Negative 6\n",
      "TP - True Positive 19\n",
      "Accuracy Rate: 0.9999399638282065\n",
      "Misclassification Rate: 6.003617179350559e-05\n"
     ]
    }
   ],
   "source": [
    "cmat = confusion_matrix(df_y_test_ae.astype(int), pred_ae_et)\n",
    "print(f'TP - True Negative {cmat[0,0]}')\n",
    "print(f'FP - False Positive {cmat[0,1]}')\n",
    "print(f'FN - False Negative {cmat[1,0]}')\n",
    "print(f'TP - True Positive {cmat[1,1]}')\n",
    "print(f'Accuracy Rate: {np.divide(np.sum([cmat[0,0],cmat[1,1]]),np.sum(cmat))}')\n",
    "print(f'Misclassification Rate: {np.divide(np.sum([cmat[0,1],cmat[1,0]]),np.sum(cmat))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "55Q0WCH-_qCp",
    "outputId": "9ef1835a-c998-4677-b4f6-7d60f84836ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.99995   0.99998   0.99997    133228\n",
      "           1    0.90476   0.76000   0.82609        25\n",
      "\n",
      "    accuracy                        0.99994    133253\n",
      "   macro avg    0.95236   0.87999   0.91303    133253\n",
      "weighted avg    0.99994   0.99994   0.99994    133253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df_y_test_ae.astype(int), pred_ae_et, digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZHSoJ8_o_qCq"
   },
   "outputs": [],
   "source": [
    "f1_ae_et = f1_score(df_y_test_ae.astype(int), pred_ae_et)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oVpDpxfS_qCr"
   },
   "outputs": [],
   "source": [
    "acc_ae_et = accuracy_score(df_y_test_ae.astype(int), pred_ae_et)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4EHLKFrl_qCx"
   },
   "source": [
    "### Autoencoder with AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KNR6ybH__qCx"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "_mFjwi3e_qCy",
    "outputId": "20e75f13-57f2-41d4-864b-a235bd83de44"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n",
       "                   n_estimators=50, random_state=42)"
      ]
     },
     "execution_count": 203,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ae_ab = AdaBoostClassifier(random_state=42)\n",
    "ae_ab.fit(df_train_ae, df_y_train_ae.astype('int'))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pKeb10TMqa34"
   },
   "outputs": [],
   "source": [
    "pickle.dump(ae_ab, open('/content/drive/My Drive/Project/trained models/ae_ab.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JQAQR54_qa3_"
   },
   "outputs": [],
   "source": [
    "ae_ab = pickle.load(open('/content/drive/My Drive/Project/trained models/ae_ab.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XKVsHNBU_qCz"
   },
   "outputs": [],
   "source": [
    "pred_ae_ab = ae_ab.predict(df_test_ae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "isWyv2i2_qCz",
    "outputId": "386fe824-9219-4bd9-9c48-6a2655f3b527"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP - True Negative 133228\n",
      "FP - False Positive 0\n",
      "FN - False Negative 19\n",
      "TP - True Positive 6\n",
      "Accuracy Rate: 0.9998574140919905\n",
      "Misclassification Rate: 0.00014258590800957576\n"
     ]
    }
   ],
   "source": [
    "cmat = confusion_matrix(df_y_test_ae.astype(int), pred_ae_ab)\n",
    "print(f'TP - True Negative {cmat[0,0]}')\n",
    "print(f'FP - False Positive {cmat[0,1]}')\n",
    "print(f'FN - False Negative {cmat[1,0]}')\n",
    "print(f'TP - True Positive {cmat[1,1]}')\n",
    "print(f'Accuracy Rate: {np.divide(np.sum([cmat[0,0],cmat[1,1]]),np.sum(cmat))}')\n",
    "print(f'Misclassification Rate: {np.divide(np.sum([cmat[0,1],cmat[1,0]]),np.sum(cmat))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "2qgiTYWY_qC0",
    "outputId": "110c768a-e833-4fa2-c0b0-fee2ba39b119"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.99986   1.00000   0.99993    133228\n",
      "           1    1.00000   0.24000   0.38710        25\n",
      "\n",
      "    accuracy                        0.99986    133253\n",
      "   macro avg    0.99993   0.62000   0.69351    133253\n",
      "weighted avg    0.99986   0.99986   0.99981    133253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df_y_test_ae.astype(int), pred_ae_ab, digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uH97jb07_qC1"
   },
   "outputs": [],
   "source": [
    "f1_ae_ab = f1_score(df_y_test_ae.astype(int), pred_ae_ab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d7Rv6eE5_qC2"
   },
   "outputs": [],
   "source": [
    "acc_ae_ab = accuracy_score(df_y_test_ae.astype(int), pred_ae_ab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UlsVO3t1_qC2"
   },
   "source": [
    "### Autoencoder with Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lzFWBjOt_qC3"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "B_yyx99S_qC4",
    "outputId": "86f1fc96-f52a-4780-9c64-2806e2abc5c2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "                           max_features=None, max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=1, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                           n_iter_no_change=None, presort='auto',\n",
       "                           random_state=42, subsample=1.0, tol=0.0001,\n",
       "                           validation_fraction=0.1, verbose=0,\n",
       "                           warm_start=False)"
      ]
     },
     "execution_count": 212,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ae_gb = GradientBoostingClassifier(random_state=42)\n",
    "ae_gb.fit(df_train_ae, df_y_train_ae.astype('int')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "scofa--fq2uV"
   },
   "outputs": [],
   "source": [
    "pickle.dump(ae_gb, open('/content/drive/My Drive/Project/trained models/ae_gb.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c4biWhCLq2uY"
   },
   "outputs": [],
   "source": [
    "ae_gb = pickle.load(open('/content/drive/My Drive/Project/trained models/ae_gb.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zYlwoXLB_qC5"
   },
   "outputs": [],
   "source": [
    "pred_ae_gb = ae_gb.predict(df_test_ae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "ESqVWqyF_qC5",
    "outputId": "2b653a51-5c6b-4101-acb4-fa2112684d3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP - True Negative 133225\n",
      "FP - False Positive 3\n",
      "FN - False Negative 7\n",
      "TP - True Positive 18\n",
      "Accuracy Rate: 0.9999249547852581\n",
      "Misclassification Rate: 7.504521474188199e-05\n"
     ]
    }
   ],
   "source": [
    "cmat = confusion_matrix(df_y_test_ae.astype(int), pred_ae_gb)\n",
    "print(f'TP - True Negative {cmat[0,0]}')\n",
    "print(f'FP - False Positive {cmat[0,1]}')\n",
    "print(f'FN - False Negative {cmat[1,0]}')\n",
    "print(f'TP - True Positive {cmat[1,1]}')\n",
    "print(f'Accuracy Rate: {np.divide(np.sum([cmat[0,0],cmat[1,1]]),np.sum(cmat))}')\n",
    "print(f'Misclassification Rate: {np.divide(np.sum([cmat[0,1],cmat[1,0]]),np.sum(cmat))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "cG5kIrLK_qC6",
    "outputId": "9077131b-0a8b-4d52-e254-58c8c355a9d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.99995   0.99998   0.99996    133228\n",
      "           1    0.85714   0.72000   0.78261        25\n",
      "\n",
      "    accuracy                        0.99992    133253\n",
      "   macro avg    0.92855   0.85999   0.89129    133253\n",
      "weighted avg    0.99992   0.99992   0.99992    133253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df_y_test_ae.astype(int), pred_ae_gb, digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kPuyJN58_qC7"
   },
   "outputs": [],
   "source": [
    "f1_ae_gb = f1_score(df_y_test_ae.astype(int), pred_ae_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D50FXSoE_qC7"
   },
   "outputs": [],
   "source": [
    "acc_ae_gb = accuracy_score(df_y_test_ae.astype(int), pred_ae_gb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GQV5VNFK_qC8"
   },
   "source": [
    "### Autoencoder with Bernoulli Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3pqiU5tp_qC8"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "_bAKitJY_qC9",
    "outputId": "a38b64f2-e6ad-4b5c-fc44-d2b390bd86fe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 221,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ae_bnb = BernoulliNB()\n",
    "ae_bnb.fit(df_train_ae, df_y_train_ae.astype('int')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h_yohSHRrN6C"
   },
   "outputs": [],
   "source": [
    "pickle.dump(ae_bnb, open('/content/drive/My Drive/Project/trained models/ae_bnb.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HNI-QGRQrN6I"
   },
   "outputs": [],
   "source": [
    "ae_bnb = pickle.load(open('/content/drive/My Drive/Project/trained models/ae_bnb.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IfQTTNMQ_qC-"
   },
   "outputs": [],
   "source": [
    "pred_ae_bnb = ae_bnb.predict(df_test_ae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "ZWZjmdpp_qC_",
    "outputId": "ce3d5ade-ad17-4dd2-f9d4-7ffa06ae7ec6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP - True Negative 133228\n",
      "FP - False Positive 0\n",
      "FN - False Negative 25\n",
      "TP - True Positive 0\n",
      "Accuracy Rate: 0.9998123869631453\n",
      "Misclassification Rate: 0.00018761303685470496\n"
     ]
    }
   ],
   "source": [
    "cmat = confusion_matrix(df_y_test_ae.astype(int), pred_ae_bnb)\n",
    "print(f'TP - True Negative {cmat[0,0]}')\n",
    "print(f'FP - False Positive {cmat[0,1]}')\n",
    "print(f'FN - False Negative {cmat[1,0]}')\n",
    "print(f'TP - True Positive {cmat[1,1]}')\n",
    "print(f'Accuracy Rate: {np.divide(np.sum([cmat[0,0],cmat[1,1]]),np.sum(cmat))}')\n",
    "print(f'Misclassification Rate: {np.divide(np.sum([cmat[0,1],cmat[1,0]]),np.sum(cmat))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "Qh-DTWuY_qDA",
    "outputId": "220a3a3b-3633-41fb-afd6-3ec75f594a86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.99981   1.00000   0.99991    133228\n",
      "           1    0.00000   0.00000   0.00000        25\n",
      "\n",
      "    accuracy                        0.99981    133253\n",
      "   macro avg    0.49991   0.50000   0.49995    133253\n",
      "weighted avg    0.99962   0.99981   0.99972    133253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df_y_test_ae.astype(int), pred_ae_bnb, digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hXHqv0qx_qDA"
   },
   "outputs": [],
   "source": [
    "f1_ae_bnb = f1_score(df_y_test_ae.astype(int), pred_ae_bnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HC2QoDsf_qDB"
   },
   "outputs": [],
   "source": [
    "acc_ae_bnb = accuracy_score(df_y_test_ae.astype(int), pred_ae_bnb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O_meOEMd_qDI"
   },
   "source": [
    "### Autoencoder with Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2J7GSjOB_qDI"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "IObozvyK_qDJ",
    "outputId": "a7597538-7607-48ac-bcce-348e71b41adf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 230,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ae_gnb = GaussianNB()\n",
    "ae_gnb.fit(df_train_ae, df_y_train_ae.astype('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EXzdINBduHXM"
   },
   "outputs": [],
   "source": [
    "pickle.dump(ae_gnb, open('/content/drive/My Drive/Project/trained models/ae_gnb.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "53hblDQeuHXQ"
   },
   "outputs": [],
   "source": [
    "ae_gnb = pickle.load(open('/content/drive/My Drive/Project/trained models/ae_gnb.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kQWu53RD_qDK"
   },
   "outputs": [],
   "source": [
    "pred_ae_gnb = ae_gnb.predict(df_test_ae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "_Ym2fPAS_qDK",
    "outputId": "62d0384e-ee4a-455f-dc01-63c38889e923"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP - True Negative 133228\n",
      "FP - False Positive 0\n",
      "FN - False Negative 25\n",
      "TP - True Positive 0\n",
      "Accuracy Rate: 0.9998123869631453\n",
      "Misclassification Rate: 0.00018761303685470496\n"
     ]
    }
   ],
   "source": [
    "cmat = confusion_matrix(df_y_test_ae.astype(int), pred_ae_gnb)\n",
    "print(f'TP - True Negative {cmat[0,0]}')\n",
    "print(f'FP - False Positive {cmat[0,1]}')\n",
    "print(f'FN - False Negative {cmat[1,0]}')\n",
    "print(f'TP - True Positive {cmat[1,1]}')\n",
    "print(f'Accuracy Rate: {np.divide(np.sum([cmat[0,0],cmat[1,1]]),np.sum(cmat))}')\n",
    "print(f'Misclassification Rate: {np.divide(np.sum([cmat[0,1],cmat[1,0]]),np.sum(cmat))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "PitsUk6S_qDM",
    "outputId": "567bea7c-0ade-4b2f-b3e7-cdf1986e3394"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.99981   1.00000   0.99991    133228\n",
      "           1    0.00000   0.00000   0.00000        25\n",
      "\n",
      "    accuracy                        0.99981    133253\n",
      "   macro avg    0.49991   0.50000   0.49995    133253\n",
      "weighted avg    0.99962   0.99981   0.99972    133253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df_y_test_ae.astype(int), pred_ae_gnb, digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xHVqUrQi_qDN"
   },
   "outputs": [],
   "source": [
    "f1_ae_gnb = f1_score(df_y_test_ae.astype(int), pred_ae_gnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OMH2g9J7_qDO"
   },
   "outputs": [],
   "source": [
    "acc_ae_gnb = accuracy_score(df_y_test_ae.astype(int), pred_ae_gnb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xm5vQYte_qDT"
   },
   "source": [
    "### Autoencoder with Ridge Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IhW-yDbU_qDT"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "h_mMFC8A_qDV",
    "outputId": "b8f0e16e-530d-419b-fc85-7ff834d85ede"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
       "                max_iter=None, normalize=False, random_state=None,\n",
       "                solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 239,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ae_ridge = RidgeClassifier()\n",
    "ae_ridge.fit(df_train_ae, df_y_train_ae.astype('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TVBVx8SZub2F"
   },
   "outputs": [],
   "source": [
    "pickle.dump(ae_ridge, open('/content/drive/My Drive/Project/trained models/ae_ridge.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HiMPLpY2ub2M"
   },
   "outputs": [],
   "source": [
    "ae_ridge = pickle.load(open('/content/drive/My Drive/Project/trained models/ae_ridge.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_9jf0eHe_qDW"
   },
   "outputs": [],
   "source": [
    "pred_ae_ridge = ae_ridge.predict(df_test_ae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "BTxdD7C2_qDX",
    "outputId": "05d4294b-f9d0-491a-d05d-306524043e86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP - True Negative 133228\n",
      "FP - False Positive 0\n",
      "FN - False Negative 25\n",
      "TP - True Positive 0\n",
      "Accuracy Rate: 0.9998123869631453\n",
      "Misclassification Rate: 0.00018761303685470496\n"
     ]
    }
   ],
   "source": [
    "cmat = confusion_matrix(df_y_test_ae.astype(int), pred_ae_ridge)\n",
    "print(f'TP - True Negative {cmat[0,0]}')\n",
    "print(f'FP - False Positive {cmat[0,1]}')\n",
    "print(f'FN - False Negative {cmat[1,0]}')\n",
    "print(f'TP - True Positive {cmat[1,1]}')\n",
    "print(f'Accuracy Rate: {np.divide(np.sum([cmat[0,0],cmat[1,1]]),np.sum(cmat))}')\n",
    "print(f'Misclassification Rate: {np.divide(np.sum([cmat[0,1],cmat[1,0]]),np.sum(cmat))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "FrX0XEa5_qDY",
    "outputId": "fcfb4e02-9170-4563-a3a6-ce7670f2dc27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.99981   1.00000   0.99991    133228\n",
      "           1    0.00000   0.00000   0.00000        25\n",
      "\n",
      "    accuracy                        0.99981    133253\n",
      "   macro avg    0.49991   0.50000   0.49995    133253\n",
      "weighted avg    0.99962   0.99981   0.99972    133253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df_y_test_ae.astype(int), pred_ae_ridge, digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HMQkvI3u_qDa"
   },
   "outputs": [],
   "source": [
    "f1_ae_ridge = f1_score(df_y_test_ae.astype(int), pred_ae_ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qfhaT995_qDc"
   },
   "outputs": [],
   "source": [
    "acc_ae_ridge = accuracy_score(df_y_test_ae.astype(int), pred_ae_ridge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WyU1EHX0_qDd"
   },
   "source": [
    "### Autoencoder with SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TTg9yn7H_qDd"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "bTFok49A_qDe",
    "outputId": "ce8038c9-7d0b-4708-afa3-f2e9259f52cd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
       "              max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "              power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
       "              validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 248,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ae_sgd = SGDClassifier()\n",
    "ae_sgd.fit(df_train_ae, df_y_train_ae.astype('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tQgQIsVeuyQp"
   },
   "outputs": [],
   "source": [
    "pickle.dump(ae_sgd, open('/content/drive/My Drive/Project/trained models/ae_sgd.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PREXEeesuyQs"
   },
   "outputs": [],
   "source": [
    "ae_sgd = pickle.load(open('/content/drive/My Drive/Project/trained models/ae_sgd.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vNelxAIB_qDg"
   },
   "outputs": [],
   "source": [
    "pred_ae_sgd = ae_sgd.predict(df_test_ae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "fhL3TWP3_qDh",
    "outputId": "dda0a004-7958-4aca-d0f8-8969b6752e4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP - True Negative 133228\n",
      "FP - False Positive 0\n",
      "FN - False Negative 25\n",
      "TP - True Positive 0\n",
      "Accuracy Rate: 0.9998123869631453\n",
      "Misclassification Rate: 0.00018761303685470496\n"
     ]
    }
   ],
   "source": [
    "cmat = confusion_matrix(df_y_test_ae.astype(int), pred_ae_sgd)\n",
    "print(f'TP - True Negative {cmat[0,0]}')\n",
    "print(f'FP - False Positive {cmat[0,1]}')\n",
    "print(f'FN - False Negative {cmat[1,0]}')\n",
    "print(f'TP - True Positive {cmat[1,1]}')\n",
    "print(f'Accuracy Rate: {np.divide(np.sum([cmat[0,0],cmat[1,1]]),np.sum(cmat))}')\n",
    "print(f'Misclassification Rate: {np.divide(np.sum([cmat[0,1],cmat[1,0]]),np.sum(cmat))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "MvegUOa2_qDi",
    "outputId": "55f58a42-d62b-4b04-db31-084326f64e90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.99981   1.00000   0.99991    133228\n",
      "           1    0.00000   0.00000   0.00000        25\n",
      "\n",
      "    accuracy                        0.99981    133253\n",
      "   macro avg    0.49991   0.50000   0.49995    133253\n",
      "weighted avg    0.99962   0.99981   0.99972    133253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df_y_test_ae.astype(int), pred_ae_sgd, digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2i0Bc7Eq_qDj"
   },
   "outputs": [],
   "source": [
    "f1_ae_sgd = f1_score(df_y_test_ae.astype(int), pred_ae_sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eCxvF85t_qDm"
   },
   "outputs": [],
   "source": [
    "acc_ae_sgd = accuracy_score(df_y_test_ae.astype(int), pred_ae_sgd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "noyp6A0e_qDn"
   },
   "source": [
    "### Autoencoder with Radius Neighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k2t4Svug_qDo"
   },
   "outputs": [],
   "source": [
    "# from sklearn.neighbors import RadiusNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_IC7wBNw_qDq"
   },
   "outputs": [],
   "source": [
    "# rnc = RadiusNeighborsClassifier()\n",
    "# rnc.fit(df_train_ae, df_y_train_ae.astype('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vr1bMOrC_qDs"
   },
   "outputs": [],
   "source": [
    "# pred_ae_rnc = rnc.predict(df_test_ae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FpGehZ31_qDt"
   },
   "outputs": [],
   "source": [
    "# cmat = confusion_matrix(df_y_test_ae.astype(int), pred_ae_rnc)\n",
    "# print(f'TP - True Negative {cmat[0,0]}')\n",
    "# print(f'FP - False Positive {cmat[0,1]}')\n",
    "# print(f'FN - False Negative {cmat[1,0]}')\n",
    "# print(f'TP - True Positive {cmat[1,1]}')\n",
    "# print(f'Accuracy Rate: {np.divide(np.sum([cmat[0,0],cmat[1,1]]),np.sum(cmat))}')\n",
    "# print(f'Misclassification Rate: {np.divide(np.sum([cmat[0,1],cmat[1,0]]),np.sum(cmat))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gxl_beIf_qDu"
   },
   "outputs": [],
   "source": [
    "# print(classification_report(df_y_test_ae.astype(int), pred_ae_rnc, digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pVUEuw-7_qDv"
   },
   "outputs": [],
   "source": [
    "# f1_ae_rnc = f1_score(df_y_test_ae.astype(int), pred_ae_rnc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iRYiwA74_qDx"
   },
   "outputs": [],
   "source": [
    "# acc_ae_rnc = accuracy_score(df_y_test_ae.astype(int), pred_ae_rnc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MlCFpOgz_qEA"
   },
   "source": [
    "### Autoencoder with Nearest Centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3syRenoZ_qEA"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors.nearest_centroid import NearestCentroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "N8x7ZQw__qEB",
    "outputId": "77f9f085-6dd0-44fb-b51e-6bd045137608"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestCentroid(metric='euclidean', shrink_threshold=None)"
      ]
     },
     "execution_count": 264,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ae_nc = NearestCentroid()\n",
    "ae_nc.fit(df_train_ae, df_y_train_ae.astype('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3h2z4fgrvJOj"
   },
   "outputs": [],
   "source": [
    "pickle.dump(ae_nc, open('/content/drive/My Drive/Project/trained models/ae_nc.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t7DF1pM4vJOm"
   },
   "outputs": [],
   "source": [
    "ae_nc = pickle.load(open('/content/drive/My Drive/Project/trained models/ae_nc.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y_9eZPr9_qEC"
   },
   "outputs": [],
   "source": [
    "pred_ae_nc = ae_nc.predict(df_test_ae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "jTrbIOUr_qED",
    "outputId": "87f66789-9f4e-4a6d-9404-0a48168aa78f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP - True Negative 93882\n",
      "FP - False Positive 39346\n",
      "FN - False Negative 5\n",
      "TP - True Positive 20\n",
      "Accuracy Rate: 0.7046895754692202\n",
      "Misclassification Rate: 0.29531042453077977\n"
     ]
    }
   ],
   "source": [
    "cmat = confusion_matrix(df_y_test_ae.astype(int), pred_ae_nc)\n",
    "print(f'TP - True Negative {cmat[0,0]}')\n",
    "print(f'FP - False Positive {cmat[0,1]}')\n",
    "print(f'FN - False Negative {cmat[1,0]}')\n",
    "print(f'TP - True Positive {cmat[1,1]}')\n",
    "print(f'Accuracy Rate: {np.divide(np.sum([cmat[0,0],cmat[1,1]]),np.sum(cmat))}')\n",
    "print(f'Misclassification Rate: {np.divide(np.sum([cmat[0,1],cmat[1,0]]),np.sum(cmat))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "YrBCZAjB_qED",
    "outputId": "25493439-2866-4fdd-b56b-95a23159ca75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.99995   0.70467   0.82674    133228\n",
      "           1    0.00051   0.80000   0.00102        25\n",
      "\n",
      "    accuracy                        0.70469    133253\n",
      "   macro avg    0.50023   0.75234   0.41388    133253\n",
      "weighted avg    0.99976   0.70469   0.82658    133253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df_y_test_ae.astype(int), pred_ae_nc, digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3AE200QJ_qEE"
   },
   "outputs": [],
   "source": [
    "f1_ae_nc = f1_score(df_y_test_ae.astype(int), pred_ae_nc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7-GgE-U7_qEG"
   },
   "outputs": [],
   "source": [
    "acc_ae_nc = accuracy_score(df_y_test_ae.astype(int), pred_ae_nc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aDnYG8Pv_qEH"
   },
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YwxPxrD6-Al7"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k53gQZNO-S1q"
   },
   "outputs": [],
   "source": [
    "df_train, df_test, df_y_train, df_y_test = \\\n",
    "train_test_split(\n",
    "    ori_subset_transformed, \n",
    "    label_int, \n",
    "    random_state=42, \n",
    "    stratify=label_int\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L4ZulKwk-dxH"
   },
   "outputs": [],
   "source": [
    "ss = MinMaxScaler()\n",
    "df_train_ss = ss.fit_transform(df_train)\n",
    "df_test_ss = ss.transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TnYFYBAt-WQA"
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=200)\n",
    "df_train_ss = pca.fit_transform(df_train_ss)\n",
    "df_test_ss = pca.transform(df_test_ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "Y7wNmNVXB8_B",
    "outputId": "a9dcdf81-1d7c-450b-e1e0-60a8a5dc21a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape (399756, 200)\n",
      "Testing data shape (133253, 200)\n"
     ]
    }
   ],
   "source": [
    "# X_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
    "print(f'Training data shape {df_train_ss.shape}')\n",
    "\n",
    "# X_test = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])\n",
    "print(f'Testing data shape {df_test_ss.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FB9t-iCE_qEM"
   },
   "source": [
    "### PCA with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "M0H5J3OPHt7j",
    "outputId": "d294c114-3e7f-4068-951f-801fe8714bd2",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 277,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Instantiate our model.\n",
    "pca_lr = LogisticRegression()\n",
    "\n",
    "# Step 2: Fit our model.\n",
    "pca_lr.fit(df_train_ss, df_y_train.astype('int'))\n",
    "\n",
    "# print(f'Logistic Regression Intercept: {logreg.intercept_}')\n",
    "# print(f'Logistic Regression Coefficient: {logreg.coef_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VOgkLwkDvrSP"
   },
   "outputs": [],
   "source": [
    "pickle.dump(pca_lr, open('/content/drive/My Drive/Project/trained models/pca_lr.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4cpcNjPKvrSS"
   },
   "outputs": [],
   "source": [
    "pca_lr = pickle.load(open('/content/drive/My Drive/Project/trained models/pca_lr.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q9yPVHMKH8Dg"
   },
   "outputs": [],
   "source": [
    "# Step 3 (part 1): Generate predicted values.\n",
    "pred_pca_lr = pca_lr.predict(df_test_ss)\n",
    "# print(f'Logreg predicted values: {pred_pca_lr}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "QuvgsI-JJz8Y",
    "outputId": "410ff6dd-1ed5-4c03-d42d-87cd99b50112"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP - True Negative 133228\n",
      "FP - False Positive 0\n",
      "FN - False Negative 7\n",
      "TP - True Positive 18\n",
      "Accuracy Rate: 0.9999474683496807\n",
      "Misclassification Rate: 5.253165031931739e-05\n"
     ]
    }
   ],
   "source": [
    "cmat = confusion_matrix(df_y_test.astype(int), pred_pca_lr)\n",
    "print(f'TP - True Negative {cmat[0,0]}')\n",
    "print(f'FP - False Positive {cmat[0,1]}')\n",
    "print(f'FN - False Negative {cmat[1,0]}')\n",
    "print(f'TP - True Positive {cmat[1,1]}')\n",
    "print(f'Accuracy Rate: {np.divide(np.sum([cmat[0,0],cmat[1,1]]),np.sum(cmat))}')\n",
    "print(f'Misclassification Rate: {np.divide(np.sum([cmat[0,1],cmat[1,0]]),np.sum(cmat))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "CeJ2ul9OKJxT",
    "outputId": "a3a5d283-8fc5-4349-88f0-7a2ae42beca4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.99995   1.00000   0.99997    133228\n",
      "           1    1.00000   0.72000   0.83721        25\n",
      "\n",
      "    accuracy                        0.99995    133253\n",
      "   macro avg    0.99997   0.86000   0.91859    133253\n",
      "weighted avg    0.99995   0.99995   0.99994    133253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df_y_test.astype(int), pred_pca_lr, digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-cGxeMh3_qET"
   },
   "outputs": [],
   "source": [
    "f1_pca_lr = f1_score(df_y_test.astype(int), pred_pca_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WoMQLr6J_qEU"
   },
   "outputs": [],
   "source": [
    "acc_pca_lr = accuracy_score(df_y_test.astype(int), pred_pca_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0d9Y8ES3_qEV"
   },
   "source": [
    "### PCA with kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "w2ekcyAUKRdV",
    "outputId": "ebc9eb09-339e-4c23-9f57-c50df1603504"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 285,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_knn = KNeighborsClassifier()\n",
    "pca_knn.fit(df_train_ss, df_y_train.astype('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-EkVj1emwOSE"
   },
   "outputs": [],
   "source": [
    "pickle.dump(pca_knn, open('/content/drive/My Drive/Project/trained models/pca_knn.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8iteds1owOSK"
   },
   "outputs": [],
   "source": [
    "pca_knn = pickle.load(open('/content/drive/My Drive/Project/trained models/pca_knn.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A_uYzjPWKajY"
   },
   "outputs": [],
   "source": [
    "pred_pca_knn = pca_knn.predict(df_test_ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "rcBjwVNPLMJJ",
    "outputId": "9b67f99b-3fff-417a-fbf1-3cbae315f247"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP - True Negative 133228\n",
      "FP - False Positive 0\n",
      "FN - False Negative 4\n",
      "TP - True Positive 21\n",
      "Accuracy Rate: 0.9999699819141032\n",
      "Misclassification Rate: 3.0018085896752794e-05\n"
     ]
    }
   ],
   "source": [
    "cmat = confusion_matrix(df_y_test.astype(int), pred_pca_knn)\n",
    "print(f'TP - True Negative {cmat[0,0]}')\n",
    "print(f'FP - False Positive {cmat[0,1]}')\n",
    "print(f'FN - False Negative {cmat[1,0]}')\n",
    "print(f'TP - True Positive {cmat[1,1]}')\n",
    "print(f'Accuracy Rate: {np.divide(np.sum([cmat[0,0],cmat[1,1]]),np.sum(cmat))}')\n",
    "print(f'Misclassification Rate: {np.divide(np.sum([cmat[0,1],cmat[1,0]]),np.sum(cmat))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "FoAGammbS8Mq",
    "outputId": "b073a914-7917-4d0e-f099-c158b04a18fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.99997   1.00000   0.99998    133228\n",
      "           1    1.00000   0.84000   0.91304        25\n",
      "\n",
      "    accuracy                        0.99997    133253\n",
      "   macro avg    0.99998   0.92000   0.95651    133253\n",
      "weighted avg    0.99997   0.99997   0.99997    133253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df_y_test.astype(int), pred_pca_knn, digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2-9DFSB3_qEY"
   },
   "outputs": [],
   "source": [
    "f1_pca_knn = f1_score(df_y_test.astype(int), pred_pca_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "70Z6WCoe_qEZ"
   },
   "outputs": [],
   "source": [
    "acc_pca_knn = accuracy_score(df_y_test.astype(int), pred_pca_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3XJ6fM-Y_qEa"
   },
   "source": [
    "### PCA with Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W0Zp_IK_SiBO"
   },
   "outputs": [],
   "source": [
    "# Instantiate support vector machine.\n",
    "pca_svc = SVC(gamma=\"scale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "t1ZHPfhgSlmA",
    "outputId": "c12176d1-0131-4b03-b01a-7e990f9db493"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 294,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit support vector machine to training data.\n",
    "pca_svc.fit(df_train_ss, df_y_train.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ew15QEdSxoDU"
   },
   "outputs": [],
   "source": [
    "pickle.dump(pca_svc, open('/content/drive/My Drive/Project/trained models/pca_svc.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6VLW2_sTxoDX"
   },
   "outputs": [],
   "source": [
    "pca_svc = pickle.load(open('/content/drive/My Drive/Project/trained models/pca_svc.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W8orFFG4TC9v"
   },
   "outputs": [],
   "source": [
    "# Generate predictions.\n",
    "pred_pca_svc = pca_svc.predict(df_test_ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "2AXt1kFHTzH-",
    "outputId": "a31de759-3336-4854-923a-03664f2741a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP - True Negative 133228\n",
      "FP - False Positive 0\n",
      "FN - False Negative 6\n",
      "TP - True Positive 19\n",
      "Accuracy Rate: 0.9999549728711549\n",
      "Misclassification Rate: 4.502712884512919e-05\n"
     ]
    }
   ],
   "source": [
    "cmat = confusion_matrix(df_y_test.astype(int), pred_pca_svc)\n",
    "print(f'TP - True Negative {cmat[0,0]}')\n",
    "print(f'FP - False Positive {cmat[0,1]}')\n",
    "print(f'FN - False Negative {cmat[1,0]}')\n",
    "print(f'TP - True Positive {cmat[1,1]}')\n",
    "print(f'Accuracy Rate: {np.divide(np.sum([cmat[0,0],cmat[1,1]]),np.sum(cmat))}')\n",
    "print(f'Misclassification Rate: {np.divide(np.sum([cmat[0,1],cmat[1,0]]),np.sum(cmat))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "mRga2tNxUPND",
    "outputId": "ed25b942-c8a2-4e75-a5f5-3e20e6dfaccf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.99995   1.00000   0.99998    133228\n",
      "           1    1.00000   0.76000   0.86364        25\n",
      "\n",
      "    accuracy                        0.99995    133253\n",
      "   macro avg    0.99998   0.88000   0.93181    133253\n",
      "weighted avg    0.99995   0.99995   0.99995    133253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df_y_test.astype(int), pred_pca_svc, digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z5bIdC0p_qEe"
   },
   "outputs": [],
   "source": [
    "f1_pca_svc = f1_score(df_y_test.astype(int), pred_pca_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kirx_aM8_qEf"
   },
   "outputs": [],
   "source": [
    "acc_pca_svc = accuracy_score(df_y_test.astype(int), pred_pca_svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UoWiSG5q_qEg"
   },
   "source": [
    "### PCA with Local Outlier Factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HcG8zlEoV9ZL"
   },
   "outputs": [],
   "source": [
    "pca_lof = LocalOutlierFactor(n_neighbors=30, contamination=0.0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-GbcuA3Izvnf"
   },
   "outputs": [],
   "source": [
    "pickle.dump(pca_lof, open('/content/drive/My Drive/Project/trained models/pca_lof.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ArbtFg4Kzvnj"
   },
   "outputs": [],
   "source": [
    "pca_lof = pickle.load(open('/content/drive/My Drive/Project/trained models/pca_lof.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z6-WRZgXV9ZW"
   },
   "outputs": [],
   "source": [
    "pred_pca_lof = pca_lof.fit_predict(df_test_ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xu_Bs40UV9ZY"
   },
   "outputs": [],
   "source": [
    "pred_pca_lof = pd.Series(pred_pca_lof).replace([-1,1],[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "y26ask49V9Zc",
    "outputId": "90f8b7a0-d81e-4b4f-e730-de86a7f0b0e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP - True Negative 133207\n",
      "FP - False Positive 21\n",
      "FN - False Negative 19\n",
      "TP - True Positive 6\n",
      "Accuracy Rate: 0.9996998191410325\n",
      "Misclassification Rate: 0.00030018085896752795\n"
     ]
    }
   ],
   "source": [
    "cmat = confusion_matrix(df_y_test.astype(int), pred_pca_lof)\n",
    "print(f'TP - True Negative {cmat[0,0]}')\n",
    "print(f'FP - False Positive {cmat[0,1]}')\n",
    "print(f'FN - False Negative {cmat[1,0]}')\n",
    "print(f'TP - True Positive {cmat[1,1]}')\n",
    "print(f'Accuracy Rate: {np.divide(np.sum([cmat[0,0],cmat[1,1]]),np.sum(cmat))}')\n",
    "print(f'Misclassification Rate: {np.divide(np.sum([cmat[0,1],cmat[1,0]]),np.sum(cmat))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "Khlz-GZTV9Ze",
    "outputId": "14c69bce-54e8-4379-cda9-1ab907b37450"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.99986   0.99984   0.99985    133228\n",
      "           1    0.22222   0.24000   0.23077        25\n",
      "\n",
      "    accuracy                        0.99970    133253\n",
      "   macro avg    0.61104   0.61992   0.61531    133253\n",
      "weighted avg    0.99971   0.99970   0.99971    133253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df_y_test.astype(int), pred_pca_lof, digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9MO5_Awl_qEk"
   },
   "outputs": [],
   "source": [
    "f1_pca_lof = f1_score(df_y_test.astype(int), pred_pca_lof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LmfV1HLv_qEl"
   },
   "outputs": [],
   "source": [
    "acc_pca_lof = accuracy_score(df_y_test.astype(int), pred_pca_lof)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HINToMGX_qEn"
   },
   "source": [
    "### PCA with kMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GTOtaJmX_qEo"
   },
   "outputs": [],
   "source": [
    "pca_kmeans = KMeans(n_clusters=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B9P6sWBZ0nWC"
   },
   "outputs": [],
   "source": [
    "pickle.dump(pca_kmeans, open('/content/drive/My Drive/Project/trained models/pca_kmeans.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "403qOAJ90nWG"
   },
   "outputs": [],
   "source": [
    "pca_kmeans = pickle.load(open('/content/drive/My Drive/Project/trained models/pca_kmeans.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CrRxlaDm_qEo"
   },
   "outputs": [],
   "source": [
    "pca_kmeans.fit(df_test_ss)\n",
    "pred_pca_kmeans = pca_kmeans.predict(df_test_ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "TPTSMYP5_qEp",
    "outputId": "de03b64a-1b75-436b-d96c-c381b18a9bef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP - True Negative 50669\n",
      "FP - False Positive 82559\n",
      "FN - False Negative 19\n",
      "TP - True Positive 6\n",
      "Accuracy Rate: 0.38029162570448694\n",
      "Misclassification Rate: 0.6197083742955131\n"
     ]
    }
   ],
   "source": [
    "cmat = confusion_matrix(df_y_test.astype(int), pred_pca_kmeans)\n",
    "print(f'TP - True Negative {cmat[0,0]}')\n",
    "print(f'FP - False Positive {cmat[0,1]}')\n",
    "print(f'FN - False Negative {cmat[1,0]}')\n",
    "print(f'TP - True Positive {cmat[1,1]}')\n",
    "print(f'Accuracy Rate: {np.divide(np.sum([cmat[0,0],cmat[1,1]]),np.sum(cmat))}')\n",
    "print(f'Misclassification Rate: {np.divide(np.sum([cmat[0,1],cmat[1,0]]),np.sum(cmat))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "Z1uLjPTR_qEq",
    "outputId": "46f15143-5b7b-4b48-94b5-7925eeae673e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.99963   0.38032   0.55100    133228\n",
      "           1    0.00007   0.24000   0.00015        25\n",
      "\n",
      "    accuracy                        0.38029    133253\n",
      "   macro avg    0.49985   0.31016   0.27557    133253\n",
      "weighted avg    0.99944   0.38029   0.55090    133253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df_y_test.astype(int), pred_pca_kmeans, digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AoI0l3yQ_qEr"
   },
   "outputs": [],
   "source": [
    "f1_pca_kmeans = f1_score(df_y_test.astype(int), pred_pca_kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2IAaVviO_qEs"
   },
   "outputs": [],
   "source": [
    "acc_pca_kmeans = accuracy_score(df_y_test.astype(int), pred_pca_kmeans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P1KTHxTh_qEs"
   },
   "source": [
    "### PCA with Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "K_4Lx954_qEs",
    "outputId": "ab80d969-0fb5-4097-9aa7-89ef2aee625b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 319,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Decision Tree classifer object\n",
    "pca_dt = DecisionTreeClassifier()\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "pca_dt.fit(df_train_ss,df_y_train.astype('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yipuezEr05KA"
   },
   "outputs": [],
   "source": [
    "pickle.dump(pca_dt, open('/content/drive/My Drive/Project/trained models/pca_dt.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lgv3rk7d05KD"
   },
   "outputs": [],
   "source": [
    "pca_dt = pickle.load(open('/content/drive/My Drive/Project/trained models/pca_dt.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "APbzoily_qEu"
   },
   "outputs": [],
   "source": [
    "#Predict the response for test dataset\n",
    "pred_pca_dt = pca_dt.predict(df_test_ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "PoFbpyJJ_qEv",
    "outputId": "0f1f10bc-fc68-4c72-f6b5-7ade6a881d9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP - True Negative 133228\n",
      "FP - False Positive 0\n",
      "FN - False Negative 4\n",
      "TP - True Positive 21\n",
      "Accuracy Rate: 0.9999699819141032\n",
      "Misclassification Rate: 3.0018085896752794e-05\n"
     ]
    }
   ],
   "source": [
    "cmat = confusion_matrix(df_y_test.astype(int), pred_pca_dt)\n",
    "print(f'TP - True Negative {cmat[0,0]}')\n",
    "print(f'FP - False Positive {cmat[0,1]}')\n",
    "print(f'FN - False Negative {cmat[1,0]}')\n",
    "print(f'TP - True Positive {cmat[1,1]}')\n",
    "print(f'Accuracy Rate: {np.divide(np.sum([cmat[0,0],cmat[1,1]]),np.sum(cmat))}')\n",
    "print(f'Misclassification Rate: {np.divide(np.sum([cmat[0,1],cmat[1,0]]),np.sum(cmat))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "I3qEAt7F_qEw",
    "outputId": "b021c744-9030-4ffc-b414-6ea6a35f5af3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.99997   1.00000   0.99998    133228\n",
      "           1    1.00000   0.84000   0.91304        25\n",
      "\n",
      "    accuracy                        0.99997    133253\n",
      "   macro avg    0.99998   0.92000   0.95651    133253\n",
      "weighted avg    0.99997   0.99997   0.99997    133253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df_y_test.astype(int), pred_pca_dt, digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xeRUmNVN_qEz"
   },
   "outputs": [],
   "source": [
    "f1_pca_dt = f1_score(df_y_test.astype(int), pred_pca_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6ipu3--Z_qE0"
   },
   "outputs": [],
   "source": [
    "acc_pca_dt = accuracy_score(df_y_test.astype(int), pred_pca_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SsyCCsgB_qE1"
   },
   "source": [
    "### PCA with Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s2tQgoJP_qE1"
   },
   "outputs": [],
   "source": [
    "pca_rf = RandomForestClassifier(random_state = 42)\n",
    "pca_rf.fit(df_train_ss, df_y_train.astype('int'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U3v6dEcL1VW5"
   },
   "outputs": [],
   "source": [
    "pickle.dump(pca_rf, open('/content/drive/My Drive/Project/trained models/pca_rf.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pkAOrbjG1VW7"
   },
   "outputs": [],
   "source": [
    "pca_rf = pickle.load(open('/content/drive/My Drive/Project/trained models/pca_rf.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d-UG4PDN_qE4"
   },
   "outputs": [],
   "source": [
    "pred_pca_rf = pca_rf.predict(df_test_ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "eel3c7bU_qE7",
    "outputId": "138bee11-75da-48de-c876-e3d79e51439f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP - True Negative 133228\n",
      "FP - False Positive 0\n",
      "FN - False Negative 8\n",
      "TP - True Positive 17\n",
      "Accuracy Rate: 0.9999399638282065\n",
      "Misclassification Rate: 6.003617179350559e-05\n"
     ]
    }
   ],
   "source": [
    "cmat = confusion_matrix(df_y_test.astype(int), pred_pca_rf)\n",
    "print(f'TP - True Negative {cmat[0,0]}')\n",
    "print(f'FP - False Positive {cmat[0,1]}')\n",
    "print(f'FN - False Negative {cmat[1,0]}')\n",
    "print(f'TP - True Positive {cmat[1,1]}')\n",
    "print(f'Accuracy Rate: {np.divide(np.sum([cmat[0,0],cmat[1,1]]),np.sum(cmat))}')\n",
    "print(f'Misclassification Rate: {np.divide(np.sum([cmat[0,1],cmat[1,0]]),np.sum(cmat))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "NMc49zly_qE8",
    "outputId": "34f331a9-e5b7-4ffd-a210-e8af2c498cee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.99994   1.00000   0.99997    133228\n",
      "           1    1.00000   0.68000   0.80952        25\n",
      "\n",
      "    accuracy                        0.99994    133253\n",
      "   macro avg    0.99997   0.84000   0.90475    133253\n",
      "weighted avg    0.99994   0.99994   0.99993    133253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df_y_test.astype(int), pred_pca_rf, digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uMnnsQTB_qE9"
   },
   "outputs": [],
   "source": [
    "f1_pca_rf = f1_score(df_y_test.astype(int), pred_pca_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-pZVP4qR_qE-"
   },
   "outputs": [],
   "source": [
    "acc_pca_rf = accuracy_score(df_y_test.astype(int), pred_pca_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rCEQ-uft_qFB"
   },
   "source": [
    "### PCA with Extra Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zz0ZLfAp_qFB"
   },
   "outputs": [],
   "source": [
    "pca_et = ExtraTreesClassifier(random_state = 42)\n",
    "pca_et.fit(df_train_ss, df_y_train.astype('int'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VARMdpiC3Cyy"
   },
   "outputs": [],
   "source": [
    "pickle.dump(pca_et, open('/content/drive/My Drive/Project/trained models/pca_et.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XMJvhYJA3Cy2"
   },
   "outputs": [],
   "source": [
    "pca_et = pickle.load(open('/content/drive/My Drive/Project/trained models/pca_et.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GFoWm_tE_qFC"
   },
   "outputs": [],
   "source": [
    "pred_pca_et = pca_et.predict(df_test_ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "PaxOWxol_qFC",
    "outputId": "b90e7524-62bc-4020-c5c7-3f051e0b892d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP - True Negative 133228\n",
      "FP - False Positive 0\n",
      "FN - False Negative 9\n",
      "TP - True Positive 16\n",
      "Accuracy Rate: 0.9999324593067324\n",
      "Misclassification Rate: 6.754069326769379e-05\n"
     ]
    }
   ],
   "source": [
    "cmat = confusion_matrix(df_y_test.astype(int), pred_pca_et)\n",
    "print(f'TP - True Negative {cmat[0,0]}')\n",
    "print(f'FP - False Positive {cmat[0,1]}')\n",
    "print(f'FN - False Negative {cmat[1,0]}')\n",
    "print(f'TP - True Positive {cmat[1,1]}')\n",
    "print(f'Accuracy Rate: {np.divide(np.sum([cmat[0,0],cmat[1,1]]),np.sum(cmat))}')\n",
    "print(f'Misclassification Rate: {np.divide(np.sum([cmat[0,1],cmat[1,0]]),np.sum(cmat))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "2f2sjhcy_qFD",
    "outputId": "7f93eeb8-f427-4021-aedb-4006e2fddfdf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.99993   1.00000   0.99997    133228\n",
      "           1    1.00000   0.64000   0.78049        25\n",
      "\n",
      "    accuracy                        0.99993    133253\n",
      "   macro avg    0.99997   0.82000   0.89023    133253\n",
      "weighted avg    0.99993   0.99993   0.99993    133253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df_y_test.astype(int), pred_pca_et, digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o2WO766G_qFF"
   },
   "outputs": [],
   "source": [
    "f1_pca_et = f1_score(df_y_test.astype(int), pred_pca_et)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AUvvjcE8_qFH"
   },
   "outputs": [],
   "source": [
    "acc_pca_et = accuracy_score(df_y_test.astype(int), pred_pca_et)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qXNJLvAy_qFN"
   },
   "source": [
    "### PCA with AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "woi9t8be_qFN",
    "outputId": "d8467651-e1db-4424-8bc6-de4891263e7f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n",
       "                   n_estimators=50, random_state=42)"
      ]
     },
     "execution_count": 343,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_ab = AdaBoostClassifier(random_state=42)\n",
    "pca_ab.fit(df_train_ss, df_y_train.astype('int'))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d9BFUNjU3eWW"
   },
   "outputs": [],
   "source": [
    "pickle.dump(pca_ab, open('/content/drive/My Drive/Project/trained models/pca_ab.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0OdGCtwW3eWY"
   },
   "outputs": [],
   "source": [
    "pca_ab = pickle.load(open('/content/drive/My Drive/Project/trained models/pca_ab.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EIqYEXQG_qFN"
   },
   "outputs": [],
   "source": [
    "pred_pca_ab = pca_ab.predict(df_test_ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "Kzwk87A0_qFO",
    "outputId": "0fb93da4-f344-48fb-8b58-0d17f6a98668"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP - True Negative 133228\n",
      "FP - False Positive 0\n",
      "FN - False Negative 5\n",
      "TP - True Positive 20\n",
      "Accuracy Rate: 0.9999624773926291\n",
      "Misclassification Rate: 3.7522607370940994e-05\n"
     ]
    }
   ],
   "source": [
    "cmat = confusion_matrix(df_y_test.astype(int), pred_pca_ab)\n",
    "print(f'TP - True Negative {cmat[0,0]}')\n",
    "print(f'FP - False Positive {cmat[0,1]}')\n",
    "print(f'FN - False Negative {cmat[1,0]}')\n",
    "print(f'TP - True Positive {cmat[1,1]}')\n",
    "print(f'Accuracy Rate: {np.divide(np.sum([cmat[0,0],cmat[1,1]]),np.sum(cmat))}')\n",
    "print(f'Misclassification Rate: {np.divide(np.sum([cmat[0,1],cmat[1,0]]),np.sum(cmat))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "ddRtTkRL_qFP",
    "outputId": "fca0a4d9-8784-4ef8-e2d6-1f443dd1b0f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.99996   1.00000   0.99998    133228\n",
      "           1    1.00000   0.80000   0.88889        25\n",
      "\n",
      "    accuracy                        0.99996    133253\n",
      "   macro avg    0.99998   0.90000   0.94444    133253\n",
      "weighted avg    0.99996   0.99996   0.99996    133253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df_y_test.astype(int), pred_pca_ab, digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VzBqDkV-_qFP"
   },
   "outputs": [],
   "source": [
    "f1_pca_ab = f1_score(df_y_test.astype(int), pred_pca_ab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "diqmHO5M_qFQ"
   },
   "outputs": [],
   "source": [
    "acc_pca_ab = accuracy_score(df_y_test.astype(int), pred_pca_ab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KoEXtvkq_qFR"
   },
   "source": [
    "### PCA with Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "tB8RELxc_qFR",
    "outputId": "a1589a03-73ba-4a77-c74d-dc48b311d94a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "                           max_features=None, max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=1, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                           n_iter_no_change=None, presort='auto',\n",
       "                           random_state=42, subsample=1.0, tol=0.0001,\n",
       "                           validation_fraction=0.1, verbose=0,\n",
       "                           warm_start=False)"
      ]
     },
     "execution_count": 351,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_gb = GradientBoostingClassifier(random_state=42)\n",
    "pca_gb.fit(df_train_ss, df_y_train.astype('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jwsQkqZe3x6W"
   },
   "outputs": [],
   "source": [
    "pickle.dump(pca_gb, open('/content/drive/My Drive/Project/trained models/pca_gb.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TJUX2h213x6c"
   },
   "outputs": [],
   "source": [
    "pca_gb = pickle.load(open('/content/drive/My Drive/Project/trained models/pca_gb.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qR9GBoAX_qFS"
   },
   "outputs": [],
   "source": [
    "pred_pca_gb = pca_gb.predict(df_test_ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "JuvTl_Q5_qFS",
    "outputId": "f582e490-193e-486d-e2ed-233296b2e373"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP - True Negative 133228\n",
      "FP - False Positive 0\n",
      "FN - False Negative 4\n",
      "TP - True Positive 21\n",
      "Accuracy Rate: 0.9999699819141032\n",
      "Misclassification Rate: 3.0018085896752794e-05\n"
     ]
    }
   ],
   "source": [
    "cmat = confusion_matrix(df_y_test.astype(int), pred_pca_gb)\n",
    "print(f'TP - True Negative {cmat[0,0]}')\n",
    "print(f'FP - False Positive {cmat[0,1]}')\n",
    "print(f'FN - False Negative {cmat[1,0]}')\n",
    "print(f'TP - True Positive {cmat[1,1]}')\n",
    "print(f'Accuracy Rate: {np.divide(np.sum([cmat[0,0],cmat[1,1]]),np.sum(cmat))}')\n",
    "print(f'Misclassification Rate: {np.divide(np.sum([cmat[0,1],cmat[1,0]]),np.sum(cmat))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "GnlmU7V2_qFT",
    "outputId": "25320597-2b7d-4869-8b76-a6f229d53dd0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.99997   1.00000   0.99998    133228\n",
      "           1    1.00000   0.84000   0.91304        25\n",
      "\n",
      "    accuracy                        0.99997    133253\n",
      "   macro avg    0.99998   0.92000   0.95651    133253\n",
      "weighted avg    0.99997   0.99997   0.99997    133253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df_y_test.astype(int), pred_pca_gb, digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Upo9xJK5_qFU"
   },
   "outputs": [],
   "source": [
    "f1_pca_gb = f1_score(df_y_test.astype(int), pred_pca_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KjsjtU1h_qFU"
   },
   "outputs": [],
   "source": [
    "acc_pca_gb = accuracy_score(df_y_test.astype(int), pred_pca_gb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CSweaWWd_qFV"
   },
   "source": [
    "### PCA with Bernoulli Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "htI_iUNb_qFW",
    "outputId": "b68979c6-4368-4f65-8bcf-43a235644b57"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 359,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_bnb = BernoulliNB()\n",
    "pca_bnb.fit(df_train_ss, df_y_train.astype('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "48RKRsMl4Heb"
   },
   "outputs": [],
   "source": [
    "pickle.dump(pca_bnb, open('/content/drive/My Drive/Project/trained models/pca_bnb.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KnRcgzKv4Hed"
   },
   "outputs": [],
   "source": [
    "pca_bnb = pickle.load(open('/content/drive/My Drive/Project/trained models/pca_bnb.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uJ6Bg_R5_qFX"
   },
   "outputs": [],
   "source": [
    "pred_pca_bnb = pca_bnb.predict(df_test_ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "8EA-lwPE_qFX",
    "outputId": "0642074e-dc58-4ec6-bf08-94ee0de14ba4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP - True Negative 123536\n",
      "FP - False Positive 9692\n",
      "FN - False Negative 7\n",
      "TP - True Positive 18\n",
      "Accuracy Rate: 0.9272136462218487\n",
      "Misclassification Rate: 0.07278635377815133\n"
     ]
    }
   ],
   "source": [
    "cmat = confusion_matrix(df_y_test.astype(int), pred_pca_bnb)\n",
    "print(f'TP - True Negative {cmat[0,0]}')\n",
    "print(f'FP - False Positive {cmat[0,1]}')\n",
    "print(f'FN - False Negative {cmat[1,0]}')\n",
    "print(f'TP - True Positive {cmat[1,1]}')\n",
    "print(f'Accuracy Rate: {np.divide(np.sum([cmat[0,0],cmat[1,1]]),np.sum(cmat))}')\n",
    "print(f'Misclassification Rate: {np.divide(np.sum([cmat[0,1],cmat[1,0]]),np.sum(cmat))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "6HKvTkPi_qFb",
    "outputId": "d5814f21-778d-465c-b22c-6dada2224fe9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.99994   0.92725   0.96223    133228\n",
      "           1    0.00185   0.72000   0.00370        25\n",
      "\n",
      "    accuracy                        0.92721    133253\n",
      "   macro avg    0.50090   0.82363   0.48296    133253\n",
      "weighted avg    0.99976   0.92721   0.96205    133253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df_y_test.astype(int), pred_pca_bnb, digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Efmgg1P7_qFb"
   },
   "outputs": [],
   "source": [
    "f1_pca_bnb = f1_score(df_y_test.astype(int), pred_pca_bnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xeh-IjDQ_qFd"
   },
   "outputs": [],
   "source": [
    "acc_pca_bnb = accuracy_score(df_y_test.astype(int), pred_pca_bnb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jp5QEabJ_qFj"
   },
   "source": [
    "### PCA with Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "H4dVA6n-_qFk",
    "outputId": "0476b7ab-6643-47d9-a3f9-79bb7830ff56"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 367,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_gnb = GaussianNB()\n",
    "pca_gnb.fit(df_train_ss, df_y_train.astype('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w_i1LKQT4jF_"
   },
   "outputs": [],
   "source": [
    "pickle.dump(pca_gnb, open('/content/drive/My Drive/Project/trained models/pca_gnb.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F9dMUhY64jGB"
   },
   "outputs": [],
   "source": [
    "pca_gnb = pickle.load(open('/content/drive/My Drive/Project/trained models/pca_gnb.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GlUjZ-EX_qFk"
   },
   "outputs": [],
   "source": [
    "pred_pca_gnb = pca_gnb.predict(df_test_ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "lcKUwslk_qFl",
    "outputId": "8811896a-c7a7-425b-c32a-5eee938a923f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP - True Negative 133228\n",
      "FP - False Positive 0\n",
      "FN - False Negative 1\n",
      "TP - True Positive 24\n",
      "Accuracy Rate: 0.9999924954785259\n",
      "Misclassification Rate: 7.5045214741881985e-06\n"
     ]
    }
   ],
   "source": [
    "cmat = confusion_matrix(df_y_test.astype(int), pred_pca_gnb)\n",
    "print(f'TP - True Negative {cmat[0,0]}')\n",
    "print(f'FP - False Positive {cmat[0,1]}')\n",
    "print(f'FN - False Negative {cmat[1,0]}')\n",
    "print(f'TP - True Positive {cmat[1,1]}')\n",
    "print(f'Accuracy Rate: {np.divide(np.sum([cmat[0,0],cmat[1,1]]),np.sum(cmat))}')\n",
    "print(f'Misclassification Rate: {np.divide(np.sum([cmat[0,1],cmat[1,0]]),np.sum(cmat))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "aafRcXf__qFm",
    "outputId": "e982a33d-bdd6-42c9-d861-9d549d96242c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.99999   1.00000   1.00000    133228\n",
      "           1    1.00000   0.96000   0.97959        25\n",
      "\n",
      "    accuracy                        0.99999    133253\n",
      "   macro avg    1.00000   0.98000   0.98979    133253\n",
      "weighted avg    0.99999   0.99999   0.99999    133253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df_y_test.astype(int), pred_pca_gnb, digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iDzKdV2O_qFn"
   },
   "outputs": [],
   "source": [
    "f1_pca_gnb = f1_score(df_y_test.astype(int), pred_pca_gnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tneZUiWM_qFo"
   },
   "outputs": [],
   "source": [
    "acc_pca_gnb = accuracy_score(df_y_test.astype(int), pred_pca_gnb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C3feukpq_qFt"
   },
   "source": [
    "### PCA with Ridge Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "ofNXk_Bd_qFt",
    "outputId": "713f6cb4-5105-471b-c63f-ad787e9356a1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
       "                max_iter=None, normalize=False, random_state=None,\n",
       "                solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 375,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_ridge = RidgeClassifier()\n",
    "pca_ridge.fit(df_train_ss, df_y_train.astype('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f3vjjuGc5C2X"
   },
   "outputs": [],
   "source": [
    "pickle.dump(pca_ridge, open('/content/drive/My Drive/Project/trained models/pca_ridge.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AiZg8BVf5C2d"
   },
   "outputs": [],
   "source": [
    "pca_ridge = pickle.load(open('/content/drive/My Drive/Project/trained models/pca_ridge.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vNLkxZkG_qFt"
   },
   "outputs": [],
   "source": [
    "pred_pca_ridge = pca_ridge.predict(df_test_ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "Xe64hHCH_qFw",
    "outputId": "22cfcebb-cb0e-493a-e005-4c2876630bda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP - True Negative 133228\n",
      "FP - False Positive 0\n",
      "FN - False Negative 6\n",
      "TP - True Positive 19\n",
      "Accuracy Rate: 0.9999549728711549\n",
      "Misclassification Rate: 4.502712884512919e-05\n"
     ]
    }
   ],
   "source": [
    "cmat = confusion_matrix(df_y_test.astype(int), pred_pca_ridge)\n",
    "print(f'TP - True Negative {cmat[0,0]}')\n",
    "print(f'FP - False Positive {cmat[0,1]}')\n",
    "print(f'FN - False Negative {cmat[1,0]}')\n",
    "print(f'TP - True Positive {cmat[1,1]}')\n",
    "print(f'Accuracy Rate: {np.divide(np.sum([cmat[0,0],cmat[1,1]]),np.sum(cmat))}')\n",
    "print(f'Misclassification Rate: {np.divide(np.sum([cmat[0,1],cmat[1,0]]),np.sum(cmat))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "UBzyGPw9_qFw",
    "outputId": "e7cde94a-9dfb-452c-e771-0fc0b33c8ea5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.99995   1.00000   0.99998    133228\n",
      "           1    1.00000   0.76000   0.86364        25\n",
      "\n",
      "    accuracy                        0.99995    133253\n",
      "   macro avg    0.99998   0.88000   0.93181    133253\n",
      "weighted avg    0.99995   0.99995   0.99995    133253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df_y_test.astype(int), pred_pca_ridge, digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yGubUzoP_qFx"
   },
   "outputs": [],
   "source": [
    "f1_pca_ridge = f1_score(df_y_test.astype(int), pred_pca_ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1et5k80d_qFy"
   },
   "outputs": [],
   "source": [
    "acc_pca_ridge = accuracy_score(df_y_test.astype(int), pred_pca_ridge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NBYpYhmN_qFy"
   },
   "source": [
    "### PCA with SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "MnSsq9G6_qFy",
    "outputId": "67161675-5a8d-40dc-b989-ee23270b3765"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
       "              max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "              power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
       "              validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 383,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_sgd = SGDClassifier()\n",
    "pca_sgd.fit(df_train_ss, df_y_train.astype('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Acc7P0mz5hD0"
   },
   "outputs": [],
   "source": [
    "pickle.dump(pca_sgd, open('/content/drive/My Drive/Project/trained models/pca_sgd.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mBBem6255hD2"
   },
   "outputs": [],
   "source": [
    "pca_sgd = pickle.load(open('/content/drive/My Drive/Project/trained models/pca_sgd.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bj8vxGCR_qFz"
   },
   "outputs": [],
   "source": [
    "pred_pca_sgd = pca_sgd.predict(df_test_ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "Un6pwdJK_qF0",
    "outputId": "bec77ee9-609b-43a0-9e48-0c5a0335c698"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP - True Negative 133228\n",
      "FP - False Positive 0\n",
      "FN - False Negative 25\n",
      "TP - True Positive 0\n",
      "Accuracy Rate: 0.9998123869631453\n",
      "Misclassification Rate: 0.00018761303685470496\n"
     ]
    }
   ],
   "source": [
    "cmat = confusion_matrix(df_y_test.astype(int), pred_pca_sgd)\n",
    "print(f'TP - True Negative {cmat[0,0]}')\n",
    "print(f'FP - False Positive {cmat[0,1]}')\n",
    "print(f'FN - False Negative {cmat[1,0]}')\n",
    "print(f'TP - True Positive {cmat[1,1]}')\n",
    "print(f'Accuracy Rate: {np.divide(np.sum([cmat[0,0],cmat[1,1]]),np.sum(cmat))}')\n",
    "print(f'Misclassification Rate: {np.divide(np.sum([cmat[0,1],cmat[1,0]]),np.sum(cmat))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "8pSg8v32_qF1",
    "outputId": "bb4b4020-d9c8-4b10-956f-cc5988faf003"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.99981   1.00000   0.99991    133228\n",
      "           1    0.00000   0.00000   0.00000        25\n",
      "\n",
      "    accuracy                        0.99981    133253\n",
      "   macro avg    0.49991   0.50000   0.49995    133253\n",
      "weighted avg    0.99962   0.99981   0.99972    133253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df_y_test.astype(int), pred_pca_sgd, digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2j3F7-Rq_qF2"
   },
   "outputs": [],
   "source": [
    "f1_pca_sgd = f1_score(df_y_test.astype(int), pred_pca_sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UVF1KjN1_qF4"
   },
   "outputs": [],
   "source": [
    "acc_pca_sgd = accuracy_score(df_y_test.astype(int), pred_pca_sgd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ErjYEdge_qF4"
   },
   "source": [
    "### PCA with Radius Neighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TUWI4gUT_qF5"
   },
   "outputs": [],
   "source": [
    "# rnc = RadiusNeighborsClassifier()\n",
    "# rnc.fit(df_train_ss, df_y_train.astype('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OQCuIl55_qF5"
   },
   "outputs": [],
   "source": [
    "# pred_pca_rnc = rnc.predict(df_test_ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9iQNmxez_qF6"
   },
   "outputs": [],
   "source": [
    "# cmat = confusion_matrix(df_y_test.astype(int), pred_pca_rnc)\n",
    "# print(f'TP - True Negative {cmat[0,0]}')\n",
    "# print(f'FP - False Positive {cmat[0,1]}')\n",
    "# print(f'FN - False Negative {cmat[1,0]}')\n",
    "# print(f'TP - True Positive {cmat[1,1]}')\n",
    "# print(f'Accuracy Rate: {np.divide(np.sum([cmat[0,0],cmat[1,1]]),np.sum(cmat))}')\n",
    "# print(f'Misclassification Rate: {np.divide(np.sum([cmat[0,1],cmat[1,0]]),np.sum(cmat))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tcaks2vQ_qF6"
   },
   "outputs": [],
   "source": [
    "# print(classification_report(df_y_test.astype(int), pred_pca_rnc, digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZR1_9vbx_qF8"
   },
   "outputs": [],
   "source": [
    "# f1_pca_rnc = f1_score(df_y_test.astype(int), pred_pca_rnc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xq6zhO-X_qF8"
   },
   "outputs": [],
   "source": [
    "# acc_pca_rnc = accuracy_score(df_y_test.astype(int), pred_pca_rnc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IekxFzHQ_qF9"
   },
   "source": [
    "### PCA with Nearest Centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "EZcWBSN-_qF9",
    "outputId": "8dd1c87e-ab82-482a-ac70-ece0657c2c7c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestCentroid(metric='euclidean', shrink_threshold=None)"
      ]
     },
     "execution_count": 397,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_nc = NearestCentroid()\n",
    "pca_nc.fit(df_train_ss, df_y_train.astype('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hV6y7M_55xWH"
   },
   "outputs": [],
   "source": [
    "pickle.dump(pca_nc, open('/content/drive/My Drive/Project/trained models/pca_nc.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L_bdefB65xWN"
   },
   "outputs": [],
   "source": [
    "pca_nc = pickle.load(open('/content/drive/My Drive/Project/trained models/pca_nc.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qZv230Jy_qF9"
   },
   "outputs": [],
   "source": [
    "pred_pca_nc = pca_nc.predict(df_test_ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "KcxBXLZO_qF-",
    "outputId": "3328ef01-61c9-4517-fc81-128f8e459412"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP - True Negative 124117\n",
      "FP - False Positive 9111\n",
      "FN - False Negative 6\n",
      "TP - True Positive 19\n",
      "Accuracy Rate: 0.9315812777198262\n",
      "Misclassification Rate: 0.0684187222801738\n"
     ]
    }
   ],
   "source": [
    "cmat = confusion_matrix(df_y_test.astype(int), pred_pca_nc)\n",
    "print(f'TP - True Negative {cmat[0,0]}')\n",
    "print(f'FP - False Positive {cmat[0,1]}')\n",
    "print(f'FN - False Negative {cmat[1,0]}')\n",
    "print(f'TP - True Positive {cmat[1,1]}')\n",
    "print(f'Accuracy Rate: {np.divide(np.sum([cmat[0,0],cmat[1,1]]),np.sum(cmat))}')\n",
    "print(f'Misclassification Rate: {np.divide(np.sum([cmat[0,1],cmat[1,0]]),np.sum(cmat))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "LdirGgj8_qF_",
    "outputId": "1377eeb9-c5cb-4dc2-863b-091288b690f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.99995   0.93161   0.96457    133228\n",
      "           1    0.00208   0.76000   0.00415        25\n",
      "\n",
      "    accuracy                        0.93158    133253\n",
      "   macro avg    0.50102   0.84581   0.48436    133253\n",
      "weighted avg    0.99976   0.93158   0.96439    133253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df_y_test.astype(int), pred_pca_nc, digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xLhaMGPW_qF_"
   },
   "outputs": [],
   "source": [
    "f1_pca_nc = f1_score(df_y_test.astype(int), pred_pca_nc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5k7Tz1QX_qGA"
   },
   "outputs": [],
   "source": [
    "acc_pca_nc = accuracy_score(df_y_test.astype(int), pred_pca_nc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "11kvrMxQ_qGA"
   },
   "source": [
    "# Ensemble Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8jzMfnuDlJ-c"
   },
   "outputs": [],
   "source": [
    "# pca_lr = pd.Series(pred_pca_lr).replace(0,-0.5) * acc_pca_lr #* f1_pca_lr\n",
    "# pca_knn = pd.Series(pred_pca_knn).replace(0,-0.5) * acc_pca_knn #* f1_pca_knn\n",
    "# pca_svc = pd.Series(pred_pca_svc).replace(0,-0.5) * acc_pca_svc #* f1_pca_svc\n",
    "# pca_lof = pd.Series(pred_pca_lof).replace(0,-0.5) * acc_pca_lof #* f1_pca_lof\n",
    "\n",
    "# ae_lr = pd.Series(pred_ae_lr).replace(0,-0.5) * acc_ae_lr #* f1_ae_lr\n",
    "# ae_knn = pd.Series(pred_ae_knn).replace(0,-0.5) * acc_ae_knn #* f1_ae_knn\n",
    "# ae_svc = pd.Series(pred_ae_svc).replace(0,-0.5) * acc_ae_svc #* f1_ae_svc\n",
    "# ae_lof = pd.Series(pred_ae_lof).replace(0,-0.5) * acc_ae_lof #* f1_ae_lof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "73YFGyJ__qGB"
   },
   "outputs": [],
   "source": [
    "pca_lr = pd.Series(pred_pca_lr) * acc_pca_lr * f1_pca_lr\n",
    "pca_knn = pd.Series(pred_pca_knn) * acc_pca_knn * f1_pca_knn\n",
    "pca_svc = pd.Series(pred_pca_svc) * acc_pca_svc * f1_pca_svc\n",
    "pca_lof = pd.Series(pred_pca_lof) * acc_pca_lof * f1_pca_lof\n",
    "pca_kmeans = pd.Series(pred_pca_kmeans) * acc_pca_kmeans * f1_pca_kmeans\n",
    "pca_dt = pd.Series(pred_pca_dt) * acc_pca_dt * f1_pca_dt\n",
    "pca_rf = pd.Series(pred_pca_rf) * acc_pca_rf * f1_pca_rf\n",
    "pca_et = pd.Series(pred_pca_et) * acc_pca_et * f1_pca_et\n",
    "pca_ab = pd.Series(pred_pca_ab) * acc_pca_ab * f1_pca_ab\n",
    "pca_gb = pd.Series(pred_pca_gb) * acc_pca_gb * f1_pca_gb\n",
    "pca_bnb = pd.Series(pred_pca_bnb) * acc_pca_bnb * f1_pca_bnb\n",
    "pca_gnb = pd.Series(pred_pca_gnb) * acc_pca_gnb * f1_pca_gnb\n",
    "pca_ridge = pd.Series(pred_pca_ridge) * acc_pca_ridge * f1_pca_ridge\n",
    "pca_sgd = pd.Series(pred_pca_sgd) * acc_pca_sgd * f1_pca_sgd\n",
    "# pca_rnc = pd.Series(pred_pca_rnc) * acc_pca_rnc * f1_pca_rnc\n",
    "pca_nc = pd.Series(pred_pca_nc) * acc_pca_nc * f1_pca_nc\n",
    "\n",
    "ae_lr = pd.Series(pred_ae_lr) * acc_ae_lr * f1_ae_lr\n",
    "ae_knn = pd.Series(pred_ae_knn) * acc_ae_knn * f1_ae_knn\n",
    "ae_svc = pd.Series(pred_ae_svc) * acc_ae_svc * f1_ae_svc\n",
    "ae_lof = pd.Series(pred_ae_lof) * acc_ae_lof * f1_ae_lof\n",
    "ae_kmeans = pd.Series(pred_ae_kmeans) * acc_ae_kmeans * f1_ae_kmeans\n",
    "ae_dt = pd.Series(pred_ae_dt) * acc_ae_dt * f1_ae_dt\n",
    "ae_rf = pd.Series(pred_ae_rf) * acc_ae_rf * f1_ae_rf\n",
    "ae_et = pd.Series(pred_ae_et) * acc_ae_et * f1_ae_et\n",
    "ae_ab = pd.Series(pred_ae_ab) * acc_ae_ab * f1_ae_ab\n",
    "ae_gb = pd.Series(pred_ae_gb) * acc_ae_gb * f1_ae_gb\n",
    "ae_bnb = pd.Series(pred_ae_bnb) * acc_ae_bnb * f1_ae_bnb\n",
    "ae_gnb = pd.Series(pred_ae_gnb) * acc_ae_gnb * f1_ae_gnb\n",
    "ae_ridge = pd.Series(pred_ae_ridge) * acc_ae_ridge * f1_ae_ridge\n",
    "ae_sgd = pd.Series(pred_ae_sgd) * acc_ae_sgd * f1_ae_sgd\n",
    "# ae_rnc = pd.Series(pred_ae_rnc) * acc_ae_rnc * f1_ae_rnc\n",
    "ae_nc = pd.Series(pred_ae_nc) * acc_ae_nc * f1_ae_nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FKSSQDjVnAIP"
   },
   "outputs": [],
   "source": [
    "df_models = pd.concat(\n",
    "    [\n",
    "     df_test.reset_index(), \n",
    "     pca_lr.rename('pca_lr'),\n",
    "     pca_knn.rename('pca_knn'),\n",
    "     pca_svc.rename('pca_svc'),\n",
    "     pca_lof.rename('pca_lof'), \n",
    "     pca_kmeans.rename('pca_kmeans'),\n",
    "     pca_dt.rename('pca_dt'),\n",
    "     pca_rf.rename('pca_rf'),\n",
    "     pca_et.rename('pca_et'),\n",
    "     pca_ab.rename('pca_ab'),\n",
    "     pca_gb.rename('pca_gb'),\n",
    "     pca_bnb.rename('pca_bnb'),\n",
    "     pca_gnb.rename('pca_gnb'),\n",
    "     pca_ridge.rename('pca_ridge'),\n",
    "     pca_sgd.rename('pca_sgd'),\n",
    "    #  pca_rnc.rename('pca_rnc'),\n",
    "     pca_nc.rename('pca_nc'),\n",
    "     ae_lr.rename('ae_lr'),\n",
    "     ae_knn.rename('ae_knn'),\n",
    "     ae_svc.rename('ae_svc'),\n",
    "     ae_lof.rename('ae_lof'),\n",
    "     ae_kmeans.rename('ae_kmeans'),\n",
    "     ae_dt.rename('ae_dt'),\n",
    "     ae_rf.rename('ae_rf'),\n",
    "     ae_et.rename('ae_et'),\n",
    "     ae_ab.rename('ae_ab'),\n",
    "     ae_gb.rename('ae_gb'),\n",
    "     ae_bnb.rename('ae_bnb'),\n",
    "     ae_gnb.rename('ae_gnb'),\n",
    "     ae_ridge.rename('ae_ridge'),\n",
    "     ae_sgd.rename('ae_sgd'),\n",
    "    #  ae_rnc.rename('ae_rnc'),\n",
    "     ae_nc.rename('ae_nc'),\n",
    "     df_y_test.reset_index().drop('index', axis = 1)\n",
    "     ], \n",
    "     axis = 1\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bc1ar297sIIM"
   },
   "outputs": [],
   "source": [
    "pred_list = [\n",
    "    'pca_lr', \n",
    "    'pca_knn', \n",
    "    'pca_svc', \n",
    "    'pca_lof', \n",
    "    'pca_kmeans',\n",
    "    'pca_dt',\n",
    "    'pca_rf',\n",
    "    'pca_et',\n",
    "    'pca_ab',\n",
    "    'pca_gb',\n",
    "    'pca_bnb',\n",
    "    'pca_gnb',\n",
    "    'pca_ridge',\n",
    "    'pca_sgd',\n",
    "    # 'pca_rnc',\n",
    "    'pca_nc',\n",
    "    'ae_lr', \n",
    "    'ae_knn', \n",
    "    'ae_svc', \n",
    "    'ae_lof',\n",
    "    'ae_kmeans',\n",
    "    'ae_dt',\n",
    "    'ae_rf',\n",
    "    'ae_et',\n",
    "    'ae_ab',\n",
    "    'ae_gb',\n",
    "    'ae_bnb',\n",
    "    'ae_gnb',\n",
    "    'ae_ridge',\n",
    "    'ae_sgd',\n",
    "    # 'ae_rnc',\n",
    "    'ae_nc',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lA8mPRx0qZO9"
   },
   "outputs": [],
   "source": [
    "df_models['confidence'] = df_models[pred_list].sum(axis=1) / len(pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 578
    },
    "colab_type": "code",
    "id": "lC2nlymy3IUC",
    "outputId": "1edcfcec-1e04-44ca-aad9-bab290d3d367"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.000006    37448\n",
       "0.000028    30395\n",
       "0.000002    27743\n",
       "0.000004    11701\n",
       "0.000116     7593\n",
       "0.000026     7104\n",
       "0.000133     6728\n",
       "0.000135     1683\n",
       "0.000143     1123\n",
       "0.000121      976\n",
       "0.000157      698\n",
       "0.007718       20\n",
       "0.454188       11\n",
       "0.024363        8\n",
       "0.215104        2\n",
       "0.292330        2\n",
       "0.215128        2\n",
       "0.000155        2\n",
       "0.211289        1\n",
       "0.099022        1\n",
       "0.401191        1\n",
       "0.441000        1\n",
       "0.054511        1\n",
       "0.055124        1\n",
       "0.467061        1\n",
       "0.007696        1\n",
       "0.292306        1\n",
       "0.026091        1\n",
       "0.161303        1\n",
       "0.026113        1\n",
       "0.428173        1\n",
       "0.080596        1\n",
       "Name: confidence, dtype: int64"
      ]
     },
     "execution_count": 410,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_models.confidence.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-IkAHUb-_qGG"
   },
   "outputs": [],
   "source": [
    "sensitivity = 0.91"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 873
    },
    "colab_type": "code",
    "id": "8kB-MOl_tb8R",
    "outputId": "4fec1dea-1d85-4750-b8cf-f7b9e45df394"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>WAERS_B00</th>\n",
       "      <th>WAERS_B31</th>\n",
       "      <th>WAERS_B39</th>\n",
       "      <th>WAERS_C1</th>\n",
       "      <th>WAERS_C2</th>\n",
       "      <th>WAERS_C3</th>\n",
       "      <th>WAERS_C4</th>\n",
       "      <th>WAERS_C5</th>\n",
       "      <th>WAERS_C6</th>\n",
       "      <th>WAERS_C7</th>\n",
       "      <th>WAERS_C8</th>\n",
       "      <th>WAERS_C89</th>\n",
       "      <th>WAERS_C9</th>\n",
       "      <th>WAERS_C91</th>\n",
       "      <th>WAERS_D48</th>\n",
       "      <th>WAERS_D52</th>\n",
       "      <th>WAERS_D88</th>\n",
       "      <th>WAERS_E00</th>\n",
       "      <th>WAERS_E15</th>\n",
       "      <th>WAERS_E26</th>\n",
       "      <th>WAERS_E59</th>\n",
       "      <th>WAERS_F66</th>\n",
       "      <th>WAERS_G38</th>\n",
       "      <th>WAERS_G92</th>\n",
       "      <th>WAERS_H01</th>\n",
       "      <th>WAERS_H45</th>\n",
       "      <th>WAERS_H50</th>\n",
       "      <th>WAERS_H54</th>\n",
       "      <th>WAERS_H84</th>\n",
       "      <th>WAERS_I86</th>\n",
       "      <th>WAERS_J13</th>\n",
       "      <th>WAERS_J15</th>\n",
       "      <th>WAERS_J38</th>\n",
       "      <th>WAERS_J41</th>\n",
       "      <th>WAERS_J73</th>\n",
       "      <th>WAERS_J82</th>\n",
       "      <th>WAERS_K11</th>\n",
       "      <th>WAERS_K99</th>\n",
       "      <th>WAERS_L26</th>\n",
       "      <th>...</th>\n",
       "      <th>HKONT_W62</th>\n",
       "      <th>HKONT_X53</th>\n",
       "      <th>HKONT_Y03</th>\n",
       "      <th>HKONT_Y23</th>\n",
       "      <th>HKONT_Z01</th>\n",
       "      <th>HKONT_Z02</th>\n",
       "      <th>DMBTR</th>\n",
       "      <th>WRBTR</th>\n",
       "      <th>pca_lr</th>\n",
       "      <th>pca_knn</th>\n",
       "      <th>pca_svc</th>\n",
       "      <th>pca_lof</th>\n",
       "      <th>pca_kmeans</th>\n",
       "      <th>pca_dt</th>\n",
       "      <th>pca_rf</th>\n",
       "      <th>pca_et</th>\n",
       "      <th>pca_ab</th>\n",
       "      <th>pca_gb</th>\n",
       "      <th>pca_bnb</th>\n",
       "      <th>pca_gnb</th>\n",
       "      <th>pca_ridge</th>\n",
       "      <th>pca_sgd</th>\n",
       "      <th>pca_nc</th>\n",
       "      <th>ae_lr</th>\n",
       "      <th>ae_knn</th>\n",
       "      <th>ae_svc</th>\n",
       "      <th>ae_lof</th>\n",
       "      <th>ae_kmeans</th>\n",
       "      <th>ae_dt</th>\n",
       "      <th>ae_rf</th>\n",
       "      <th>ae_et</th>\n",
       "      <th>ae_ab</th>\n",
       "      <th>ae_gb</th>\n",
       "      <th>ae_bnb</th>\n",
       "      <th>ae_gnb</th>\n",
       "      <th>ae_ridge</th>\n",
       "      <th>ae_sgd</th>\n",
       "      <th>ae_nc</th>\n",
       "      <th>label</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4924</th>\n",
       "      <td>365262</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.913016</td>\n",
       "      <td>0.863597</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.913016</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.888856</td>\n",
       "      <td>0.913016</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.979584</td>\n",
       "      <td>0.863597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003867</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.211289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9098</th>\n",
       "      <td>528759</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.837165</td>\n",
       "      <td>0.913016</td>\n",
       "      <td>0.863597</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.913016</td>\n",
       "      <td>0.809475</td>\n",
       "      <td>0.780435</td>\n",
       "      <td>0.888856</td>\n",
       "      <td>0.913016</td>\n",
       "      <td>0.003429</td>\n",
       "      <td>0.979584</td>\n",
       "      <td>0.863597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003867</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.863597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730692</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.808456</td>\n",
       "      <td>0.8444</td>\n",
       "      <td>0.826037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.78255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000716</td>\n",
       "      <td>1</td>\n",
       "      <td>0.454188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11430</th>\n",
       "      <td>336799</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.837165</td>\n",
       "      <td>0.913016</td>\n",
       "      <td>0.863597</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.913016</td>\n",
       "      <td>0.809475</td>\n",
       "      <td>0.780435</td>\n",
       "      <td>0.888856</td>\n",
       "      <td>0.913016</td>\n",
       "      <td>0.003429</td>\n",
       "      <td>0.979584</td>\n",
       "      <td>0.863597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003867</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.863597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.808456</td>\n",
       "      <td>0.8444</td>\n",
       "      <td>0.826037</td>\n",
       "      <td>0.387042</td>\n",
       "      <td>0.78255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.467061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24258</th>\n",
       "      <td>318771</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.734266</td>\n",
       "      <td>0.794316</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2307</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.979584</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.863597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.808456</td>\n",
       "      <td>0.8444</td>\n",
       "      <td>0.826037</td>\n",
       "      <td>0.387042</td>\n",
       "      <td>0.78255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000716</td>\n",
       "      <td>1</td>\n",
       "      <td>0.215128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26602</th>\n",
       "      <td>246305</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.837165</td>\n",
       "      <td>0.913016</td>\n",
       "      <td>0.863597</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.913016</td>\n",
       "      <td>0.809475</td>\n",
       "      <td>0.780435</td>\n",
       "      <td>0.888856</td>\n",
       "      <td>0.913016</td>\n",
       "      <td>0.003429</td>\n",
       "      <td>0.979584</td>\n",
       "      <td>0.863597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003867</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.863597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730692</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.808456</td>\n",
       "      <td>0.8444</td>\n",
       "      <td>0.826037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.78255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000716</td>\n",
       "      <td>1</td>\n",
       "      <td>0.454188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29651</th>\n",
       "      <td>466915</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.837165</td>\n",
       "      <td>0.913016</td>\n",
       "      <td>0.863597</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.913016</td>\n",
       "      <td>0.809475</td>\n",
       "      <td>0.780435</td>\n",
       "      <td>0.888856</td>\n",
       "      <td>0.913016</td>\n",
       "      <td>0.003429</td>\n",
       "      <td>0.979584</td>\n",
       "      <td>0.863597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003867</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.863597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.808456</td>\n",
       "      <td>0.8444</td>\n",
       "      <td>0.826037</td>\n",
       "      <td>0.387042</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000716</td>\n",
       "      <td>1</td>\n",
       "      <td>0.441000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46942</th>\n",
       "      <td>348343</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.837165</td>\n",
       "      <td>0.913016</td>\n",
       "      <td>0.863597</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.913016</td>\n",
       "      <td>0.809475</td>\n",
       "      <td>0.780435</td>\n",
       "      <td>0.888856</td>\n",
       "      <td>0.913016</td>\n",
       "      <td>0.003429</td>\n",
       "      <td>0.979584</td>\n",
       "      <td>0.863597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003867</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.863597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730692</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.808456</td>\n",
       "      <td>0.8444</td>\n",
       "      <td>0.826037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.78255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000716</td>\n",
       "      <td>1</td>\n",
       "      <td>0.454188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49433</th>\n",
       "      <td>234335</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.734266</td>\n",
       "      <td>0.794305</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2307</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.979584</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.863597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.808456</td>\n",
       "      <td>0.8444</td>\n",
       "      <td>0.826037</td>\n",
       "      <td>0.387042</td>\n",
       "      <td>0.78255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.215104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50913</th>\n",
       "      <td>246501</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.837165</td>\n",
       "      <td>0.913016</td>\n",
       "      <td>0.863597</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.913016</td>\n",
       "      <td>0.809475</td>\n",
       "      <td>0.780435</td>\n",
       "      <td>0.888856</td>\n",
       "      <td>0.913016</td>\n",
       "      <td>0.003429</td>\n",
       "      <td>0.979584</td>\n",
       "      <td>0.863597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003867</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.863597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730692</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.808456</td>\n",
       "      <td>0.8444</td>\n",
       "      <td>0.826037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.78255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000716</td>\n",
       "      <td>1</td>\n",
       "      <td>0.454188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52613</th>\n",
       "      <td>281275</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.837165</td>\n",
       "      <td>0.913016</td>\n",
       "      <td>0.863597</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.913016</td>\n",
       "      <td>0.809475</td>\n",
       "      <td>0.780435</td>\n",
       "      <td>0.888856</td>\n",
       "      <td>0.913016</td>\n",
       "      <td>0.003429</td>\n",
       "      <td>0.979584</td>\n",
       "      <td>0.863597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003867</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000716</td>\n",
       "      <td>1</td>\n",
       "      <td>0.292330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54931</th>\n",
       "      <td>487511</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.837165</td>\n",
       "      <td>0.913016</td>\n",
       "      <td>0.863597</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.913016</td>\n",
       "      <td>0.809475</td>\n",
       "      <td>0.780435</td>\n",
       "      <td>0.888856</td>\n",
       "      <td>0.913016</td>\n",
       "      <td>0.003429</td>\n",
       "      <td>0.979584</td>\n",
       "      <td>0.863597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003867</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.863597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730692</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.808456</td>\n",
       "      <td>0.8444</td>\n",
       "      <td>0.826037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.78255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000716</td>\n",
       "      <td>1</td>\n",
       "      <td>0.454188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55544</th>\n",
       "      <td>261308</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.837165</td>\n",
       "      <td>0.913016</td>\n",
       "      <td>0.863597</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.913016</td>\n",
       "      <td>0.809475</td>\n",
       "      <td>0.780435</td>\n",
       "      <td>0.888856</td>\n",
       "      <td>0.913016</td>\n",
       "      <td>0.003429</td>\n",
       "      <td>0.979584</td>\n",
       "      <td>0.863597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003867</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.863597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730692</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.808456</td>\n",
       "      <td>0.8444</td>\n",
       "      <td>0.826037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.78255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000716</td>\n",
       "      <td>1</td>\n",
       "      <td>0.454188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57070</th>\n",
       "      <td>300115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.734266</td>\n",
       "      <td>0.794303</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2307</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.979584</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.863597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.808456</td>\n",
       "      <td>0.8444</td>\n",
       "      <td>0.826037</td>\n",
       "      <td>0.387042</td>\n",
       "      <td>0.78255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.215104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76905</th>\n",
       "      <td>32317</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.734266</td>\n",
       "      <td>0.794301</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.913016</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2307</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.913016</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.888856</td>\n",
       "      <td>0.913016</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.979584</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000716</td>\n",
       "      <td>1</td>\n",
       "      <td>0.161303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91811</th>\n",
       "      <td>229634</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.837165</td>\n",
       "      <td>0.913016</td>\n",
       "      <td>0.863597</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.913016</td>\n",
       "      <td>0.809475</td>\n",
       "      <td>0.780435</td>\n",
       "      <td>0.888856</td>\n",
       "      <td>0.913016</td>\n",
       "      <td>0.003429</td>\n",
       "      <td>0.979584</td>\n",
       "      <td>0.863597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003867</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000716</td>\n",
       "      <td>1</td>\n",
       "      <td>0.292330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95260</th>\n",
       "      <td>484997</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.837165</td>\n",
       "      <td>0.913016</td>\n",
       "      <td>0.863597</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.913016</td>\n",
       "      <td>0.809475</td>\n",
       "      <td>0.780435</td>\n",
       "      <td>0.888856</td>\n",
       "      <td>0.913016</td>\n",
       "      <td>0.003429</td>\n",
       "      <td>0.979584</td>\n",
       "      <td>0.863597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003867</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.863597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730692</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.808456</td>\n",
       "      <td>0.8444</td>\n",
       "      <td>0.826037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.78255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000716</td>\n",
       "      <td>1</td>\n",
       "      <td>0.454188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99026</th>\n",
       "      <td>71036</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.837165</td>\n",
       "      <td>0.913016</td>\n",
       "      <td>0.863597</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.913016</td>\n",
       "      <td>0.809475</td>\n",
       "      <td>0.780435</td>\n",
       "      <td>0.888856</td>\n",
       "      <td>0.913016</td>\n",
       "      <td>0.003429</td>\n",
       "      <td>0.979584</td>\n",
       "      <td>0.863597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003867</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.863597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730692</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.808456</td>\n",
       "      <td>0.8444</td>\n",
       "      <td>0.826037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.78255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000716</td>\n",
       "      <td>1</td>\n",
       "      <td>0.454188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103415</th>\n",
       "      <td>90831</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.837165</td>\n",
       "      <td>0.913016</td>\n",
       "      <td>0.863597</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.913016</td>\n",
       "      <td>0.809475</td>\n",
       "      <td>0.780435</td>\n",
       "      <td>0.888856</td>\n",
       "      <td>0.913016</td>\n",
       "      <td>0.003429</td>\n",
       "      <td>0.979584</td>\n",
       "      <td>0.863597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003867</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.863597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730692</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.808456</td>\n",
       "      <td>0.8444</td>\n",
       "      <td>0.826037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.78255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000716</td>\n",
       "      <td>1</td>\n",
       "      <td>0.454188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109505</th>\n",
       "      <td>88224</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.837165</td>\n",
       "      <td>0.913016</td>\n",
       "      <td>0.863597</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.913016</td>\n",
       "      <td>0.809475</td>\n",
       "      <td>0.780435</td>\n",
       "      <td>0.888856</td>\n",
       "      <td>0.913016</td>\n",
       "      <td>0.003429</td>\n",
       "      <td>0.979584</td>\n",
       "      <td>0.863597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003867</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.863597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730692</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.808456</td>\n",
       "      <td>0.8444</td>\n",
       "      <td>0.826037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.78255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000716</td>\n",
       "      <td>1</td>\n",
       "      <td>0.454188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109772</th>\n",
       "      <td>359776</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.734266</td>\n",
       "      <td>0.794311</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.913016</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2307</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.913016</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.913016</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000716</td>\n",
       "      <td>1</td>\n",
       "      <td>0.099022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111978</th>\n",
       "      <td>418854</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.837165</td>\n",
       "      <td>0.913016</td>\n",
       "      <td>0.863597</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.913016</td>\n",
       "      <td>0.809475</td>\n",
       "      <td>0.780435</td>\n",
       "      <td>0.888856</td>\n",
       "      <td>0.913016</td>\n",
       "      <td>0.003429</td>\n",
       "      <td>0.979584</td>\n",
       "      <td>0.863597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003867</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.863597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730692</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.808456</td>\n",
       "      <td>0.8444</td>\n",
       "      <td>0.826037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.78255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000716</td>\n",
       "      <td>1</td>\n",
       "      <td>0.454188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121201</th>\n",
       "      <td>172868</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.837165</td>\n",
       "      <td>0.913016</td>\n",
       "      <td>0.863597</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.913016</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.888856</td>\n",
       "      <td>0.913016</td>\n",
       "      <td>0.003429</td>\n",
       "      <td>0.979584</td>\n",
       "      <td>0.863597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003867</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.863597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730692</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.808456</td>\n",
       "      <td>0.8444</td>\n",
       "      <td>0.826037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.78255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000716</td>\n",
       "      <td>1</td>\n",
       "      <td>0.401191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125155</th>\n",
       "      <td>33365</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.837165</td>\n",
       "      <td>0.913016</td>\n",
       "      <td>0.863597</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.913016</td>\n",
       "      <td>0.809475</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.888856</td>\n",
       "      <td>0.913016</td>\n",
       "      <td>0.003429</td>\n",
       "      <td>0.979584</td>\n",
       "      <td>0.863597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003867</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.863597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730692</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.808456</td>\n",
       "      <td>0.8444</td>\n",
       "      <td>0.826037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.78255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000716</td>\n",
       "      <td>1</td>\n",
       "      <td>0.428173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126106</th>\n",
       "      <td>360246</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.734265</td>\n",
       "      <td>0.794311</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2307</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.979584</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.863597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.808456</td>\n",
       "      <td>0.8444</td>\n",
       "      <td>0.826037</td>\n",
       "      <td>0.387042</td>\n",
       "      <td>0.78255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000716</td>\n",
       "      <td>1</td>\n",
       "      <td>0.215128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130144</th>\n",
       "      <td>391298</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.837165</td>\n",
       "      <td>0.913016</td>\n",
       "      <td>0.863597</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.913016</td>\n",
       "      <td>0.809475</td>\n",
       "      <td>0.780435</td>\n",
       "      <td>0.888856</td>\n",
       "      <td>0.913016</td>\n",
       "      <td>0.003429</td>\n",
       "      <td>0.979584</td>\n",
       "      <td>0.863597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003867</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.292306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25 rows  651 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index  WAERS_B00  WAERS_B31  ...     ae_nc  label  confidence\n",
       "4924    365262          0          0  ...  0.000000      1    0.211289\n",
       "9098    528759          0          0  ...  0.000716      1    0.454188\n",
       "11430   336799          0          0  ...  0.000000      1    0.467061\n",
       "24258   318771          0          0  ...  0.000716      1    0.215128\n",
       "26602   246305          0          0  ...  0.000716      1    0.454188\n",
       "29651   466915          0          0  ...  0.000716      1    0.441000\n",
       "46942   348343          0          0  ...  0.000716      1    0.454188\n",
       "49433   234335          0          0  ...  0.000000      1    0.215104\n",
       "50913   246501          0          0  ...  0.000716      1    0.454188\n",
       "52613   281275          0          0  ...  0.000716      1    0.292330\n",
       "54931   487511          0          0  ...  0.000716      1    0.454188\n",
       "55544   261308          0          0  ...  0.000716      1    0.454188\n",
       "57070   300115          0          0  ...  0.000000      1    0.215104\n",
       "76905    32317          0          0  ...  0.000716      1    0.161303\n",
       "91811   229634          0          0  ...  0.000716      1    0.292330\n",
       "95260   484997          0          0  ...  0.000716      1    0.454188\n",
       "99026    71036          1          0  ...  0.000716      1    0.454188\n",
       "103415   90831          0          0  ...  0.000716      1    0.454188\n",
       "109505   88224          0          0  ...  0.000716      1    0.454188\n",
       "109772  359776          0          0  ...  0.000716      1    0.099022\n",
       "111978  418854          0          0  ...  0.000716      1    0.454188\n",
       "121201  172868          0          0  ...  0.000716      1    0.401191\n",
       "125155   33365          0          0  ...  0.000716      1    0.428173\n",
       "126106  360246          0          0  ...  0.000716      1    0.215128\n",
       "130144  391298          0          0  ...  0.000000      1    0.292306\n",
       "\n",
       "[25 rows x 651 columns]"
      ]
     },
     "execution_count": 412,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_models[(df_models.confidence >= (1-sensitivity))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "4CvG4sQuQBQ_",
    "outputId": "970952bf-a098-4195-eae2-c223597ce9ff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    133228\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 413,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_models[(df_models.confidence < (1-sensitivity))].label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6PCj629ZRmBy"
   },
   "source": [
    "## AE kNN + PCA kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mlTuXupJ3oMh"
   },
   "outputs": [],
   "source": [
    "# pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iOLpd57uSurj"
   },
   "outputs": [],
   "source": [
    "#  pred_knn=pd.Series(pred)\n",
    "#  pred_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yjO-87yGRtV_"
   },
   "outputs": [],
   "source": [
    "# df_ae_knn = ori_subset_transformed.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pe5ni6QYXaw2"
   },
   "outputs": [],
   "source": [
    "# X_train_ae_knn, X_val_ae_knn, y_train_ae_knn, y_val_ae_knn = \\\n",
    "# train_test_split(\n",
    "#     df_ae_knn_train, \n",
    "#     df_ae_knn_y_train, \n",
    "#     random_state=42, \n",
    "#     stratify=df_y_train\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0Y9qmp25Wd25"
   },
   "outputs": [],
   "source": [
    "# ae_knn_filter = pd.concat([pd.concat([df_ae_knn.reset_index(),pred_knn.rename('pred_ae_knn')], axis = 1),label.reset_index().drop(columns='index')], axis = 1).set_index('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rKdjwiFEWlIt"
   },
   "outputs": [],
   "source": [
    "# ae_knn_filter = ae_knn_filter[(ae_knn_filter.pred_ae_knn != 1)].drop(columns=['pred_ae_knn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GOakTVxwZgBI"
   },
   "outputs": [],
   "source": [
    "# label_new = ae_knn_filter.pop('label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wYZdApFhaJrP"
   },
   "outputs": [],
   "source": [
    "# label_new = label_new.map({'regular': 0, 'global': 1, 'local': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TdI3sJpuW6RQ"
   },
   "outputs": [],
   "source": [
    "# df_ae_knn_train, df_ae_knn_test, df_ae_knn_y_train, df_ae_knn_y_test = \\\n",
    "# train_test_split(\n",
    "#     ae_knn_filter, \n",
    "#     label_new, \n",
    "#     random_state=42, \n",
    "#     stratify=label_new\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pVN-6J8xYjyv"
   },
   "outputs": [],
   "source": [
    "# ss = MinMaxScaler()\n",
    "# X_train_knn_ss = ss.fit_transform(df_ae_knn_train)\n",
    "# X_val_knn_ss = ss.transform(df_ae_knn_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NMTK9KYzZH27"
   },
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qsKMqCcfZNJy"
   },
   "outputs": [],
   "source": [
    "# pca = PCA(n_components=200)\n",
    "# X_train_knn_ss = pca.fit_transform(X_train_knn_ss)\n",
    "# X_val_knn_ss = pca.transform(X_val_knn_ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fTSaeDKLZSBH"
   },
   "outputs": [],
   "source": [
    "# # X_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
    "# print(f'Training data shape {X_train_knn_ss.shape}')\n",
    "\n",
    "# # X_test = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])\n",
    "# print(f'Testing data shape {X_val_knn_ss.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qTrQndm-ZXAi"
   },
   "outputs": [],
   "source": [
    "# knn = KNeighborsClassifier()\n",
    "# knn.fit(X_train_knn_ss, df_ae_knn_y_train.astype('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5tGJrOuSZY2L"
   },
   "outputs": [],
   "source": [
    "# pred_2 = knn.predict(X_val_knn_ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NGighr5HaS9J"
   },
   "outputs": [],
   "source": [
    "# pred_pca_knn =pd.Series(pred_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J1r_AFKFZ-Z5"
   },
   "outputs": [],
   "source": [
    "# cmat = confusion_matrix(df_ae_knn_y_test.astype(int), pred_2)\n",
    "# print(f'TP - True Negative {cmat[0,0]}')\n",
    "# print(f'FP - False Positive {cmat[0,1]}')\n",
    "# print(f'FN - False Negative {cmat[1,0]}')\n",
    "# print(f'TP - True Positive {cmat[1,1]}')\n",
    "# print(f'Accuracy Rate: {np.divide(np.sum([cmat[0,0],cmat[1,1]]),np.sum(cmat))}')\n",
    "# print(f'Misclassification Rate: {np.divide(np.sum([cmat[0,1],cmat[1,0]]),np.sum(cmat))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bzSc6F6NaDmR"
   },
   "outputs": [],
   "source": [
    "# print(classification_report(df_ae_knn_y_test.astype(int), pred_2, digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3D4pJS9ub2AK"
   },
   "outputs": [],
   "source": [
    "# # lof_filter = \n",
    "# pd.concat([ae_knn_filter.reset_index(), pred_pca_knn.rename('pred_pca_knn')], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZczjqfYsfWU8"
   },
   "outputs": [],
   "source": [
    "# df_new = lof_filter[(lof_filter.pred_ae_lof != 1) & (lof_filter.pred_lof != 1)].drop(labels=['pred_ae_lof', 'pred_lof'], axis = 1).set_index('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D8_ZUnhOiq4N"
   },
   "outputs": [],
   "source": [
    "# log()\n",
    "# # remove the \"ground-truth\" label information for the following steps of the lab\n",
    "# label_new = df_new.pop('label')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "name": "aa_07_technical_report_autoencoder.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
