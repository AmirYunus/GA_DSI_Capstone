{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "start_time = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T07:15:25.102282Z",
     "start_time": "2019-11-14T07:15:21.614130Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 151
    },
    "colab_type": "code",
    "id": "FG3JA7nankdB",
    "outputId": "f93a2c96-38e2-44de-bc62-b977ac15b97d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import warnings\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.externals import joblib\n",
    "from numpy.random import seed\n",
    "from keras.layers import Input, Dropout, Dense, LSTM, TimeDistributed, RepeatVector, LeakyReLU\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.display import display, Markdown, HTML\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, CSVLogger\n",
    "\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T07:15:25.208478Z",
     "start_time": "2019-11-14T07:15:25.115019Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "mEX9wzPFnkdF"
   },
   "outputs": [],
   "source": [
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T07:15:25.423967Z",
     "start_time": "2019-11-14T07:15:25.211549Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "VIX_5yFlnkdH",
    "outputId": "e29cc668-0d86-4d3d-bc58-a0337e5ffef5"
   },
   "outputs": [],
   "source": [
    "# prevent warnings from distracting the reader\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T07:15:26.002991Z",
     "start_time": "2019-11-14T07:15:25.471677Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "pVNWhhghnkdR",
    "outputId": "abdeadfb-32ff-4adb-b3f2-ac95059caa10"
   },
   "outputs": [],
   "source": [
    "# load the dataset into the notebook kernel\n",
    "ori_dataset = pd.read_csv('../data/test_set_c.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T07:15:27.187381Z",
     "start_time": "2019-11-14T07:15:27.163945Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "IKkHjDjqnkdS",
    "outputId": "b7e0e355-b2b1-4ed5-dc69-11628c74cbd1"
   },
   "outputs": [],
   "source": [
    "# remove the \"ground-truth\" label\n",
    "if 'label' in ori_dataset:\n",
    "    label = ori_dataset.pop('label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T07:15:44.767685Z",
     "start_time": "2019-11-14T07:15:42.253654Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "rMK20pzonkdU",
    "outputId": "5f87bf95-7f19-4cba-8a7b-8fc203719841"
   },
   "outputs": [],
   "source": [
    "categ_cols = ori_dataset.select_dtypes([np.object]).columns\n",
    "\n",
    "# # select categorical attributes to be \"one-hot\" encoded\n",
    "# categorical_attr_names = ['WAERS', 'BUKRS', 'KTOSL', 'PRCTR', 'BSCHL', 'HKONT']\n",
    "\n",
    "# encode categorical attributes into a binary one-hot encoded representation \n",
    "ori_dataset_categ_transformed = pd.get_dummies(ori_dataset[categ_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T07:15:44.853303Z",
     "start_time": "2019-11-14T07:15:44.794108Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "29bK-wtjnkdW",
    "outputId": "cc12bb16-27f3-4303-86b5-560114c64628"
   },
   "outputs": [],
   "source": [
    "numeric_cols = ori_dataset.select_dtypes([np.int64, np.float64, np.uint64]).columns\n",
    "\n",
    "# # select \"DMBTR\" vs. \"WRBTR\" attribute\n",
    "# numeric_attr_names = ['DMBTR', 'WRBTR']\n",
    "\n",
    "# add a small epsilon to eliminate zero values from data for log scaling\n",
    "numeric_attr = ori_dataset[numeric_cols] + 1e-7\n",
    "numeric_attr = numeric_attr.apply(np.log)\n",
    "\n",
    "# normalize all numeric attributes to the range [0,1]\n",
    "ori_dataset_numeric_attr = (numeric_attr - numeric_attr.min()) / (numeric_attr.max() - numeric_attr.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T07:17:33.180096Z",
     "start_time": "2019-11-14T07:17:32.491229Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "rbxxwR1tnkdX",
    "outputId": "7eebe4cc-bf63-4636-aa1b-75f06c0ef0b1"
   },
   "outputs": [],
   "source": [
    "# merge categorical and numeric subsets\n",
    "ori_subset_transformed = pd.concat([ori_dataset_categ_transformed, ori_dataset_numeric_attr], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Su1SRWznkda"
   },
   "outputs": [],
   "source": [
    "df = ori_subset_transformed.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aDaCAzhJnkdc"
   },
   "outputs": [],
   "source": [
    "ss = MinMaxScaler()\n",
    "df_ss = ss.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OjAjw_UbtzwR"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "# latent space dimension\n",
    "encoding_dim = 2\n",
    "\n",
    "# input placeholder\n",
    "input_data = Input(shape = (df_ss.shape[1],))\n",
    "\n",
    "# encoded input\n",
    "encoded = Dense(512, activation = 'relu', activity_regularizer = regularizers.l1(10e-5) ) (input_data)\n",
    "encoded = Dense(256, activation='relu')(encoded)\n",
    "encoded = Dense(128, activation='relu')(encoded)\n",
    "encoded = Dense(64, activation='relu')(encoded)\n",
    "encoded = Dense(32, activation='relu')(encoded)\n",
    "encoded = Dense(16, activation='relu')(encoded)\n",
    "encoded = Dense(4, activation='relu')(encoded)\n",
    "encoded = Dense(encoding_dim, activation='relu')(encoded)\n",
    "\n",
    "# decoded input\n",
    "decoded = Dense(4, activation='relu')(encoded)\n",
    "decoded = Dense(16, activation='relu')(decoded)\n",
    "decoded = Dense(32, activation='relu')(decoded)\n",
    "decoded = Dense(64, activation='relu')(decoded)\n",
    "decoded = Dense(128, activation='relu')(decoded)\n",
    "decoded = Dense(256, activation='relu')(decoded)\n",
    "decoded = Dense(512, activation='relu')(decoded)\n",
    "decoded = Dense(df_ss.shape[1], activation='sigmoid')(decoded)\n",
    "\n",
    "# build autoencoder model\n",
    "autoencoder = Model (input_data, decoded)\n",
    "\n",
    "# build encoder for autoencoder model\n",
    "encoder = Model (input_data, encoded)\n",
    "\n",
    "# build decoder for autoencoder model\n",
    "# encoded_input = Input (shape = (encoding_dim, ) )\n",
    "# decoder_layer = autoencoder.layers[-1]\n",
    "# decoder = Model (encoded_input, decoder_layer (encoded_input) )\n",
    "\n",
    "autoencoder.compile (optimizer = 'adam', loss = 'binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T08:29:27.923896Z",
     "start_time": "2019-11-14T07:19:28.394615Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "GeX0iuU2nkdt",
    "outputId": "8fdc1eae-d48f-43bf-bafc-0264548fe961",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "batch_size = 64\n",
    "autoencoder_history = autoencoder.fit(\n",
    "    df_ss, \n",
    "    df_ss, \n",
    "    epochs = epochs,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = False,\n",
    "    verbose = 0,\n",
    "    validation_split = (1 / 3),\n",
    ").history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_ratio = 0.0002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "head = int(anomaly_ratio * df_ss.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iC4klToFnkeC"
   },
   "outputs": [],
   "source": [
    "threshold = 0.019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T08:56:12.742492Z",
     "start_time": "2019-11-14T08:56:01.506665Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "g4kqTVZfnkeF"
   },
   "outputs": [],
   "source": [
    "X_pred = autoencoder.predict(df_ss)\n",
    "X_pred = pd.DataFrame(X_pred, columns = df.columns)\n",
    "X_pred.index = df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T08:56:14.080626Z",
     "start_time": "2019-11-14T08:56:12.745406Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "9q_kbxgunkeG"
   },
   "outputs": [],
   "source": [
    "autoencoder_scored = pd.DataFrame(index = df.index)\n",
    "autoencoder_scored['anomaly_score'] = np.mean(np.abs(X_pred-df_ss), axis=1)\n",
    "autoencoder_scored = autoencoder_scored.sort_values('anomaly_score', ascending=False).head(head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_scored['threshold'] = threshold\n",
    "autoencoder_scored['pred_anomaly'] = (autoencoder_scored.anomaly_score >= autoencoder_scored.threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oTvXfd5Rx00k"
   },
   "outputs": [],
   "source": [
    "df_results = autoencoder_scored[(autoencoder_scored.pred_anomaly == True)]['pred_anomaly']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VfHr0hRHzEVQ"
   },
   "outputs": [],
   "source": [
    "df_results = pd.concat([ori_dataset.iloc[df_results.index]], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UIGz6hXj5_9h"
   },
   "outputs": [],
   "source": [
    "html_string = '''\n",
    "<html>\n",
    "  <head><title>Fraud Scan Results</title></head>\n",
    "  <link rel=\"stylesheet\" type=\"text/css\" href=\"../code/df_style.css\"/>\n",
    "  <body>\n",
    "    <h1 align = 'center'>Fraud Scan Results</h1>\n",
    "    <p align = 'center'>Review {n_anomalies} detected issues</p>\n",
    "    <p align = 'center'>{table}</p>\n",
    "    <p align = 'center'>Time Taken: {time_taken}</p>\n",
    "  </body>\n",
    "</html>.\n",
    "'''\n",
    "\n",
    "# OUTPUT AN HTML FILE\n",
    "with open('../data/results.html', 'w') as f:\n",
    "    f.write(\n",
    "        html_string.format(\n",
    "            n_anomalies = \\\n",
    "            df_results.shape[0],\n",
    "            table=df_results.to_html(classes='mystyle'), \n",
    "            time_taken=(datetime.now() - start_time)\n",
    "        )\n",
    "    )\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "name": "aa_07_technical_report_autoencoder.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
